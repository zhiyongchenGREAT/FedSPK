{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torchaudio.info('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioMetaData(sample_rate=16000, num_frames=133761, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torchaudio.backend.sox_io_backend.load('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-147, -137,  -86,  ...,  581, 1629, 2023]], dtype=torch.int16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "sample_rate, audio  = wavfile.read('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.SpeakerNet import SpeakerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_vector.py, Embedding size is 192,  Spec_aug False.\n",
      "Initialised Softmax Loss\n"
     ]
    }
   ],
   "source": [
    "s = SpeakerNet(model='X_vector', trainfunc='softmax', nPerSpeaker=1, Syncbatch=False, n_mels=40, nOut=192, spec_aug=False, nClasses=5994, additional_model=[True,True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(s.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(s.__S__.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x7fe0db0ef3e0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(s.__L__.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'__L__' in '__L__.fc.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.fc.weight', '__L__.fc.bias', '__L__.encoder_layers.self_attn.in_proj_weight', '__L__.encoder_layers.self_attn.in_proj_bias', '__L__.encoder_layers.self_attn.out_proj.weight', '__L__.encoder_layers.self_attn.out_proj.bias', '__L__.encoder_layers.linear1.weight', '__L__.encoder_layers.linear1.bias', '__L__.encoder_layers.linear2.weight', '__L__.encoder_layers.linear2.bias', '__L__.encoder_layers.norm1.weight', '__L__.encoder_layers.norm1.bias', '__L__.encoder_layers.norm2.weight', '__L__.encoder_layers.norm2.bias', '__L__.transformer_encoder.layers.0.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.0.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.0.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.0.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.0.linear1.weight', '__L__.transformer_encoder.layers.0.linear1.bias', '__L__.transformer_encoder.layers.0.linear2.weight', '__L__.transformer_encoder.layers.0.linear2.bias', '__L__.transformer_encoder.layers.0.norm1.weight', '__L__.transformer_encoder.layers.0.norm1.bias', '__L__.transformer_encoder.layers.0.norm2.weight', '__L__.transformer_encoder.layers.0.norm2.bias', '__L__.transformer_encoder.layers.1.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.1.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.1.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.1.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.1.linear1.weight', '__L__.transformer_encoder.layers.1.linear1.bias', '__L__.transformer_encoder.layers.1.linear2.weight', '__L__.transformer_encoder.layers.1.linear2.bias', '__L__.transformer_encoder.layers.1.norm1.weight', '__L__.transformer_encoder.layers.1.norm1.bias', '__L__.transformer_encoder.layers.1.norm2.weight', '__L__.transformer_encoder.layers.1.norm2.bias'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('__S__.torchfb.0.flipped_filter',\n",
       "              tensor([[[-0.9700,  1.0000]]])),\n",
       "             ('__S__.torchfb.1.spectrogram.window',\n",
       "              tensor([0.0800, 0.0801, 0.0802, 0.0805, 0.0809, 0.0814, 0.0820, 0.0828, 0.0836,\n",
       "                      0.0846, 0.0857, 0.0868, 0.0881, 0.0896, 0.0911, 0.0927, 0.0945, 0.0963,\n",
       "                      0.0983, 0.1003, 0.1025, 0.1048, 0.1072, 0.1097, 0.1123, 0.1150, 0.1178,\n",
       "                      0.1208, 0.1238, 0.1269, 0.1301, 0.1335, 0.1369, 0.1404, 0.1441, 0.1478,\n",
       "                      0.1516, 0.1555, 0.1595, 0.1637, 0.1679, 0.1721, 0.1765, 0.1810, 0.1856,\n",
       "                      0.1902, 0.1949, 0.1998, 0.2047, 0.2097, 0.2147, 0.2199, 0.2251, 0.2304,\n",
       "                      0.2358, 0.2413, 0.2468, 0.2524, 0.2581, 0.2638, 0.2696, 0.2755, 0.2814,\n",
       "                      0.2874, 0.2935, 0.2997, 0.3058, 0.3121, 0.3184, 0.3248, 0.3312, 0.3376,\n",
       "                      0.3441, 0.3507, 0.3573, 0.3640, 0.3707, 0.3774, 0.3842, 0.3910, 0.3979,\n",
       "                      0.4047, 0.4117, 0.4186, 0.4256, 0.4326, 0.4397, 0.4467, 0.4538, 0.4609,\n",
       "                      0.4680, 0.4752, 0.4823, 0.4895, 0.4967, 0.5039, 0.5111, 0.5183, 0.5256,\n",
       "                      0.5328, 0.5400, 0.5472, 0.5544, 0.5617, 0.5689, 0.5761, 0.5833, 0.5905,\n",
       "                      0.5977, 0.6048, 0.6120, 0.6191, 0.6262, 0.6333, 0.6403, 0.6474, 0.6544,\n",
       "                      0.6614, 0.6683, 0.6753, 0.6821, 0.6890, 0.6958, 0.7026, 0.7093, 0.7160,\n",
       "                      0.7227, 0.7293, 0.7359, 0.7424, 0.7488, 0.7552, 0.7616, 0.7679, 0.7742,\n",
       "                      0.7803, 0.7865, 0.7926, 0.7986, 0.8045, 0.8104, 0.8162, 0.8219, 0.8276,\n",
       "                      0.8332, 0.8387, 0.8442, 0.8496, 0.8549, 0.8601, 0.8653, 0.8703, 0.8753,\n",
       "                      0.8802, 0.8851, 0.8898, 0.8944, 0.8990, 0.9035, 0.9079, 0.9121, 0.9163,\n",
       "                      0.9205, 0.9245, 0.9284, 0.9322, 0.9359, 0.9396, 0.9431, 0.9465, 0.9499,\n",
       "                      0.9531, 0.9562, 0.9592, 0.9622, 0.9650, 0.9677, 0.9703, 0.9728, 0.9752,\n",
       "                      0.9775, 0.9797, 0.9817, 0.9837, 0.9855, 0.9873, 0.9889, 0.9904, 0.9919,\n",
       "                      0.9932, 0.9943, 0.9954, 0.9964, 0.9972, 0.9980, 0.9986, 0.9991, 0.9995,\n",
       "                      0.9998, 0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9991, 0.9986, 0.9980,\n",
       "                      0.9972, 0.9964, 0.9954, 0.9943, 0.9932, 0.9919, 0.9904, 0.9889, 0.9873,\n",
       "                      0.9855, 0.9837, 0.9817, 0.9797, 0.9775, 0.9752, 0.9728, 0.9703, 0.9677,\n",
       "                      0.9650, 0.9622, 0.9592, 0.9562, 0.9531, 0.9499, 0.9465, 0.9431, 0.9396,\n",
       "                      0.9359, 0.9322, 0.9284, 0.9245, 0.9205, 0.9163, 0.9121, 0.9079, 0.9035,\n",
       "                      0.8990, 0.8944, 0.8898, 0.8851, 0.8802, 0.8753, 0.8703, 0.8653, 0.8601,\n",
       "                      0.8549, 0.8496, 0.8442, 0.8387, 0.8332, 0.8276, 0.8219, 0.8162, 0.8104,\n",
       "                      0.8045, 0.7986, 0.7926, 0.7865, 0.7803, 0.7742, 0.7679, 0.7616, 0.7552,\n",
       "                      0.7488, 0.7424, 0.7359, 0.7293, 0.7227, 0.7160, 0.7093, 0.7026, 0.6958,\n",
       "                      0.6890, 0.6821, 0.6753, 0.6683, 0.6614, 0.6544, 0.6474, 0.6403, 0.6333,\n",
       "                      0.6262, 0.6191, 0.6120, 0.6048, 0.5977, 0.5905, 0.5833, 0.5761, 0.5689,\n",
       "                      0.5617, 0.5544, 0.5472, 0.5400, 0.5328, 0.5256, 0.5183, 0.5111, 0.5039,\n",
       "                      0.4967, 0.4895, 0.4823, 0.4752, 0.4680, 0.4609, 0.4538, 0.4467, 0.4397,\n",
       "                      0.4326, 0.4256, 0.4186, 0.4117, 0.4047, 0.3979, 0.3910, 0.3842, 0.3774,\n",
       "                      0.3707, 0.3640, 0.3573, 0.3507, 0.3441, 0.3376, 0.3312, 0.3248, 0.3184,\n",
       "                      0.3121, 0.3058, 0.2997, 0.2935, 0.2874, 0.2814, 0.2755, 0.2696, 0.2638,\n",
       "                      0.2581, 0.2524, 0.2468, 0.2413, 0.2358, 0.2304, 0.2251, 0.2199, 0.2147,\n",
       "                      0.2097, 0.2047, 0.1998, 0.1949, 0.1902, 0.1856, 0.1810, 0.1765, 0.1721,\n",
       "                      0.1679, 0.1637, 0.1595, 0.1555, 0.1516, 0.1478, 0.1441, 0.1404, 0.1369,\n",
       "                      0.1335, 0.1301, 0.1269, 0.1238, 0.1208, 0.1178, 0.1150, 0.1123, 0.1097,\n",
       "                      0.1072, 0.1048, 0.1025, 0.1003, 0.0983, 0.0963, 0.0945, 0.0927, 0.0911,\n",
       "                      0.0896, 0.0881, 0.0868, 0.0857, 0.0846, 0.0836, 0.0828, 0.0820, 0.0814,\n",
       "                      0.0809, 0.0805, 0.0802, 0.0801])),\n",
       "             ('__S__.torchfb.1.mel_scale.fb',\n",
       "              tensor([[-0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.8756, 0.1244, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.7972, 0.2028,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      ...,\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1889],\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0945],\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])),\n",
       "             ('__S__.tdnn1.0.weight',\n",
       "              tensor([[[-1.2713e-02, -1.8299e-02,  4.9114e-02,  5.2640e-02,  2.6351e-02],\n",
       "                       [-3.2142e-02, -1.6426e-02, -2.1600e-02,  2.2035e-02,  2.4249e-02],\n",
       "                       [-4.3636e-02, -4.7509e-02,  1.9992e-02, -4.2740e-02, -3.8626e-02],\n",
       "                       ...,\n",
       "                       [ 1.1885e-02,  3.0398e-02,  4.6570e-02,  3.7177e-02,  4.5768e-02],\n",
       "                       [ 3.8047e-03, -5.2037e-02, -3.3013e-02,  3.4105e-02,  1.8720e-02],\n",
       "                       [-2.4096e-02,  4.7861e-02,  3.4828e-02, -4.5024e-02,  3.4111e-02]],\n",
       "              \n",
       "                      [[-7.3117e-03,  2.7849e-02,  8.7948e-03,  2.0099e-02, -3.5584e-04],\n",
       "                       [-2.1074e-02, -2.0154e-02, -4.2670e-02,  2.2109e-02,  1.1238e-02],\n",
       "                       [-2.1508e-02, -1.2506e-02, -2.9124e-02, -1.3669e-02, -3.1951e-02],\n",
       "                       ...,\n",
       "                       [ 1.9888e-03,  4.0819e-02, -5.2169e-02, -4.1193e-02,  3.6546e-02],\n",
       "                       [-1.9751e-02, -5.3781e-02,  3.1711e-03, -4.5323e-02, -6.8933e-03],\n",
       "                       [-3.5621e-02,  3.3085e-02,  2.2242e-02,  1.2598e-02,  4.8566e-02]],\n",
       "              \n",
       "                      [[ 3.9252e-02,  1.7649e-02, -5.3880e-02, -8.6610e-03, -3.1874e-02],\n",
       "                       [-1.6965e-02,  5.1327e-02, -4.0371e-02, -4.3542e-02, -1.7022e-02],\n",
       "                       [ 1.0157e-02,  2.4904e-02,  3.3899e-02,  4.7954e-02, -8.1891e-03],\n",
       "                       ...,\n",
       "                       [ 2.3529e-02, -2.9429e-02, -3.5445e-02, -1.1126e-04,  3.5911e-02],\n",
       "                       [-4.8669e-02, -3.0855e-02,  1.6818e-02,  2.3097e-02, -5.3822e-02],\n",
       "                       [ 4.8929e-02, -1.4289e-02, -2.4074e-02,  4.6487e-02, -1.3184e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-5.8105e-03,  4.5871e-02, -1.3916e-02,  4.1882e-03, -5.1549e-02],\n",
       "                       [-4.9753e-04,  1.8424e-02,  4.9461e-02, -3.2300e-02, -8.3654e-04],\n",
       "                       [-5.2578e-02, -1.0689e-02, -4.5455e-03,  3.3247e-02, -5.0517e-02],\n",
       "                       ...,\n",
       "                       [-3.3230e-02, -1.5510e-02,  4.9918e-02,  8.2053e-04,  2.7274e-02],\n",
       "                       [ 2.6714e-02,  5.1033e-02, -3.4452e-02, -3.9167e-02,  1.1618e-02],\n",
       "                       [-2.9936e-02, -3.0279e-02, -1.2971e-02,  3.6829e-02, -4.7347e-02]],\n",
       "              \n",
       "                      [[-5.2432e-03,  2.0584e-02, -2.4683e-02,  1.8076e-02, -4.6413e-02],\n",
       "                       [-3.8681e-02,  5.8238e-03, -3.3817e-02,  1.0495e-02, -1.3731e-02],\n",
       "                       [ 4.7389e-02, -5.0768e-02,  2.8942e-02, -3.0262e-02,  1.3478e-02],\n",
       "                       ...,\n",
       "                       [ 4.2523e-02,  4.1866e-02, -3.9260e-02, -3.2368e-02, -6.3879e-04],\n",
       "                       [-9.8459e-03,  5.1897e-02, -7.5477e-03,  1.8934e-02, -9.0929e-03],\n",
       "                       [-4.9178e-02, -1.8614e-02,  4.0535e-02, -2.1405e-03,  8.0089e-03]],\n",
       "              \n",
       "                      [[-5.4289e-02,  2.3374e-02, -1.4197e-02, -8.1346e-03, -4.5811e-02],\n",
       "                       [-3.3268e-02,  1.7945e-02, -5.4105e-02,  1.1113e-02, -1.2995e-02],\n",
       "                       [ 2.4381e-02,  5.0347e-05, -2.0353e-02, -5.4582e-02, -4.2675e-02],\n",
       "                       ...,\n",
       "                       [-3.7074e-02,  2.8415e-02,  5.0810e-03, -3.9278e-02, -3.8614e-02],\n",
       "                       [-2.5877e-02, -2.9665e-02,  4.8716e-02, -4.6956e-02, -5.2224e-03],\n",
       "                       [ 4.7323e-02,  1.3843e-02,  1.2301e-02, -3.2644e-02,  1.4515e-02]]])),\n",
       "             ('__S__.tdnn1.0.bias',\n",
       "              tensor([ 2.1225e-02, -3.4663e-02, -3.0911e-02, -4.4578e-02,  3.9308e-02,\n",
       "                      -4.8730e-02, -4.4159e-02,  6.1011e-04, -3.8355e-02, -5.3412e-02,\n",
       "                       4.6391e-02, -9.2273e-03,  3.3401e-02,  2.5872e-02,  3.3986e-02,\n",
       "                      -2.5412e-02, -4.5164e-02, -3.7321e-02, -1.4405e-02,  3.4323e-02,\n",
       "                      -9.4329e-03, -2.8923e-02, -4.6448e-02,  1.6631e-02,  2.2533e-02,\n",
       "                       2.5740e-02,  5.3552e-02,  4.6541e-02,  3.7678e-02,  3.5410e-03,\n",
       "                       1.5976e-02, -2.7482e-03, -1.6613e-02,  5.4716e-02,  3.6388e-02,\n",
       "                       4.9836e-03,  4.4453e-02,  3.5055e-02,  3.2246e-02,  3.6123e-02,\n",
       "                       1.6936e-02, -3.1664e-03,  2.7083e-02,  1.1190e-02,  1.0725e-02,\n",
       "                      -3.2800e-02, -2.8942e-02,  1.2268e-03, -2.8194e-02,  9.5324e-03,\n",
       "                      -5.2609e-02,  2.7666e-02,  2.1066e-02, -1.9721e-02,  4.1050e-02,\n",
       "                       4.4041e-02, -3.7851e-02,  3.8728e-02,  2.1210e-02,  4.3475e-02,\n",
       "                      -5.5432e-02,  1.2468e-02, -4.9233e-02,  7.9523e-03,  2.9810e-03,\n",
       "                      -4.2981e-02,  4.2245e-02, -1.0139e-03,  1.9798e-02, -2.7027e-02,\n",
       "                       4.6851e-02, -2.2462e-02, -7.4380e-03, -5.5482e-02,  3.9247e-03,\n",
       "                      -3.3131e-02, -2.1083e-02,  3.9598e-02, -3.9156e-02,  5.0789e-02,\n",
       "                      -2.0754e-02, -4.5866e-02, -1.1342e-02,  1.3645e-02, -4.5697e-03,\n",
       "                       3.4663e-02,  5.1346e-02,  3.7283e-02,  3.8097e-02,  4.2713e-02,\n",
       "                      -4.7749e-02,  1.3728e-02, -1.9579e-02, -3.9805e-02, -1.6205e-02,\n",
       "                      -6.1746e-03, -4.0048e-02, -4.7881e-02,  3.6936e-03,  3.0681e-02,\n",
       "                       3.8717e-02,  4.4373e-02,  4.3153e-03,  2.9153e-02,  5.5591e-02,\n",
       "                      -3.5564e-02,  4.6579e-02, -2.5779e-02, -2.3843e-02,  2.3816e-02,\n",
       "                       5.5840e-02,  4.9082e-04, -5.3624e-02,  2.2875e-02,  4.6366e-02,\n",
       "                      -2.1595e-02,  3.5394e-03,  9.8031e-03, -5.3514e-02, -4.7845e-02,\n",
       "                       1.2374e-02, -3.4012e-02,  3.7188e-02,  1.0206e-02, -5.3159e-02,\n",
       "                       5.4067e-02, -4.8588e-02, -2.0124e-02,  4.5033e-02, -3.0863e-02,\n",
       "                      -3.5240e-03, -5.3638e-03, -4.6537e-02,  5.1911e-02, -3.7870e-02,\n",
       "                      -5.3864e-02, -1.9706e-02,  2.2665e-02, -2.2881e-02,  2.1116e-02,\n",
       "                      -1.8186e-05, -1.2089e-02,  4.3941e-02, -8.0688e-03, -2.7860e-02,\n",
       "                      -5.2700e-03, -4.1925e-02, -1.0441e-03, -6.7197e-03, -1.3656e-02,\n",
       "                       1.3803e-02, -2.6863e-02,  2.7806e-03,  2.9672e-02,  3.3279e-02,\n",
       "                      -1.7282e-02,  2.6512e-02, -2.1732e-02,  5.1686e-02, -4.2194e-02,\n",
       "                       1.9876e-02,  7.9002e-03,  4.4641e-03, -2.5952e-02, -1.0853e-03,\n",
       "                      -5.4857e-02,  3.0565e-02,  2.6505e-03, -3.8498e-02, -9.6770e-03,\n",
       "                      -3.4100e-02, -5.3490e-02, -2.1057e-02,  3.3397e-02, -9.2772e-03,\n",
       "                       6.8743e-03,  2.6723e-02,  4.3575e-02, -4.1231e-02, -6.4345e-03,\n",
       "                       1.9982e-02,  2.7320e-02,  8.1943e-03,  5.1254e-02, -4.8654e-02,\n",
       "                      -2.4833e-02, -3.1278e-02,  5.2356e-03, -4.8930e-02,  7.2022e-03,\n",
       "                       4.0372e-02,  6.4079e-03, -1.1613e-02, -3.6681e-02,  5.5342e-02,\n",
       "                       4.9236e-02, -2.1395e-02, -3.9998e-03,  1.4899e-04, -1.5888e-02,\n",
       "                       6.0450e-03, -4.8238e-03,  3.7750e-02,  3.4732e-03,  5.2840e-02,\n",
       "                       3.1822e-02,  2.9084e-02,  5.3660e-02, -3.4406e-02, -7.3505e-04,\n",
       "                      -1.8191e-02, -1.7812e-02, -1.8582e-02,  4.3449e-02, -4.8234e-02,\n",
       "                      -3.6482e-02,  3.3936e-02,  3.9694e-03,  1.6771e-04, -3.2234e-02,\n",
       "                      -1.3827e-02,  9.9384e-03, -1.5535e-02,  4.0458e-02,  1.4332e-02,\n",
       "                       4.6847e-02, -2.1521e-03,  3.8454e-02,  4.2858e-02,  2.2143e-02,\n",
       "                       5.3585e-02, -4.3914e-02,  5.4745e-02,  3.9681e-02, -6.6811e-03,\n",
       "                       2.8300e-02, -5.1964e-02, -2.3363e-02,  2.6782e-02,  4.7105e-02,\n",
       "                      -1.4355e-02,  4.2660e-03,  5.5263e-03,  3.6475e-02, -1.7283e-02,\n",
       "                       3.3341e-02,  4.9456e-02,  2.3787e-02, -3.0133e-02, -1.3515e-02,\n",
       "                      -4.5446e-02,  1.0198e-02, -2.5406e-02, -1.9571e-02,  3.7893e-02,\n",
       "                      -3.0942e-02, -3.1304e-02, -4.4918e-02,  2.9694e-02,  4.1192e-02,\n",
       "                      -5.5342e-02,  2.3412e-02,  2.4394e-02, -2.3254e-02,  9.6306e-03,\n",
       "                      -1.4006e-02, -3.3344e-03, -4.8415e-03,  1.4848e-02, -5.9308e-03,\n",
       "                       1.5163e-02,  2.1900e-02, -1.4321e-02, -5.2330e-02, -2.4230e-02,\n",
       "                       1.7207e-02, -3.8608e-02,  5.5684e-02, -4.6674e-02, -5.0327e-02,\n",
       "                      -1.4193e-02, -9.7704e-03,  5.4642e-02,  1.0305e-02,  3.5914e-02,\n",
       "                      -3.8995e-02,  1.5792e-02, -8.6831e-03, -4.7834e-02,  1.5045e-02,\n",
       "                      -4.2623e-02, -2.6146e-02,  2.3978e-02, -5.2158e-02, -1.6089e-02,\n",
       "                      -2.6944e-02, -5.1301e-02,  4.7776e-02, -4.2819e-02, -4.0032e-02,\n",
       "                       3.1316e-02, -4.9107e-03, -2.1047e-02, -4.2430e-02,  1.5704e-02,\n",
       "                      -3.3161e-02,  2.1621e-02,  4.0684e-02,  2.2307e-02,  1.6555e-02,\n",
       "                       1.9509e-02, -1.0036e-02, -1.9088e-02,  5.2763e-02,  5.1164e-02,\n",
       "                      -4.3807e-02,  5.3921e-02,  4.4027e-02,  4.3926e-02,  8.8357e-03,\n",
       "                       4.6649e-02,  4.2139e-02, -5.0424e-02,  5.9970e-03,  5.3166e-02,\n",
       "                      -5.0025e-04, -4.0940e-02, -3.3919e-02,  1.7805e-02, -2.6141e-02,\n",
       "                       3.2784e-04, -4.9358e-02, -1.8665e-02,  3.9359e-02,  5.0460e-02,\n",
       "                      -1.8713e-02, -5.5574e-02,  1.2764e-02,  6.4568e-03, -3.7575e-02,\n",
       "                       3.8396e-02, -4.9561e-02,  2.3706e-02, -1.0987e-02,  1.6868e-02,\n",
       "                       4.8727e-02,  5.2588e-02,  2.6377e-02,  1.4795e-02,  2.3238e-02,\n",
       "                      -1.4946e-02,  2.5691e-02, -4.3647e-02,  7.9372e-03,  4.7138e-02,\n",
       "                       4.6603e-02,  2.8739e-02, -7.6574e-03, -4.2673e-02, -4.3615e-02,\n",
       "                       2.8123e-02, -1.9241e-02,  5.2003e-02, -1.7523e-02,  5.1233e-02,\n",
       "                       9.6720e-03, -4.5080e-02,  2.9587e-02,  4.5288e-02,  2.1803e-02,\n",
       "                      -2.8970e-02,  3.6591e-02,  4.5905e-04,  5.8287e-04, -3.9192e-02,\n",
       "                      -4.4069e-02,  3.0832e-02, -4.6912e-02, -4.5945e-02,  2.0351e-02,\n",
       "                       4.3572e-02,  7.9333e-03, -4.9102e-02,  2.4471e-02, -3.0827e-02,\n",
       "                       4.4869e-02, -5.4619e-02, -1.4646e-03,  6.4370e-04, -3.0407e-02,\n",
       "                       1.2361e-02,  1.6616e-02,  1.3511e-02, -5.3985e-02, -1.3335e-02,\n",
       "                      -3.1039e-02, -6.5891e-03,  4.1464e-02, -5.4736e-02, -1.9209e-02,\n",
       "                       6.4644e-03, -2.7037e-02, -3.7604e-02,  2.2614e-02, -2.3873e-02,\n",
       "                       2.0286e-02,  2.3057e-02,  1.0024e-02,  4.0377e-04,  4.5650e-02,\n",
       "                       2.8350e-02, -4.4368e-02, -3.1973e-02,  3.8715e-02, -4.3743e-03,\n",
       "                      -2.4962e-02, -3.7935e-02,  4.5193e-02, -2.1064e-02, -5.0053e-02,\n",
       "                      -1.9664e-02, -3.5546e-02, -3.3585e-02,  1.1103e-02,  1.0295e-03,\n",
       "                       2.5813e-03,  5.4148e-02, -2.1120e-02, -2.0156e-02, -2.4537e-02,\n",
       "                       3.5011e-02, -2.3944e-03,  3.0298e-04, -1.5707e-02, -2.8259e-03,\n",
       "                       5.1449e-02, -2.7974e-03, -2.5520e-02,  9.6119e-03,  9.7931e-03,\n",
       "                       2.9714e-02,  2.4472e-02, -5.0737e-02,  2.6958e-02, -3.2635e-02,\n",
       "                       3.7877e-02,  1.2793e-02, -5.1739e-02,  2.4540e-02, -1.6677e-02,\n",
       "                       1.7770e-02,  4.4357e-02,  1.2874e-02, -4.2136e-02,  5.0765e-02,\n",
       "                      -7.2195e-03, -5.5428e-02, -3.7544e-03, -1.4103e-02,  8.7452e-03,\n",
       "                      -4.3352e-02, -1.5841e-02,  1.2422e-02, -3.4793e-02,  1.3941e-02,\n",
       "                      -2.1917e-03, -1.6442e-02, -2.6874e-02, -3.1153e-02,  5.4963e-02,\n",
       "                       4.4818e-02,  1.0342e-02, -2.9892e-02, -3.5117e-02, -1.8821e-02,\n",
       "                      -2.5612e-02,  3.0695e-02, -5.1180e-02,  3.7974e-02,  4.6682e-02,\n",
       "                       4.5310e-02,  3.3414e-02,  1.1838e-02,  2.3061e-02, -1.1660e-02,\n",
       "                      -3.8187e-02, -1.8608e-03, -5.1647e-02, -5.0353e-04,  4.6606e-02,\n",
       "                       4.5555e-02, -1.9873e-03,  3.2301e-02, -2.8507e-02,  4.0151e-02,\n",
       "                      -2.6527e-02, -1.0557e-02, -5.5398e-02, -2.2874e-02,  4.9305e-02,\n",
       "                      -3.6818e-02, -4.8607e-02,  8.8546e-04,  2.1474e-02, -4.6295e-02,\n",
       "                      -1.4643e-03, -5.4033e-02, -1.6165e-02,  4.1647e-04,  4.9470e-02,\n",
       "                      -3.4312e-02, -6.6533e-03])),\n",
       "             ('__S__.tdnn1.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn1.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn1.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn1.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn1.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn2.0.weight',\n",
       "              tensor([[[-0.0171, -0.0061, -0.0191],\n",
       "                       [-0.0145,  0.0147,  0.0028],\n",
       "                       [-0.0016,  0.0062, -0.0121],\n",
       "                       ...,\n",
       "                       [-0.0109, -0.0139, -0.0230],\n",
       "                       [-0.0003, -0.0050,  0.0013],\n",
       "                       [ 0.0146, -0.0176,  0.0095]],\n",
       "              \n",
       "                      [[ 0.0039,  0.0071, -0.0239],\n",
       "                       [ 0.0140,  0.0134,  0.0081],\n",
       "                       [ 0.0104,  0.0154,  0.0066],\n",
       "                       ...,\n",
       "                       [ 0.0225, -0.0043, -0.0117],\n",
       "                       [-0.0073, -0.0217,  0.0016],\n",
       "                       [ 0.0198, -0.0027, -0.0080]],\n",
       "              \n",
       "                      [[-0.0084, -0.0196,  0.0122],\n",
       "                       [ 0.0251,  0.0253,  0.0108],\n",
       "                       [ 0.0055, -0.0090,  0.0141],\n",
       "                       ...,\n",
       "                       [-0.0025,  0.0186,  0.0035],\n",
       "                       [ 0.0040, -0.0212, -0.0115],\n",
       "                       [-0.0015,  0.0223,  0.0028]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0234,  0.0159, -0.0034],\n",
       "                       [-0.0154, -0.0099,  0.0112],\n",
       "                       [ 0.0004, -0.0162, -0.0019],\n",
       "                       ...,\n",
       "                       [-0.0243, -0.0042, -0.0200],\n",
       "                       [ 0.0056,  0.0026, -0.0118],\n",
       "                       [-0.0251,  0.0203, -0.0164]],\n",
       "              \n",
       "                      [[-0.0094,  0.0029,  0.0240],\n",
       "                       [ 0.0092,  0.0122, -0.0175],\n",
       "                       [-0.0106, -0.0224,  0.0205],\n",
       "                       ...,\n",
       "                       [ 0.0094,  0.0147, -0.0183],\n",
       "                       [ 0.0178, -0.0087, -0.0082],\n",
       "                       [ 0.0144,  0.0130, -0.0236]],\n",
       "              \n",
       "                      [[-0.0054,  0.0078, -0.0164],\n",
       "                       [-0.0031,  0.0075, -0.0142],\n",
       "                       [ 0.0150,  0.0070,  0.0176],\n",
       "                       ...,\n",
       "                       [ 0.0239, -0.0060, -0.0129],\n",
       "                       [ 0.0054,  0.0193,  0.0009],\n",
       "                       [-0.0217, -0.0132, -0.0063]]])),\n",
       "             ('__S__.tdnn2.0.bias',\n",
       "              tensor([-1.4222e-02,  1.2266e-02, -9.2187e-03,  1.0356e-02, -6.8833e-03,\n",
       "                      -5.3937e-03,  2.3555e-02, -7.0714e-03, -2.4058e-02,  2.1791e-02,\n",
       "                       1.2158e-02, -7.8424e-04,  6.2325e-04, -2.3522e-02,  9.7166e-03,\n",
       "                      -1.2461e-02,  1.9153e-02,  1.7377e-02,  9.7963e-03,  2.2881e-02,\n",
       "                       7.3936e-03, -3.3218e-03,  9.0691e-03, -3.8945e-04,  3.7289e-03,\n",
       "                       1.9572e-02,  2.0036e-04, -1.6830e-02,  2.2875e-02,  2.1188e-02,\n",
       "                      -1.4945e-02,  8.4366e-03, -8.3212e-03, -6.4731e-03,  5.4817e-03,\n",
       "                      -1.1957e-02, -2.0802e-03,  2.0115e-02,  1.9645e-02, -1.9704e-03,\n",
       "                      -2.4272e-02, -1.8098e-03,  1.1165e-02, -3.1457e-03, -1.5682e-03,\n",
       "                       1.2992e-02, -1.9219e-02,  5.8960e-03,  1.6375e-02,  4.3268e-03,\n",
       "                      -2.1723e-02, -1.7311e-02,  2.2045e-02,  1.7993e-02,  1.8017e-02,\n",
       "                       1.0208e-02, -1.3824e-02, -2.6385e-04, -4.6527e-03, -8.2718e-03,\n",
       "                       2.1415e-02, -1.7219e-02,  2.5126e-03,  3.1609e-04, -2.3843e-02,\n",
       "                      -1.3092e-02, -2.3397e-02, -1.6504e-02,  7.3695e-03,  1.6649e-02,\n",
       "                      -1.9316e-02, -1.6868e-02,  1.2635e-02, -1.7271e-02, -2.1228e-02,\n",
       "                      -1.4394e-02,  7.8286e-03, -8.9021e-03,  1.3911e-02,  2.3634e-02,\n",
       "                      -3.7420e-03,  2.4027e-02,  1.2371e-03, -6.1385e-03,  5.6420e-03,\n",
       "                      -3.1108e-03,  3.6590e-03, -5.7734e-03,  1.2307e-02,  1.3401e-02,\n",
       "                      -1.6480e-02,  1.0562e-02, -1.9665e-03,  1.7607e-02,  6.3656e-03,\n",
       "                      -2.2083e-02, -8.0709e-03, -2.5397e-02, -1.0977e-03,  1.8088e-02,\n",
       "                      -1.3989e-02,  2.4155e-02, -1.4817e-02, -2.1272e-02, -9.4426e-03,\n",
       "                      -4.9423e-03, -1.5084e-02, -8.8722e-03,  2.2957e-02,  2.1598e-02,\n",
       "                      -2.0179e-02, -7.7462e-03,  2.1082e-02,  1.8155e-02, -1.7733e-02,\n",
       "                      -8.0361e-03, -2.1397e-02,  9.7367e-03, -5.6435e-03,  1.9180e-02,\n",
       "                      -2.5894e-03, -1.4960e-02,  2.5117e-02, -4.3130e-03, -3.2984e-03,\n",
       "                      -2.3926e-02,  9.4758e-03, -3.7726e-03,  1.0502e-02,  5.1651e-03,\n",
       "                       2.4409e-03,  3.3642e-03,  6.7007e-03, -2.1415e-02,  1.7654e-02,\n",
       "                      -1.0044e-02, -1.3423e-02,  1.0330e-02, -3.7896e-03, -1.7435e-02,\n",
       "                       2.5892e-03, -1.9737e-03, -2.1466e-02,  1.8932e-02, -2.0796e-03,\n",
       "                       2.1118e-02, -2.5258e-02,  7.6999e-03, -9.9569e-03, -1.8860e-02,\n",
       "                      -1.2738e-02,  9.6707e-03,  9.5509e-03, -5.5543e-03,  6.2219e-03,\n",
       "                      -9.2841e-03, -1.4191e-02,  2.0556e-02,  2.3415e-02, -7.4605e-03,\n",
       "                       5.0702e-03, -2.0327e-02,  1.2536e-02, -7.0013e-03,  1.7234e-02,\n",
       "                      -1.1163e-02, -1.4340e-02, -8.4265e-03,  2.4326e-02,  1.8776e-02,\n",
       "                      -1.1664e-02, -7.8462e-03, -2.3582e-02, -2.1370e-02,  2.4135e-02,\n",
       "                      -2.1151e-02, -2.4583e-02, -1.6544e-02, -1.8092e-02, -5.2859e-03,\n",
       "                       1.1107e-02,  2.2142e-02,  2.0234e-03, -1.3031e-02, -1.7249e-02,\n",
       "                       2.2023e-02,  7.8325e-03, -1.6514e-03,  2.4671e-02,  2.4186e-02,\n",
       "                      -1.6071e-02, -2.1630e-02,  4.3053e-03, -1.2321e-02,  2.0102e-02,\n",
       "                       1.5066e-02,  5.7595e-03,  1.5195e-02, -2.3413e-02, -7.9518e-03,\n",
       "                       1.5637e-02, -1.8819e-02, -3.5305e-03, -5.3056e-03, -2.3642e-02,\n",
       "                      -1.4505e-02,  2.4743e-02,  1.7717e-02,  1.1939e-02, -2.2104e-02,\n",
       "                      -1.6603e-02,  9.5191e-03,  4.9707e-05,  1.3473e-02, -1.8428e-02,\n",
       "                       1.5097e-02, -2.0648e-03, -9.6945e-03, -1.7744e-02,  1.3738e-02,\n",
       "                       5.9211e-03,  2.2390e-02, -2.3430e-02, -1.4382e-03,  1.7833e-02,\n",
       "                       6.5364e-03,  2.2926e-02, -2.4699e-02, -2.1118e-02,  3.0730e-04,\n",
       "                       1.3488e-02,  6.0480e-03,  2.1114e-03,  2.3120e-02, -4.5682e-03,\n",
       "                      -1.4121e-02,  9.5474e-03, -1.7839e-02,  9.8831e-03, -4.8561e-03,\n",
       "                       2.0196e-02, -7.4500e-03, -2.0294e-02, -8.5459e-03, -9.6827e-04,\n",
       "                       2.3735e-02,  2.1191e-03,  2.0475e-02, -2.4522e-02, -1.9885e-02,\n",
       "                      -2.3634e-02,  3.7965e-04,  1.7150e-02,  1.5719e-02,  2.1979e-03,\n",
       "                      -2.5126e-02, -5.1536e-03, -6.0249e-03,  6.0619e-03,  2.1001e-02,\n",
       "                      -1.3410e-02, -1.8632e-02, -1.7675e-04,  1.8982e-02, -2.4001e-02,\n",
       "                      -1.9236e-02, -1.5040e-02,  1.7307e-02, -1.6319e-02, -9.7832e-03,\n",
       "                       1.5657e-02,  2.4729e-02,  2.2883e-02,  1.1455e-03, -5.5433e-03,\n",
       "                       2.3802e-03,  1.3456e-02,  5.0085e-03, -1.5372e-02, -6.0970e-03,\n",
       "                       4.5651e-03,  2.3338e-02, -1.8547e-02, -5.2437e-03,  1.5525e-02,\n",
       "                      -1.3041e-02,  4.6142e-03,  1.3785e-03,  6.7429e-03, -5.6421e-03,\n",
       "                      -4.0686e-03, -1.1533e-02, -2.5283e-02, -5.7880e-03, -1.3124e-02,\n",
       "                       6.9868e-03, -2.1623e-02, -1.1526e-02, -1.7999e-02,  1.3508e-02,\n",
       "                       1.4487e-03,  7.4739e-03, -1.5438e-02, -1.6691e-02, -2.3553e-02,\n",
       "                      -2.1713e-03, -1.6825e-02, -1.3696e-02, -1.1457e-03,  1.5676e-02,\n",
       "                      -2.4640e-02,  1.8183e-02,  1.9784e-02, -1.5690e-02,  2.3676e-02,\n",
       "                      -6.5231e-03, -6.6435e-03, -2.5494e-02, -1.4004e-02,  1.3053e-02,\n",
       "                       1.7420e-02,  2.2794e-03, -6.4025e-03,  1.6053e-02,  2.5121e-02,\n",
       "                      -2.3840e-02,  1.4741e-03, -1.9594e-02, -7.0558e-03, -1.9358e-02,\n",
       "                       2.0071e-02, -2.0986e-02,  1.0067e-02, -3.3684e-03,  2.5370e-02,\n",
       "                       1.6489e-02,  3.1021e-03, -3.8855e-03,  7.0289e-03,  1.8303e-02,\n",
       "                       2.3633e-02, -7.3465e-03,  9.3258e-03, -2.5044e-02,  2.3166e-02,\n",
       "                       1.0766e-02,  1.1399e-02,  1.4462e-02, -1.6338e-02, -3.9989e-03,\n",
       "                      -6.2925e-03,  1.5868e-02,  2.3622e-02, -1.0488e-02, -2.5921e-03,\n",
       "                       2.3792e-02,  1.5430e-02,  4.3626e-03, -2.0024e-02, -1.3095e-02,\n",
       "                      -9.0591e-03, -1.3603e-02, -5.1387e-03,  1.4565e-02,  2.0691e-02,\n",
       "                      -2.1079e-02, -1.2463e-02,  2.2420e-02, -4.4231e-03, -1.3302e-02,\n",
       "                      -3.6154e-03, -2.1624e-02, -1.0776e-02, -3.2818e-04, -2.5342e-03,\n",
       "                       1.4891e-02, -1.6952e-02, -1.5457e-03, -1.7076e-02,  1.6353e-02,\n",
       "                       1.0669e-03, -2.9554e-03,  1.1908e-02, -9.2411e-03, -2.2205e-02,\n",
       "                       2.4879e-02, -1.7554e-02,  1.9303e-02,  1.7735e-02, -1.8927e-02,\n",
       "                       7.7002e-03, -1.3819e-02,  1.6119e-02,  1.2976e-02,  2.0005e-02,\n",
       "                       4.9640e-03, -2.0413e-02,  1.1255e-02,  2.9413e-03,  2.2818e-02,\n",
       "                       1.1405e-02, -1.8204e-02,  5.0312e-03,  7.2009e-03,  2.4142e-02,\n",
       "                       8.9092e-03, -1.0756e-04,  2.4993e-02,  1.2250e-02, -1.9575e-02,\n",
       "                       9.0941e-03, -2.2128e-02,  1.0677e-02,  6.5316e-03,  1.4514e-02,\n",
       "                      -2.3672e-02, -1.0513e-02, -1.0216e-02, -1.1484e-02,  2.6113e-03,\n",
       "                       2.4558e-02,  6.5544e-03,  2.3963e-02, -1.5001e-02, -6.1973e-03,\n",
       "                       2.3334e-02, -1.9570e-02,  1.7806e-02, -8.8015e-03, -9.8613e-03,\n",
       "                       2.4263e-02,  8.0180e-04,  1.2237e-02, -1.1740e-02,  2.6031e-03,\n",
       "                      -3.7717e-03, -2.4540e-02, -1.5924e-02,  1.3982e-02,  1.2489e-02,\n",
       "                      -1.1507e-03,  2.3493e-02, -2.3561e-02, -1.0206e-02,  1.6744e-02,\n",
       "                      -1.7922e-02,  2.3257e-02, -1.7006e-02,  1.9299e-02, -1.2102e-02,\n",
       "                      -1.4461e-02,  1.4814e-02, -2.3477e-02, -4.8671e-03, -1.6340e-03,\n",
       "                       1.7526e-02,  2.2135e-02, -2.3618e-02, -2.2416e-02, -1.2816e-02,\n",
       "                      -2.0135e-02,  7.7553e-04, -1.1973e-02, -6.7282e-03, -1.6196e-02,\n",
       "                       1.9982e-02, -1.0032e-02, -6.2954e-03, -1.5926e-02,  1.3992e-03,\n",
       "                      -5.7690e-03, -1.9201e-02, -5.6930e-03,  2.8703e-03, -8.9832e-03,\n",
       "                      -1.9717e-02,  1.9249e-02, -3.5901e-03, -5.7033e-03, -8.0994e-03,\n",
       "                      -9.9780e-03, -6.9180e-03,  1.1724e-03,  1.6251e-02, -7.7720e-03,\n",
       "                       1.7628e-02, -1.5657e-02,  2.0949e-03,  2.3423e-02, -4.3998e-03,\n",
       "                       2.5305e-02,  1.0836e-02,  1.3011e-02,  4.9767e-03, -1.6489e-02,\n",
       "                       2.1197e-02,  1.1996e-02,  1.3164e-02, -1.1514e-02, -9.8646e-03,\n",
       "                      -2.0917e-02,  7.0743e-03,  1.4061e-02, -1.3463e-02, -2.0865e-02,\n",
       "                      -9.4157e-03,  2.3009e-02, -1.4475e-02,  3.7430e-04, -2.1384e-02,\n",
       "                       2.2898e-02, -3.7045e-03])),\n",
       "             ('__S__.tdnn2.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn2.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn2.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn2.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn2.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn3.0.weight',\n",
       "              tensor([[[-0.0229,  0.0078,  0.0016],\n",
       "                       [-0.0170, -0.0083,  0.0254],\n",
       "                       [-0.0109, -0.0134, -0.0115],\n",
       "                       ...,\n",
       "                       [-0.0171,  0.0069,  0.0189],\n",
       "                       [ 0.0030,  0.0009,  0.0166],\n",
       "                       [-0.0165, -0.0213,  0.0079]],\n",
       "              \n",
       "                      [[-0.0118,  0.0041,  0.0039],\n",
       "                       [-0.0221, -0.0115,  0.0176],\n",
       "                       [-0.0228,  0.0242,  0.0203],\n",
       "                       ...,\n",
       "                       [-0.0012,  0.0109, -0.0225],\n",
       "                       [-0.0059,  0.0179, -0.0192],\n",
       "                       [ 0.0008,  0.0177,  0.0151]],\n",
       "              \n",
       "                      [[-0.0103,  0.0094,  0.0022],\n",
       "                       [-0.0184,  0.0108, -0.0233],\n",
       "                       [-0.0066, -0.0225,  0.0185],\n",
       "                       ...,\n",
       "                       [ 0.0203,  0.0189, -0.0081],\n",
       "                       [-0.0129,  0.0244, -0.0251],\n",
       "                       [ 0.0080, -0.0050,  0.0245]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0178, -0.0209,  0.0037],\n",
       "                       [ 0.0198, -0.0153, -0.0163],\n",
       "                       [ 0.0010, -0.0030,  0.0017],\n",
       "                       ...,\n",
       "                       [-0.0008,  0.0046, -0.0047],\n",
       "                       [-0.0140, -0.0230, -0.0075],\n",
       "                       [ 0.0131, -0.0158, -0.0205]],\n",
       "              \n",
       "                      [[ 0.0091, -0.0021,  0.0240],\n",
       "                       [-0.0194,  0.0024, -0.0162],\n",
       "                       [-0.0191,  0.0019, -0.0200],\n",
       "                       ...,\n",
       "                       [-0.0169, -0.0233, -0.0070],\n",
       "                       [ 0.0179, -0.0085,  0.0125],\n",
       "                       [ 0.0192,  0.0039,  0.0015]],\n",
       "              \n",
       "                      [[-0.0039,  0.0050, -0.0069],\n",
       "                       [-0.0191,  0.0021, -0.0016],\n",
       "                       [ 0.0061,  0.0224,  0.0034],\n",
       "                       ...,\n",
       "                       [-0.0121,  0.0103,  0.0191],\n",
       "                       [-0.0128, -0.0168,  0.0133],\n",
       "                       [-0.0098, -0.0139,  0.0092]]])),\n",
       "             ('__S__.tdnn3.0.bias',\n",
       "              tensor([-2.2601e-02, -3.8762e-03,  3.3697e-03,  4.4517e-03,  4.8219e-03,\n",
       "                       2.0293e-03, -7.4470e-03, -1.0319e-02, -1.2063e-02,  2.1350e-03,\n",
       "                       2.3954e-02, -1.9183e-02,  9.8305e-03,  8.1325e-04, -1.6426e-02,\n",
       "                      -1.5857e-02,  1.7180e-02, -1.4932e-02, -5.9951e-03,  1.3610e-02,\n",
       "                      -3.5420e-03,  3.5968e-03, -1.6474e-02,  1.6798e-02, -2.1174e-02,\n",
       "                      -1.0885e-02, -1.5937e-02, -1.7538e-02,  1.1635e-03, -1.9036e-03,\n",
       "                       3.0145e-03,  6.9190e-03, -1.0986e-02,  2.5208e-02,  1.6609e-02,\n",
       "                      -8.9742e-03, -9.4197e-03,  1.4880e-02,  1.9096e-02, -3.9555e-03,\n",
       "                       2.1063e-02, -2.5447e-02,  1.6194e-02,  9.1560e-03, -1.2586e-02,\n",
       "                       1.1750e-02,  1.0976e-02, -2.3503e-02,  2.0845e-02,  9.4207e-03,\n",
       "                       1.2033e-02,  2.1159e-02,  1.3190e-02, -8.8513e-03, -1.6639e-02,\n",
       "                      -6.3803e-03, -1.0963e-02, -1.4464e-02, -1.4928e-02,  1.2063e-02,\n",
       "                       8.8372e-03,  1.4489e-02, -2.0762e-02, -1.3215e-02,  1.9491e-02,\n",
       "                       2.1174e-02,  2.0455e-02,  7.8522e-03,  1.1947e-02, -9.6868e-03,\n",
       "                       1.2003e-02, -4.5976e-03,  2.1395e-02, -5.4812e-03, -1.0613e-03,\n",
       "                      -1.2537e-02, -3.9876e-03,  1.4596e-02,  2.2940e-02, -1.7378e-02,\n",
       "                      -2.8606e-03,  1.7135e-04,  7.8554e-03, -1.5792e-02, -3.8008e-03,\n",
       "                      -1.5091e-02,  6.0938e-03, -2.1174e-02, -2.2564e-02, -1.7931e-02,\n",
       "                       2.2138e-02, -1.0661e-02,  2.3635e-02,  1.9605e-02, -2.2306e-02,\n",
       "                      -2.2874e-02,  8.1617e-03, -5.1707e-04, -1.0355e-02,  1.2237e-02,\n",
       "                       6.8230e-03, -5.7056e-03, -2.2204e-02,  1.9300e-02,  1.2902e-02,\n",
       "                      -1.4612e-02,  4.2615e-03,  9.9983e-03,  1.4371e-02, -2.9826e-03,\n",
       "                      -1.1550e-02,  7.1524e-03, -4.8312e-03, -1.3498e-02, -2.4978e-02,\n",
       "                      -9.5320e-03, -2.5419e-02, -1.4105e-02, -3.2404e-03, -1.0801e-02,\n",
       "                      -1.0546e-02,  1.7413e-02,  1.4872e-02,  3.8445e-03,  2.1733e-02,\n",
       "                      -1.8104e-02,  1.1102e-02,  1.4539e-02, -3.9540e-03,  3.2909e-03,\n",
       "                       2.1679e-02,  1.2448e-02,  4.0128e-04,  4.9261e-03, -1.0304e-02,\n",
       "                      -1.0842e-02,  1.9794e-02,  2.4776e-02,  2.3794e-02, -3.0890e-03,\n",
       "                       2.5026e-02, -2.1832e-02, -2.1268e-04,  1.0448e-02, -8.5664e-03,\n",
       "                       6.7025e-03,  2.0029e-02, -2.5088e-02, -9.2922e-03, -2.2903e-02,\n",
       "                       1.5497e-02,  1.1287e-02, -2.0997e-02,  6.4860e-03, -5.3903e-03,\n",
       "                       1.2409e-02, -2.9595e-03,  1.2223e-02, -1.8576e-04, -7.3416e-03,\n",
       "                      -8.0846e-03, -3.1198e-03,  2.9917e-03, -9.2033e-04, -2.3751e-02,\n",
       "                       1.6790e-02,  1.6125e-03, -1.8061e-02,  6.7311e-03, -1.4120e-03,\n",
       "                       1.0349e-02, -2.4983e-02,  1.7725e-02,  1.7637e-02, -7.4579e-04,\n",
       "                      -2.0063e-02,  6.7935e-03, -1.4256e-02,  1.3856e-02, -2.1316e-02,\n",
       "                      -5.9798e-03,  1.7938e-02, -2.4791e-02, -2.1314e-02,  2.5461e-02,\n",
       "                       1.6386e-02,  8.7120e-03, -1.2340e-02,  1.0240e-02,  2.1145e-02,\n",
       "                       1.9590e-02,  1.7399e-02, -1.3619e-04, -5.0606e-03,  5.7608e-04,\n",
       "                      -8.1125e-03, -1.3552e-02,  8.1082e-04,  2.1526e-02,  7.0061e-03,\n",
       "                      -2.3285e-02, -9.1774e-03, -1.4762e-02,  1.5736e-02,  1.9833e-02,\n",
       "                      -2.2074e-02, -1.8856e-02,  3.6536e-03,  1.4594e-02,  1.5593e-02,\n",
       "                       2.0486e-02, -1.4410e-02, -3.1757e-03,  1.9905e-03, -3.4839e-03,\n",
       "                       9.5239e-03,  1.0045e-02, -1.9861e-02, -1.0834e-02, -5.4680e-05,\n",
       "                      -2.5002e-02,  3.6168e-03, -2.1132e-02, -8.4794e-03,  7.8348e-03,\n",
       "                       2.3225e-02,  1.5407e-02, -4.8016e-03, -1.3011e-02,  7.8205e-03,\n",
       "                      -2.4247e-02, -3.6600e-03,  2.2119e-02, -2.3281e-02, -1.1587e-02,\n",
       "                      -5.7926e-03, -1.2657e-02,  1.0073e-02, -2.0285e-02,  1.2949e-02,\n",
       "                      -1.0213e-02,  1.2539e-02, -7.7986e-03, -1.6004e-02, -6.3676e-03,\n",
       "                       1.5746e-02,  5.5768e-03, -1.8041e-02,  1.4096e-02,  5.9269e-04,\n",
       "                      -6.1763e-03,  1.5410e-02,  6.5497e-03, -1.6260e-02, -1.6813e-02,\n",
       "                       2.0994e-03,  7.9001e-03, -1.7722e-02, -9.6670e-03, -2.3238e-02,\n",
       "                      -2.5497e-02, -4.7793e-03,  1.8747e-02,  2.2392e-02,  1.5180e-02,\n",
       "                       2.3847e-02, -1.7832e-02,  1.1738e-02,  2.3423e-02, -1.9616e-02,\n",
       "                       2.2189e-02,  7.8885e-03, -2.3102e-02, -4.5879e-03, -1.5300e-02,\n",
       "                      -5.7948e-03, -8.3203e-03, -1.8798e-02,  2.4812e-02,  1.6801e-02,\n",
       "                      -1.5480e-03, -1.0918e-02, -1.5810e-02, -2.0950e-02, -2.5385e-02,\n",
       "                       3.8341e-03, -2.2267e-02, -1.3967e-03,  6.8777e-03,  7.4658e-04,\n",
       "                       1.3178e-02,  7.8954e-03,  8.3044e-03,  4.7887e-03,  1.2558e-02,\n",
       "                       2.4760e-02,  2.4834e-03,  4.0910e-03, -2.1307e-02,  2.0086e-02,\n",
       "                       1.2443e-03,  5.6497e-04,  1.9583e-02,  1.1659e-02, -1.3871e-02,\n",
       "                       2.3285e-02, -8.9017e-03, -1.0995e-02, -1.0121e-02,  5.3366e-03,\n",
       "                      -7.4986e-03, -2.1392e-02, -2.1119e-02, -2.4709e-02,  1.1931e-02,\n",
       "                       2.1518e-02,  8.8515e-03, -1.8802e-02, -9.4775e-03,  9.5812e-03,\n",
       "                       1.2697e-02,  8.9736e-03,  1.4154e-02, -1.9564e-02,  2.0681e-02,\n",
       "                       1.4188e-02,  2.3692e-02, -8.1231e-03, -1.1903e-02, -2.0180e-02,\n",
       "                      -2.2698e-02,  1.8216e-02,  1.7578e-05,  7.1059e-03,  1.9199e-02,\n",
       "                      -2.0264e-02, -9.0161e-03,  1.8790e-02, -1.6193e-02, -1.1524e-03,\n",
       "                      -3.6202e-05, -2.3931e-02,  1.0962e-02,  2.1133e-03,  1.7792e-02,\n",
       "                       1.4340e-02, -1.4286e-02,  1.3403e-02, -1.2444e-02, -7.8574e-03,\n",
       "                       7.6194e-03,  3.3333e-03,  1.8063e-02, -1.7247e-02,  1.1642e-02,\n",
       "                       1.4148e-02,  2.0241e-02,  1.4131e-02,  1.1988e-02, -1.8255e-02,\n",
       "                       5.1446e-03, -2.0562e-03, -8.1819e-04, -4.7332e-03,  1.4576e-02,\n",
       "                      -2.3944e-02,  1.8521e-02,  2.0032e-02,  9.9497e-03, -1.3807e-02,\n",
       "                      -1.0317e-03,  9.8103e-03, -9.4638e-03, -5.4793e-03,  2.0663e-02,\n",
       "                      -1.6271e-02, -2.2825e-02, -4.9688e-03, -1.7008e-02, -2.0832e-02,\n",
       "                       2.0663e-02, -1.3890e-02, -2.4789e-02, -2.5443e-02,  2.3578e-02,\n",
       "                      -1.9585e-02, -4.3555e-04, -2.3285e-02,  1.3480e-02, -2.3654e-02,\n",
       "                       2.1416e-02, -7.3319e-03, -2.3788e-02, -7.3927e-03, -3.9029e-03,\n",
       "                       2.0051e-02, -1.6857e-02,  2.5074e-02, -1.8191e-02,  7.6259e-03,\n",
       "                       5.1879e-03, -1.6905e-02, -1.7273e-03,  1.8219e-03,  9.9717e-03,\n",
       "                       3.8754e-03,  1.6902e-02, -5.6131e-03,  4.7569e-03, -1.5454e-02,\n",
       "                       2.2951e-02,  1.7261e-02,  6.1743e-03, -2.4627e-04,  6.3318e-03,\n",
       "                       2.1959e-02,  1.1858e-02, -1.2683e-03,  1.3460e-02,  2.4521e-02,\n",
       "                       2.5640e-03,  2.4161e-02, -1.4085e-03,  1.3474e-02,  1.0281e-02,\n",
       "                       2.0366e-02, -2.0133e-02,  1.8657e-02, -2.2846e-02, -2.3879e-02,\n",
       "                       1.4762e-02, -2.7277e-03,  1.7620e-02,  1.6483e-02, -1.8457e-02,\n",
       "                      -2.1519e-02,  1.1146e-02, -1.6067e-02, -2.9458e-03, -3.2326e-03,\n",
       "                       1.7140e-03, -3.6957e-03,  3.3231e-03, -9.1342e-03, -3.7684e-03,\n",
       "                       1.1891e-02,  2.0576e-02,  2.1636e-02,  1.1915e-02, -6.3280e-03,\n",
       "                       1.8136e-02, -1.3064e-02,  5.5319e-03, -2.2187e-02,  1.8720e-04,\n",
       "                       1.9529e-02,  3.6148e-03,  2.4075e-02, -9.6008e-03,  1.7036e-04,\n",
       "                      -1.0401e-02, -1.8021e-02, -3.7382e-03,  2.4679e-02, -7.2719e-03,\n",
       "                       9.1436e-03,  3.8174e-03, -4.7193e-03, -1.4345e-02, -2.5430e-02,\n",
       "                      -2.0612e-02,  2.2033e-02, -1.8103e-02,  1.0685e-02,  2.1724e-03,\n",
       "                      -1.5186e-02, -1.4375e-02,  2.3949e-03, -9.1202e-03, -2.9944e-03,\n",
       "                       7.0771e-05,  2.2133e-02,  1.5544e-02, -3.9801e-04, -9.3464e-03,\n",
       "                       8.8630e-03,  2.3889e-02, -1.0486e-02, -1.6026e-02, -1.3433e-02,\n",
       "                       1.8756e-02, -1.5501e-02,  2.3155e-02,  6.2286e-03,  8.7450e-03,\n",
       "                       6.8904e-03,  1.4150e-02,  1.6630e-02,  1.0005e-02, -5.7465e-03,\n",
       "                      -3.7619e-03, -7.1171e-03, -1.6442e-02, -1.9171e-02, -1.3702e-02,\n",
       "                      -3.1802e-03, -1.6405e-02,  1.5797e-03,  1.4794e-02, -4.5666e-03,\n",
       "                      -6.2521e-03, -1.6091e-02])),\n",
       "             ('__S__.tdnn3.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn3.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn3.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn3.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn3.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn4.0.weight',\n",
       "              tensor([[[ 0.0202],\n",
       "                       [-0.0173],\n",
       "                       [-0.0175],\n",
       "                       ...,\n",
       "                       [-0.0245],\n",
       "                       [-0.0192],\n",
       "                       [-0.0410]],\n",
       "              \n",
       "                      [[-0.0222],\n",
       "                       [ 0.0230],\n",
       "                       [-0.0051],\n",
       "                       ...,\n",
       "                       [ 0.0427],\n",
       "                       [ 0.0275],\n",
       "                       [ 0.0279]],\n",
       "              \n",
       "                      [[-0.0213],\n",
       "                       [-0.0354],\n",
       "                       [ 0.0077],\n",
       "                       ...,\n",
       "                       [ 0.0275],\n",
       "                       [ 0.0349],\n",
       "                       [-0.0359]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0220],\n",
       "                       [-0.0006],\n",
       "                       [-0.0326],\n",
       "                       ...,\n",
       "                       [ 0.0115],\n",
       "                       [ 0.0118],\n",
       "                       [ 0.0028]],\n",
       "              \n",
       "                      [[-0.0278],\n",
       "                       [ 0.0164],\n",
       "                       [-0.0116],\n",
       "                       ...,\n",
       "                       [-0.0349],\n",
       "                       [ 0.0266],\n",
       "                       [ 0.0378]],\n",
       "              \n",
       "                      [[-0.0033],\n",
       "                       [ 0.0311],\n",
       "                       [-0.0131],\n",
       "                       ...,\n",
       "                       [ 0.0417],\n",
       "                       [-0.0433],\n",
       "                       [-0.0063]]])),\n",
       "             ('__S__.tdnn4.0.bias',\n",
       "              tensor([-3.9521e-02, -1.3964e-02, -5.8618e-03, -1.1828e-02,  1.7036e-02,\n",
       "                      -3.2960e-02,  1.7691e-03,  1.1719e-02, -7.2136e-03,  3.8725e-04,\n",
       "                      -2.4402e-02,  1.6353e-02,  8.3455e-03, -2.2517e-02, -2.1743e-02,\n",
       "                       3.9909e-02,  1.1072e-02, -1.4706e-02, -4.4071e-02,  1.7243e-02,\n",
       "                      -2.2479e-02,  3.8230e-02,  2.5368e-02,  2.2699e-02,  1.6840e-02,\n",
       "                      -6.1671e-03,  2.3430e-02,  3.2418e-03, -4.2470e-02, -2.4065e-02,\n",
       "                      -3.4568e-02, -2.4667e-02, -3.6610e-02,  3.4013e-02,  6.2310e-03,\n",
       "                       5.0414e-03, -1.2908e-02,  8.0380e-03, -2.8141e-02,  1.5530e-02,\n",
       "                      -5.5195e-03,  3.0129e-03,  9.3967e-03,  2.0002e-02,  4.1527e-02,\n",
       "                       1.7917e-02,  4.4139e-02, -4.6196e-03,  3.1983e-02,  9.9266e-03,\n",
       "                      -1.9886e-02, -1.1085e-02, -2.6320e-02,  2.8755e-02, -3.9933e-02,\n",
       "                       2.7551e-02,  2.2824e-02, -2.9851e-02, -2.7588e-02, -2.5049e-03,\n",
       "                       2.1449e-02, -2.3188e-02, -2.2580e-02, -1.9647e-03, -3.2997e-02,\n",
       "                      -4.0659e-03, -2.4484e-02, -6.4936e-04,  2.5815e-02,  2.1973e-02,\n",
       "                      -8.2288e-03, -3.9827e-02, -1.6853e-02,  4.3692e-02,  3.5592e-02,\n",
       "                       2.2377e-02,  4.1195e-02, -5.2968e-03, -3.5317e-02,  2.6829e-02,\n",
       "                       3.0681e-02,  4.1176e-02,  3.0817e-02,  7.4884e-03, -9.8538e-03,\n",
       "                       2.2392e-02,  7.0795e-04,  7.7075e-03,  4.0728e-03, -3.5539e-02,\n",
       "                       2.2607e-02, -3.0291e-02,  4.3890e-02,  3.0481e-02, -2.4451e-02,\n",
       "                       2.6951e-02, -1.7527e-02, -3.0061e-02,  3.4751e-02,  3.7448e-04,\n",
       "                      -3.6784e-02, -3.1944e-02,  2.0617e-02,  1.9557e-02, -3.8455e-03,\n",
       "                      -4.1093e-02,  1.5691e-02, -1.3667e-02,  2.0819e-02,  3.4596e-02,\n",
       "                       1.0457e-03, -6.5855e-03, -7.4990e-03,  1.2416e-02, -7.4223e-03,\n",
       "                       1.9316e-03,  3.3916e-02, -2.2333e-02, -4.0313e-02,  2.2585e-02,\n",
       "                      -3.6825e-02, -1.9322e-02,  3.9437e-02, -7.6470e-03,  7.2620e-03,\n",
       "                       4.0330e-02, -3.6669e-02, -3.5452e-03, -1.0397e-02,  9.1176e-03,\n",
       "                       1.4272e-02,  4.8757e-03,  2.5169e-02,  4.2788e-02, -5.2970e-03,\n",
       "                      -3.7749e-02, -2.7060e-02,  2.1552e-03,  1.4486e-02, -2.9869e-02,\n",
       "                       2.7639e-02, -2.4674e-02,  3.0899e-02, -3.5810e-02,  9.2086e-03,\n",
       "                       4.0748e-02,  3.5959e-02, -3.7505e-02, -3.7186e-02,  1.1982e-02,\n",
       "                       1.9935e-02,  3.9047e-02, -4.3048e-02, -3.5767e-02,  2.5894e-02,\n",
       "                      -2.8207e-02,  3.5305e-02,  7.0999e-04, -1.9609e-02, -1.2114e-02,\n",
       "                       1.4795e-03, -5.7700e-03, -4.1595e-02, -4.3823e-02,  2.5801e-02,\n",
       "                      -8.9345e-03,  2.4052e-02,  2.2221e-03,  4.2612e-02, -2.4605e-02,\n",
       "                       8.9763e-03, -3.2922e-02, -2.3218e-02, -3.8887e-02,  2.8612e-02,\n",
       "                      -2.0098e-02, -1.2955e-02, -1.6202e-02, -9.0409e-03,  5.3171e-03,\n",
       "                      -8.9959e-03, -2.5277e-02,  3.1513e-02, -1.9969e-02, -3.8689e-02,\n",
       "                      -4.3038e-02, -3.2809e-02,  4.0176e-02,  2.8451e-02, -1.2894e-02,\n",
       "                      -2.6763e-02,  2.8733e-03,  2.5885e-02,  2.6327e-02,  2.5144e-02,\n",
       "                       1.1239e-02,  6.5606e-03, -2.1276e-03,  2.2919e-02, -3.7771e-02,\n",
       "                       3.9726e-02, -4.3352e-02, -4.1698e-02,  1.3385e-02, -1.5596e-02,\n",
       "                       1.0952e-02, -2.6959e-02, -3.0486e-02,  7.7101e-03, -2.9675e-02,\n",
       "                      -1.7148e-02,  3.1716e-02,  2.9144e-03,  2.9590e-02, -4.1186e-02,\n",
       "                      -8.1675e-03, -2.2636e-02,  2.4151e-02, -6.6595e-03,  1.4392e-02,\n",
       "                       4.2879e-02, -3.9360e-02, -1.0424e-02, -6.2076e-03,  6.3926e-04,\n",
       "                       2.6553e-06,  1.2715e-02,  1.6164e-02,  6.5457e-04,  3.7942e-02,\n",
       "                       4.2867e-02,  2.2610e-02, -1.6393e-02,  2.1763e-02, -1.6172e-02,\n",
       "                      -2.0853e-02, -3.1756e-02, -3.6017e-03, -6.7043e-03,  7.9934e-04,\n",
       "                      -2.6433e-02,  1.5433e-02, -3.5738e-02, -4.1740e-02,  3.7924e-02,\n",
       "                      -2.3842e-02,  3.9347e-02,  1.1469e-02, -3.5631e-02, -3.6123e-02,\n",
       "                      -8.5721e-03,  1.2621e-02,  1.6850e-02, -1.3785e-02,  3.8712e-02,\n",
       "                       4.5542e-03, -2.0739e-03,  1.5983e-03,  1.6469e-02, -2.0746e-03,\n",
       "                      -8.9429e-03,  1.7788e-02,  1.3988e-02, -3.5315e-02,  2.1591e-03,\n",
       "                       6.5030e-04,  5.2022e-03, -1.8971e-02,  8.6891e-03, -4.2265e-02,\n",
       "                      -2.8781e-02, -2.1885e-02, -1.9439e-02, -1.5539e-02, -3.8935e-02,\n",
       "                      -2.7044e-02, -2.7033e-02, -1.7785e-02, -2.5535e-02,  2.1723e-03,\n",
       "                       4.3042e-02,  3.9042e-02,  1.4768e-02, -4.0979e-02, -1.0971e-02,\n",
       "                      -4.3522e-02,  3.7301e-02,  2.5817e-02, -3.8092e-02,  2.3361e-02,\n",
       "                      -2.2811e-02, -1.8811e-02,  9.5936e-03, -2.9924e-02,  7.4870e-03,\n",
       "                      -4.3482e-02, -5.4137e-03,  2.9212e-02,  1.8176e-02,  4.2388e-02,\n",
       "                       2.2601e-03, -2.6682e-02,  2.5432e-03,  1.5482e-02,  3.2234e-02,\n",
       "                      -2.1457e-02, -4.0758e-02,  5.7415e-04,  8.6478e-03,  7.4995e-03,\n",
       "                      -2.9695e-02, -2.5171e-03, -3.4790e-02, -2.6186e-02,  5.0249e-03,\n",
       "                      -3.8415e-02,  2.4952e-02,  1.6696e-03,  2.0034e-02, -3.4579e-04,\n",
       "                       2.0316e-02, -3.9186e-02,  2.0465e-02,  3.2908e-02,  4.3616e-02,\n",
       "                       1.0071e-03, -3.9423e-02, -2.4873e-02, -3.6809e-02,  3.6965e-02,\n",
       "                      -2.9297e-02,  2.8074e-02, -1.6178e-02, -2.3990e-02,  2.0379e-02,\n",
       "                       2.3435e-02, -6.7641e-03, -4.3818e-02, -3.2831e-02,  3.5420e-02,\n",
       "                       3.5989e-02,  2.8603e-02, -3.2104e-02, -2.0151e-02,  1.7828e-02,\n",
       "                      -1.7554e-02, -3.0170e-02, -5.9291e-03, -4.1329e-02,  4.1625e-02,\n",
       "                      -1.4843e-02,  1.3538e-02, -2.5894e-03, -2.1016e-02, -1.5050e-02,\n",
       "                      -2.9481e-02,  1.0258e-02, -2.7488e-02, -2.2468e-03,  1.9959e-02,\n",
       "                      -3.3678e-02, -3.9367e-02,  2.5470e-02, -5.6959e-03,  1.9395e-02,\n",
       "                      -4.2826e-02,  4.4108e-02, -3.6174e-02,  2.5144e-03, -2.0158e-02,\n",
       "                       2.0522e-02,  2.8464e-02,  2.9977e-02, -1.6377e-02, -5.7612e-03,\n",
       "                      -3.6401e-03,  1.7553e-02,  1.0839e-02, -2.0058e-02,  7.3047e-03,\n",
       "                      -3.0235e-02,  2.1001e-02, -3.8725e-02, -3.5970e-02, -1.5564e-02,\n",
       "                      -2.0424e-02, -1.4629e-02,  5.2306e-04, -2.3617e-02, -1.0120e-04,\n",
       "                      -3.4833e-02, -3.7002e-02,  3.6201e-02, -1.7146e-02,  3.2178e-02,\n",
       "                      -3.9860e-03, -3.8684e-02, -1.2871e-02, -4.2824e-02,  3.3360e-02,\n",
       "                      -5.0488e-03,  6.2711e-03, -2.8112e-02, -3.9143e-02,  1.7675e-03,\n",
       "                      -4.1675e-02,  2.2835e-02, -3.7505e-02,  4.1249e-02,  4.3742e-02,\n",
       "                      -2.4258e-02,  3.4525e-02, -2.9333e-02,  2.7352e-02, -2.6444e-02,\n",
       "                       3.9394e-02,  2.2775e-02, -2.3315e-02, -4.2466e-02, -2.4536e-02,\n",
       "                      -3.3627e-02,  3.6052e-02,  3.2263e-02,  2.9398e-02, -1.9969e-02,\n",
       "                       3.2223e-02,  2.0694e-02, -3.0176e-02, -2.3416e-02,  2.3037e-02,\n",
       "                      -1.6820e-02,  2.7209e-02,  4.2328e-02,  3.4410e-02,  2.4142e-02,\n",
       "                      -1.5842e-02, -9.5929e-03, -2.7161e-02,  4.2949e-02, -1.1869e-02,\n",
       "                       8.3619e-03,  2.6464e-02,  2.6247e-02, -2.5737e-02,  1.9616e-02,\n",
       "                      -3.6112e-02,  3.4172e-02, -1.3108e-02,  3.9197e-02, -6.2959e-03,\n",
       "                       5.4154e-03,  2.9941e-03, -1.0623e-02, -2.4471e-02, -5.5058e-03,\n",
       "                      -4.5500e-03,  3.7988e-02, -3.3964e-02, -2.2443e-02,  1.6194e-02,\n",
       "                       3.4872e-02,  2.6405e-02,  8.7336e-03, -4.2351e-03,  3.2777e-02,\n",
       "                       1.6281e-02,  2.1749e-02,  5.4855e-03, -2.5098e-02,  9.2174e-04,\n",
       "                       2.1761e-03,  3.2563e-02, -2.2796e-02,  3.9475e-02, -1.8014e-02,\n",
       "                      -6.0217e-03, -2.6841e-02,  1.9047e-03, -1.1580e-03,  1.0494e-02,\n",
       "                       3.1037e-03,  2.0600e-02,  1.5304e-02, -2.2692e-02,  4.0857e-02,\n",
       "                      -2.9509e-02,  1.9164e-02, -3.3144e-02, -3.1607e-03,  2.9906e-03,\n",
       "                      -3.2901e-02,  3.8913e-02,  3.0443e-02, -9.7022e-04,  2.9788e-02,\n",
       "                       1.0222e-02,  4.3473e-02,  3.7400e-02,  3.3907e-03, -3.8639e-02,\n",
       "                       2.6508e-02, -3.5372e-02, -2.3559e-02,  4.2005e-02,  2.0017e-02,\n",
       "                       2.0691e-03,  2.0162e-02,  4.3980e-02, -2.1227e-03,  3.2621e-02,\n",
       "                       3.5281e-02, -2.6309e-02])),\n",
       "             ('__S__.tdnn4.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn4.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn4.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn4.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn4.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn5.0.weight',\n",
       "              tensor([[[-0.0229],\n",
       "                       [-0.0125],\n",
       "                       [-0.0374],\n",
       "                       ...,\n",
       "                       [ 0.0240],\n",
       "                       [-0.0126],\n",
       "                       [-0.0370]],\n",
       "              \n",
       "                      [[ 0.0381],\n",
       "                       [ 0.0340],\n",
       "                       [-0.0165],\n",
       "                       ...,\n",
       "                       [ 0.0389],\n",
       "                       [ 0.0102],\n",
       "                       [-0.0348]],\n",
       "              \n",
       "                      [[ 0.0428],\n",
       "                       [-0.0103],\n",
       "                       [ 0.0364],\n",
       "                       ...,\n",
       "                       [-0.0332],\n",
       "                       [ 0.0371],\n",
       "                       [ 0.0032]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0034],\n",
       "                       [-0.0260],\n",
       "                       [ 0.0192],\n",
       "                       ...,\n",
       "                       [ 0.0229],\n",
       "                       [ 0.0100],\n",
       "                       [-0.0009]],\n",
       "              \n",
       "                      [[-0.0025],\n",
       "                       [-0.0180],\n",
       "                       [ 0.0239],\n",
       "                       ...,\n",
       "                       [-0.0236],\n",
       "                       [ 0.0348],\n",
       "                       [ 0.0224]],\n",
       "              \n",
       "                      [[ 0.0194],\n",
       "                       [-0.0252],\n",
       "                       [-0.0432],\n",
       "                       ...,\n",
       "                       [-0.0340],\n",
       "                       [-0.0135],\n",
       "                       [-0.0011]]])),\n",
       "             ('__S__.tdnn5.0.bias',\n",
       "              tensor([-0.0334,  0.0098,  0.0440,  ..., -0.0017, -0.0268,  0.0320])),\n",
       "             ('__S__.tdnn5.2.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])),\n",
       "             ('__S__.tdnn5.2.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('__S__.tdnn5.2.running_mean',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('__S__.tdnn5.2.running_var',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.])),\n",
       "             ('__S__.tdnn5.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.pooling.linear1.weight',\n",
       "              tensor([[[-0.0004],\n",
       "                       [-0.0048],\n",
       "                       [-0.0021],\n",
       "                       ...,\n",
       "                       [-0.0001],\n",
       "                       [ 0.0091],\n",
       "                       [ 0.0068]],\n",
       "              \n",
       "                      [[-0.0111],\n",
       "                       [ 0.0021],\n",
       "                       [ 0.0036],\n",
       "                       ...,\n",
       "                       [ 0.0016],\n",
       "                       [-0.0147],\n",
       "                       [-0.0021]],\n",
       "              \n",
       "                      [[-0.0031],\n",
       "                       [-0.0145],\n",
       "                       [ 0.0233],\n",
       "                       ...,\n",
       "                       [ 0.0047],\n",
       "                       [-0.0184],\n",
       "                       [-0.0029]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0231],\n",
       "                       [ 0.0105],\n",
       "                       [ 0.0034],\n",
       "                       ...,\n",
       "                       [-0.0244],\n",
       "                       [ 0.0113],\n",
       "                       [-0.0126]],\n",
       "              \n",
       "                      [[ 0.0147],\n",
       "                       [ 0.0161],\n",
       "                       [-0.0087],\n",
       "                       ...,\n",
       "                       [ 0.0245],\n",
       "                       [-0.0126],\n",
       "                       [-0.0209]],\n",
       "              \n",
       "                      [[ 0.0050],\n",
       "                       [ 0.0223],\n",
       "                       [ 0.0014],\n",
       "                       ...,\n",
       "                       [ 0.0157],\n",
       "                       [ 0.0196],\n",
       "                       [-0.0016]]])),\n",
       "             ('__S__.pooling.linear1.bias',\n",
       "              tensor([ 1.1690e-03, -2.9569e-03, -2.4084e-02,  2.1898e-02, -1.5069e-02,\n",
       "                       1.2164e-02,  1.1746e-02,  1.7477e-03,  1.9293e-02, -2.2257e-02,\n",
       "                       9.4038e-04, -3.8836e-03,  1.3968e-03,  1.9127e-02, -7.7005e-03,\n",
       "                      -1.2250e-02, -1.1025e-03, -1.3980e-02, -2.2869e-02, -2.5340e-02,\n",
       "                      -2.7671e-03, -2.6237e-03,  2.2916e-02,  7.2109e-03, -2.5177e-02,\n",
       "                      -7.5660e-03,  1.0588e-02, -2.4560e-02, -1.0035e-02,  9.0492e-03,\n",
       "                      -1.3856e-02, -2.5473e-03,  1.7109e-02,  8.5650e-03, -9.1047e-03,\n",
       "                      -5.9214e-03,  4.9649e-03,  1.9471e-02,  4.5044e-04,  7.8715e-03,\n",
       "                      -1.9609e-02, -2.4754e-02,  2.5264e-02,  8.2206e-03, -1.2271e-03,\n",
       "                      -2.5456e-03, -6.2811e-03, -2.1334e-02, -4.6197e-03, -3.2599e-03,\n",
       "                      -2.5386e-02, -9.9041e-03,  1.8512e-02,  8.2638e-03,  4.0762e-03,\n",
       "                      -1.9350e-02, -2.5522e-02,  1.2760e-02,  1.5920e-03, -2.0741e-02,\n",
       "                       1.5455e-02, -2.1972e-02,  1.6640e-02,  2.6467e-03,  1.8629e-02,\n",
       "                       2.1856e-02, -1.2141e-02,  2.0111e-02,  4.6604e-03, -1.3793e-03,\n",
       "                       1.0662e-02,  1.9564e-02, -7.1969e-03,  1.1944e-02, -1.8457e-02,\n",
       "                      -2.1197e-02, -1.3911e-02, -1.4849e-02,  2.0356e-02,  2.1073e-02,\n",
       "                       5.8554e-03,  1.7099e-02,  9.9753e-03,  1.0322e-02, -1.5015e-02,\n",
       "                       1.3678e-03, -5.8369e-03,  1.4446e-02, -2.4480e-02,  1.2548e-02,\n",
       "                       1.6893e-02,  1.1416e-02, -7.2285e-04,  2.0359e-02,  2.0938e-02,\n",
       "                       2.6932e-03,  2.4562e-02,  1.0536e-02, -1.8561e-02, -2.5184e-02,\n",
       "                       6.9061e-03,  1.2162e-02,  1.1877e-02, -6.9634e-03, -5.2372e-03,\n",
       "                      -1.7865e-02, -2.4682e-03,  1.9801e-05,  4.6449e-04, -1.3092e-02,\n",
       "                      -6.5373e-03,  9.0358e-03,  6.3959e-03,  1.9784e-02,  1.9872e-02,\n",
       "                      -1.1820e-02,  5.7718e-03,  1.4543e-03, -9.7804e-03, -2.0106e-02,\n",
       "                      -1.8136e-02,  5.6104e-03, -5.2767e-03, -1.1757e-02,  2.7971e-03,\n",
       "                       2.7896e-03,  8.6078e-03,  4.4473e-03])),\n",
       "             ('__S__.pooling.linear2.weight',\n",
       "              tensor([[[-0.0046],\n",
       "                       [ 0.0671],\n",
       "                       [-0.0155],\n",
       "                       ...,\n",
       "                       [ 0.0283],\n",
       "                       [ 0.0428],\n",
       "                       [ 0.0751]],\n",
       "              \n",
       "                      [[-0.0151],\n",
       "                       [-0.0331],\n",
       "                       [-0.0451],\n",
       "                       ...,\n",
       "                       [ 0.0285],\n",
       "                       [-0.0702],\n",
       "                       [-0.0036]],\n",
       "              \n",
       "                      [[-0.0171],\n",
       "                       [-0.0342],\n",
       "                       [ 0.0608],\n",
       "                       ...,\n",
       "                       [-0.0393],\n",
       "                       [ 0.0500],\n",
       "                       [-0.0492]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0598],\n",
       "                       [ 0.0151],\n",
       "                       [-0.0041],\n",
       "                       ...,\n",
       "                       [ 0.0804],\n",
       "                       [-0.0602],\n",
       "                       [ 0.0477]],\n",
       "              \n",
       "                      [[-0.0001],\n",
       "                       [-0.0472],\n",
       "                       [-0.0582],\n",
       "                       ...,\n",
       "                       [-0.0184],\n",
       "                       [ 0.0716],\n",
       "                       [-0.0464]],\n",
       "              \n",
       "                      [[ 0.0560],\n",
       "                       [-0.0700],\n",
       "                       [-0.0505],\n",
       "                       ...,\n",
       "                       [ 0.0848],\n",
       "                       [ 0.0723],\n",
       "                       [-0.0073]]])),\n",
       "             ('__S__.pooling.linear2.bias',\n",
       "              tensor([ 0.0500,  0.0571,  0.0409,  ..., -0.0336, -0.0320, -0.0404])),\n",
       "             ('__S__.embedding_layer1.linear.weight',\n",
       "              tensor([[ 0.0070,  0.0109, -0.0029,  ...,  0.0151, -0.0126,  0.0124],\n",
       "                      [-0.0042, -0.0144,  0.0118,  ...,  0.0046, -0.0158, -0.0024],\n",
       "                      [-0.0155, -0.0104, -0.0088,  ..., -0.0048, -0.0061,  0.0089],\n",
       "                      ...,\n",
       "                      [ 0.0176,  0.0093, -0.0147,  ..., -0.0015,  0.0028, -0.0012],\n",
       "                      [ 0.0031,  0.0011,  0.0057,  ..., -0.0132,  0.0086,  0.0012],\n",
       "                      [-0.0078, -0.0066, -0.0112,  ...,  0.0169, -0.0008,  0.0141]])),\n",
       "             ('__S__.embedding_layer1.linear.bias',\n",
       "              tensor([-1.0349e-02, -1.7972e-02,  1.7249e-02,  1.4870e-02,  9.9584e-03,\n",
       "                      -1.5486e-02,  3.8871e-03,  1.2742e-02, -1.4397e-02, -1.7714e-02,\n",
       "                      -1.1004e-02, -1.7119e-02, -3.5033e-03, -2.9436e-03,  9.4609e-04,\n",
       "                      -9.6580e-03,  1.3120e-02,  1.3958e-02, -5.2743e-03, -1.3442e-02,\n",
       "                      -5.3794e-04,  2.5785e-03, -5.5474e-03, -1.0862e-02,  3.3420e-03,\n",
       "                       8.4271e-03, -4.3764e-03,  6.4858e-03, -6.8555e-03,  5.7438e-03,\n",
       "                      -1.3499e-02,  5.0019e-03,  1.3434e-02,  2.4432e-03,  1.7515e-02,\n",
       "                       1.3908e-02,  5.0184e-03, -6.7034e-04, -1.7539e-02,  4.8698e-03,\n",
       "                      -1.4642e-02, -8.4949e-03,  7.2557e-03,  1.8161e-02,  1.3053e-02,\n",
       "                       6.4032e-03, -5.5115e-03,  1.0247e-02, -1.6862e-03, -1.5463e-02,\n",
       "                      -1.3256e-02, -6.7334e-03,  1.7349e-02, -1.7340e-02,  4.0732e-05,\n",
       "                      -1.7362e-02,  1.1759e-02,  1.2885e-02,  5.8442e-03,  8.6430e-03,\n",
       "                      -7.0206e-04,  9.2753e-03,  1.1053e-02,  6.7893e-03,  1.4063e-02,\n",
       "                      -2.4761e-03, -1.6334e-02,  1.2895e-02, -5.6168e-03,  1.3502e-02,\n",
       "                       1.5774e-02, -2.9390e-03,  1.5313e-02,  1.1735e-02, -1.1822e-02,\n",
       "                      -8.2481e-03, -1.6153e-02,  7.7252e-03, -5.1074e-03,  2.2907e-03,\n",
       "                       1.0183e-02,  7.9087e-03, -1.1379e-02, -6.0890e-03,  1.5366e-02,\n",
       "                      -1.0474e-02,  6.6609e-03,  1.2746e-02,  1.3932e-02, -1.3021e-03,\n",
       "                       2.5392e-03,  2.9697e-03, -7.2156e-03,  1.2879e-02,  1.4856e-02,\n",
       "                      -9.8424e-03,  2.2375e-03, -6.2086e-03,  1.4080e-02, -2.4572e-03,\n",
       "                       1.1103e-02, -9.7863e-04, -1.4057e-02, -4.1303e-03,  8.5761e-03,\n",
       "                      -1.7040e-02,  1.8810e-03,  1.6777e-02, -1.5836e-02, -1.7882e-02,\n",
       "                       1.7345e-02,  1.5125e-02, -4.1963e-03, -7.5611e-03,  1.6779e-02,\n",
       "                      -1.5003e-02, -1.6691e-02, -3.1231e-03,  3.0470e-03, -1.4490e-02,\n",
       "                       2.9487e-03, -2.7787e-03,  1.2794e-02, -5.0551e-03,  9.1710e-03,\n",
       "                       8.5885e-03,  1.0121e-02,  1.4734e-02,  1.1210e-02,  2.6850e-03,\n",
       "                      -5.0584e-03,  1.3950e-02,  2.5412e-04, -8.8646e-03,  8.0690e-03,\n",
       "                      -2.4214e-03,  1.5722e-02, -6.5616e-03,  3.9569e-03, -1.0896e-02,\n",
       "                      -9.1125e-03,  1.7793e-02,  9.6051e-03,  6.3442e-03,  8.0714e-03,\n",
       "                       4.0336e-03, -1.7603e-02,  8.3497e-04,  1.5526e-04,  3.5042e-04,\n",
       "                      -1.2190e-02,  1.3428e-03, -1.7037e-02,  5.2623e-03, -1.2302e-02,\n",
       "                      -6.1150e-03, -1.7345e-02, -1.2093e-02,  3.1441e-03,  9.2207e-03,\n",
       "                       1.0255e-02,  1.2777e-02, -2.9669e-03,  1.2361e-02,  1.2395e-02,\n",
       "                       5.6799e-03, -9.3067e-03,  1.5533e-02, -5.6200e-03, -3.9354e-03,\n",
       "                      -1.6030e-02,  1.1848e-03,  1.5296e-02, -1.0602e-02,  6.2509e-03,\n",
       "                      -2.4574e-03, -1.5326e-02, -1.1856e-02, -1.5397e-02, -4.1111e-03,\n",
       "                       1.0579e-02, -8.2224e-03, -1.5633e-02,  1.2613e-02,  1.6264e-02,\n",
       "                       3.5068e-03,  3.7387e-03, -2.7682e-03, -1.4333e-02, -5.4606e-03,\n",
       "                       1.1248e-02, -1.5572e-02])),\n",
       "             ('__S__.embedding_layer1.batchnorm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('__L__.fc.weight',\n",
       "              tensor([[-0.0535,  0.0347,  0.0201,  ..., -0.0365, -0.0007,  0.0472],\n",
       "                      [ 0.0567,  0.0202, -0.0330,  ..., -0.0009,  0.0713, -0.0576],\n",
       "                      [-0.0142, -0.0654,  0.0437,  ...,  0.0399,  0.0240,  0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0469, -0.0623, -0.0647,  ..., -0.0373,  0.0557,  0.0547],\n",
       "                      [ 0.0189,  0.0004,  0.0574,  ..., -0.0483, -0.0125,  0.0266],\n",
       "                      [-0.0006,  0.0400,  0.0575,  ...,  0.0444,  0.0639,  0.0099]])),\n",
       "             ('__L__.fc.bias',\n",
       "              tensor([-0.0186, -0.0333, -0.0554,  ...,  0.0284,  0.0671,  0.0522]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DatasetLoader import get_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(dataset_file_name='/nvme/zhiyong/sdsv21/vox2_trainlist.txt', batch_size=128, augment=False, musan_path='/nvme/zhiyong/musan_split', rir_path='/nvme/zhiyong/RIRS_NOISES/simulated_rirs', max_frames=300, max_seg_per_spk=10, nDataLoaderThread=4, nPerSpeaker=1, train_path='/nvme/zhiyong/sdsv21', sox_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.28125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5994*10/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = glob.glob('/nvme/zhiyong/CN-Celeb/data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for i in a:\n",
    "    b = glob.glob(i+'/*')\n",
    "    if b[0].split('/')[-1].split('-')[0] == 'interview':\n",
    "        c.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/workspace/train_logs/X_vector_trans/model/model000000134.model'\n",
    "loaded_state = torch.load(path, map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.fc.weight', '__L__.fc.bias', '__L__.encoder_layers.self_attn.in_proj_weight', '__L__.encoder_layers.self_attn.in_proj_bias', '__L__.encoder_layers.self_attn.out_proj.weight', '__L__.encoder_layers.self_attn.out_proj.bias', '__L__.encoder_layers.linear1.weight', '__L__.encoder_layers.linear1.bias', '__L__.encoder_layers.linear2.weight', '__L__.encoder_layers.linear2.bias', '__L__.encoder_layers.norm1.weight', '__L__.encoder_layers.norm1.bias', '__L__.encoder_layers.norm2.weight', '__L__.encoder_layers.norm2.bias', '__L__.transformer_encoder.layers.0.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.0.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.0.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.0.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.0.linear1.weight', '__L__.transformer_encoder.layers.0.linear1.bias', '__L__.transformer_encoder.layers.0.linear2.weight', '__L__.transformer_encoder.layers.0.linear2.bias', '__L__.transformer_encoder.layers.0.norm1.weight', '__L__.transformer_encoder.layers.0.norm1.bias', '__L__.transformer_encoder.layers.0.norm2.weight', '__L__.transformer_encoder.layers.0.norm2.bias', '__L__.transformer_encoder.layers.1.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.1.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.1.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.1.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.1.linear1.weight', '__L__.transformer_encoder.layers.1.linear1.bias', '__L__.transformer_encoder.layers.1.linear2.weight', '__L__.transformer_encoder.layers.1.linear2.bias', '__L__.transformer_encoder.layers.1.norm1.weight', '__L__.transformer_encoder.layers.1.norm1.bias', '__L__.transformer_encoder.layers.1.norm2.weight', '__L__.transformer_encoder.layers.1.norm2.bias'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.W', '__L__.encoder_layers.self_attn.in_proj_weight', '__L__.encoder_layers.self_attn.in_proj_bias', '__L__.encoder_layers.self_attn.out_proj.weight', '__L__.encoder_layers.self_attn.out_proj.bias', '__L__.encoder_layers.linear1.weight', '__L__.encoder_layers.linear1.bias', '__L__.encoder_layers.linear2.weight', '__L__.encoder_layers.linear2.bias', '__L__.encoder_layers.norm1.weight', '__L__.encoder_layers.norm1.bias', '__L__.encoder_layers.norm2.weight', '__L__.encoder_layers.norm2.bias', '__L__.transformer_encoder.layers.0.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.0.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.0.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.0.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.0.linear1.weight', '__L__.transformer_encoder.layers.0.linear1.bias', '__L__.transformer_encoder.layers.0.linear2.weight', '__L__.transformer_encoder.layers.0.linear2.bias', '__L__.transformer_encoder.layers.0.norm1.weight', '__L__.transformer_encoder.layers.0.norm1.bias', '__L__.transformer_encoder.layers.0.norm2.weight', '__L__.transformer_encoder.layers.0.norm2.bias', '__L__.transformer_encoder.layers.1.self_attn.in_proj_weight', '__L__.transformer_encoder.layers.1.self_attn.in_proj_bias', '__L__.transformer_encoder.layers.1.self_attn.out_proj.weight', '__L__.transformer_encoder.layers.1.self_attn.out_proj.bias', '__L__.transformer_encoder.layers.1.linear1.weight', '__L__.transformer_encoder.layers.1.linear1.bias', '__L__.transformer_encoder.layers.1.linear2.weight', '__L__.transformer_encoder.layers.1.linear2.bias', '__L__.transformer_encoder.layers.1.norm1.weight', '__L__.transformer_encoder.layers.1.norm1.bias', '__L__.transformer_encoder.layers.1.norm2.weight', '__L__.transformer_encoder.layers.1.norm2.bias'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParameters(model, path, map_location=\"cuda:0\"):\n",
    "\n",
    "    self_state = model.state_dict()\n",
    "    loaded_state = torch.load(path, map_location=map_location)\n",
    "\n",
    "    for name, param in loaded_state['model'].items():\n",
    "        if name == '__L__.W':\n",
    "            continue\n",
    "        \n",
    "        origname = name\n",
    "        if name not in self_state:\n",
    "            name = name.replace(\"module.\", \"\")\n",
    "            if name not in self_state:\n",
    "                name = \"__S__.\"+name\n",
    "                if name not in self_state:\n",
    "                    print(\"#%s is not in the model.\"%origname)\n",
    "                    continue\n",
    "\n",
    "        if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "            print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "            continue\n",
    "\n",
    "        self_state[name].copy_(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadParameters(s, path, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy, math, pdb, sys, random\n",
    "import time, os, itertools, shutil, importlib\n",
    "\n",
    "from src.DatasetLoader import loadWAV\n",
    "from src.tuneThreshold import tuneThresholdfromScore_std\n",
    "\n",
    "def evaluateFromList(model, listfilename, distance_m='cosine', print_interval=100, test_path='', num_eval=10, eval_frames=0, verbose=True):\n",
    "    assert distance_m in ['L2', 'cosine']\n",
    "    if verbose:\n",
    "        print('Distance metric: %s'%(distance_m))\n",
    "        print('Evaluating from trial file: %s'%(listfilename))\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    lines       = []\n",
    "    files       = []\n",
    "    feats       = {}\n",
    "    tstart      = time.time()\n",
    "\n",
    "    ## Read all lines\n",
    "    with open(listfilename) as listfile:\n",
    "        while True:\n",
    "            line = listfile.readline()\n",
    "            if (not line):\n",
    "                break\n",
    "\n",
    "            data = line.split()\n",
    "\n",
    "            ## Append random label if missing\n",
    "            if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "            files.append(data[1])\n",
    "            files.append(data[2])\n",
    "            lines.append(line)\n",
    "\n",
    "    setfiles = list(set(files))\n",
    "    setfiles.sort()\n",
    "\n",
    "    ## Save all features to file\n",
    "    for idx, file in enumerate(setfiles):\n",
    "\n",
    "        inp1 = torch.FloatTensor(loadWAV(os.path.join(test_path,file), eval_frames, evalmode=True, num_eval=num_eval)).cuda()\n",
    "\n",
    "        ref_feat = model.forward(inp1).detach().cpu()\n",
    "\n",
    "        filename = '%06d.wav'%idx\n",
    "\n",
    "        feats[file] = ref_feat\n",
    "\n",
    "        telapsed = time.time() - tstart\n",
    "\n",
    "        if (idx % print_interval == 0) and verbose:\n",
    "            sys.stdout.write(\"\\rReading %d of %d: %.2f Hz, embedding size %d\"%(idx, len(setfiles), idx/telapsed, ref_feat.size()[1]))\n",
    "\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    all_trials = []\n",
    "    tstart = time.time()\n",
    "\n",
    "    ## Read files and compute all scores\n",
    "    for idx, line in enumerate(lines):\n",
    "\n",
    "        data = line.split()\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "\n",
    "        ref_feat = feats[data[1]]\n",
    "        com_feat = feats[data[2]]\n",
    "        # ref_feat = (feats[data[1]] - mean_vector).cuda() \n",
    "        # com_feat = (feats[data[2]] - mean_vector).cuda()\n",
    "\n",
    "        # if self.__model__.module.__L__.test_normalize:\n",
    "        ref_feat = F.normalize(ref_feat, p=2, dim=1)\n",
    "        com_feat = F.normalize(com_feat, p=2, dim=1)\n",
    "\n",
    "        if distance_m == 'L2':\n",
    "            dist = F.pairwise_distance(ref_feat.unsqueeze(-1), com_feat.unsqueeze(-1).transpose(0,2)).numpy()\n",
    "            score = -1 * numpy.mean(dist)\n",
    "        elif distance_m == 'cosine':\n",
    "            ## [1, emb_size]\n",
    "            dist = F.cosine_similarity(ref_feat.unsqueeze(-1), com_feat.unsqueeze(-1).transpose(0,2)).numpy()\n",
    "            score = numpy.mean(dist)\n",
    "        else:\n",
    "            raise ValueError('Unknown distance metric: %s'%(distance_m))\n",
    "\n",
    "        all_scores.append(score)\n",
    "        all_labels.append(int(data[0]))\n",
    "        all_trials.append(data[1]+\" \"+data[2])\n",
    "\n",
    "        if (idx % (print_interval*100) == 0) and verbose:\n",
    "            telapsed = time.time() - tstart\n",
    "            sys.stdout.write(\"\\rComputing %d of %d: %.2f Hz\"%(idx,len(lines),idx/telapsed))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    result = tuneThresholdfromScore_std(all_scores, all_labels)\n",
    "    print('')\n",
    "    print('EER %2.4f MINC@0.01 %.5f MINC@0.001 %.5f'%(result[1], result[-2], result[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance metric: cosine\n",
      "Evaluating from trial file: /nvme/zhiyong/sdsv21/vox_o_triallist.txt\n",
      "Computing 30000 of 37611: 6605.29 Hzedding size 192\n",
      "EER 2.0469 MINC@0.01 0.23119 MINC@0.001 0.32961\n"
     ]
    }
   ],
   "source": [
    "evaluateFromList(s, '/nvme/zhiyong/sdsv21/vox_o_triallist.txt', distance_m='cosine', print_interval=100, test_path='/nvme/zhiyong/sdsv21', num_eval=10, eval_frames=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('config.yaml') as c:\n",
    "    configs = list(yaml.load_all(c, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.3,\n",
       " 'K': 12,\n",
       " 'R': 50,\n",
       " 'E': 1,\n",
       " 'B': 10,\n",
       " 'criterion': 'torch.nn.CrossEntropyLoss',\n",
       " 'optimizer': 'torch.optim.SGD',\n",
       " 'non_fed_split_training': False,\n",
       " 'centerized_training': False,\n",
       " 'freeze_backbone': False,\n",
       " 'continue_learning_setting': [False, 3, 30],\n",
       " 'stagename_dict': {2: '#3.txt', 3: '#2.txt'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs[2][\"fed_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = configs[0][\"global_config\"]\n",
    "data_config = configs[1][\"data_config\"]\n",
    "fed_config = configs[2][\"fed_config\"]\n",
    "optim_config = configs[3][\"optim_config\"]\n",
    "init_config = configs[4][\"init_config\"]\n",
    "model_config = configs[5][\"model_config\"]\n",
    "log_config = configs[6][\"log_config\"]\n",
    "eval_config = configs[7][\"eval_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/flearn_data/train_list_G1.txt',\n",
       " '/workspace/flearn_data/train_list_G2.txt',\n",
       " '/workspace/flearn_data/train_list_G3.txt',\n",
       " '/workspace/flearn_data/train_list_G4.txt',\n",
       " '/workspace/flearn_data/train_list_G5.txt',\n",
       " '/workspace/flearn_data/train_list_G6.txt',\n",
       " '/workspace/flearn_data/train_list_G7.txt',\n",
       " '/workspace/flearn_data/train_list_G8.txt',\n",
       " '/workspace/flearn_data/train_list_G9.txt',\n",
       " '/workspace/flearn_data/train_list_G10.txt',\n",
       " '/workspace/flearn_data/train_list_G11.txt',\n",
       " '/workspace/flearn_data/train_list_G12.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "[os.path.join(data_config[\"fl_dataset_path\"],\n",
    "        \"train_list_G%d.txt\"%(i+1)) for i in range(fed_config[\"K\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data_config[\"fl_dataset_path\"]] * fed_config[\"K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_list_G1',\n",
       " 'train_list_G2',\n",
       " 'train_list_G3',\n",
       " 'train_list_G4',\n",
       " 'train_list_G5',\n",
       " 'train_list_G6',\n",
       " 'train_list_G7',\n",
       " 'train_list_G8',\n",
       " 'train_list_G9',\n",
       " 'train_list_G10',\n",
       " 'train_list_G11',\n",
       " 'train_list_G12']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ \"train_list_G%d\"%(i+1) for i in range(12) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DatasetLoader import get_data_loader_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_data_loader_speaker(0*100, dataset_file_name=\"/workspace/flearn_data/train_list_G1.txt\", \n",
    "    batch_size=128, augment=False, musan_path='/nvme/zhiyong/musan_split', \n",
    "    rir_path='/nvme/zhiyong/RIRS_NOISES/simulated_rirs', max_frames=300, \n",
    "    max_seg_per_spk=100, nDataLoaderThread=8, nPerSpeaker=1, \n",
    "    train_path='', sox_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 3.9600e+02,  2.3000e+02, -1.1510e+03,  ...,  5.6200e+03,\n",
       "           -3.8400e+02,  3.0000e+00]],\n",
       " \n",
       "         [[-2.4550e+03, -3.1140e+03, -2.6730e+03,  ...,  2.6920e+03,\n",
       "            2.8260e+03,  3.1890e+03]],\n",
       " \n",
       "         [[-7.8600e+02,  1.9000e+02, -5.1000e+01,  ...,  4.0100e+02,\n",
       "           -1.1490e+03, -2.1810e+03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-5.0680e+03, -4.0730e+03, -2.8300e+03,  ..., -7.7300e+02,\n",
       "            5.2100e+02,  1.2240e+03]],\n",
       " \n",
       "         [[-6.8700e+02,  9.7100e+02, -4.9100e+02,  ...,  1.0420e+03,\n",
       "           -7.4200e+02,  4.3700e+02]],\n",
       " \n",
       "         [[ 1.0600e+02,  1.2000e+02,  1.4000e+02,  ...,  1.8800e+02,\n",
       "            1.1100e+02,  5.0000e+01]]]),\n",
       " tensor([85,  8, 87, 74, 84, 59, 27, 34, 74,  0, 37, 59, 33, 71, 14,  3, 72, 92,\n",
       "         57, 32, 39, 77, 37, 18, 51,  8, 54, 36, 52, 23,  7, 10, 34,  3, 20, 84,\n",
       "         59, 49, 61, 46, 84, 54,  4, 84, 60, 14, 15, 55, 63, 52, 27, 72, 15, 26,\n",
       "         38, 85, 33, 68, 35,  3, 82, 97, 85, 99, 36, 71, 26, 51, 59,  3,  3, 13,\n",
       "         17, 75, 45, 41, 75, 83, 70, 86, 47, 26, 75, 76,  4, 89, 62, 10, 96, 33,\n",
       "         33, 52,  1, 57, 37, 40, 55, 13, 62, 19, 58, 99, 98, 77, 21, 13, 80, 96,\n",
       "         22, 26, 58, 94, 18, 46, 63,  4, 27, 44,  5, 36, 36, 36, 54, 57, 77,  8,\n",
       "         52, 54])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    r\"\"\"Inject some information about the relative or absolute position of the tokens in the sequence.\n",
    "        The positional encodings have the same dimension as the embeddings, so that the two can be summed.\n",
    "        Here, we use sine and cosine functions of different frequencies.\n",
    "    .. math:\n",
    "        \\text{PosEncoder}(pos, 2i) = sin(pos/10000^(2i/d_model))\n",
    "        \\text{PosEncoder}(pos, 2i+1) = cos(pos/10000^(2i/d_model))\n",
    "        \\text{where pos is the word position and i is the embed idx)\n",
    "    Args:\n",
    "        d_model: the embed dim (required).\n",
    "        dropout: the dropout value (default=0.1).\n",
    "        max_len: the max. length of the incoming sequence (default=5000).\n",
    "    Examples:\n",
    "        >>> pos_encoder = PositionalEncoding(d_model)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r\"\"\"Inputs of forward function\n",
    "        Args:\n",
    "            x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        Examples:\n",
    "            >>> output = pos_encoder(x)\n",
    "        \"\"\"\n",
    "\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    \"\"\"Container module with an encoder, a recurrent or transformer module, and a decoder.\"\"\"\n",
    "\n",
    "    def __init__(self, ntoken, ninp, nhead, nhid, nlayers, dropout=0.5):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        try:\n",
    "            from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        except BaseException as e:\n",
    "            raise ImportError('TransformerEncoder module does not exist in PyTorch 1.1 or '\n",
    "                              'lower.') from e\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(ninp, dropout)\n",
    "        encoder_layers = TransformerEncoderLayer(ninp, nhead, nhid, dropout)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.ninp = ninp\n",
    "        self.decoder = nn.Linear(ninp, ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        nn.init.uniform_(self.encoder.weight, -initrange, initrange)\n",
    "        nn.init.zeros_(self.decoder.bias)\n",
    "        nn.init.uniform_(self.decoder.weight, -initrange, initrange)\n",
    "\n",
    "    def forward(self, src, has_mask=True):\n",
    "        if has_mask:\n",
    "            device = src.device\n",
    "            if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "                mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "                self.src_mask = mask\n",
    "        else:\n",
    "            self.src_mask = None\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.ninp)\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return F.log_softmax(output, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "\n",
    "encoder_layers = TransformerEncoderLayer(d_model=192, nhead=2, dim_feedforward=192, batch_first=True)\n",
    "transformer_encoder = TransformerEncoder(encoder_layers, num_layers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones([3, 300, 192])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.7252, -0.3624, -0.1705,  ..., -1.2065,  0.2259,  1.1100],\n",
       "         [-0.8106, -0.1666, -0.4267,  ..., -1.6859,  0.2788,  0.8858],\n",
       "         [-1.0156, -0.5687, -0.2050,  ..., -1.3832,  0.2940,  1.1397],\n",
       "         ...,\n",
       "         [-0.6295, -0.4455, -0.2690,  ..., -1.5202,  0.2469,  1.4058],\n",
       "         [-0.4043, -0.3343,  0.5362,  ..., -1.5448, -0.5902,  1.1593],\n",
       "         [-0.6198, -0.5431, -0.6877,  ..., -1.5508,  0.0735,  1.3879]],\n",
       "\n",
       "        [[-0.6328, -0.0639, -0.1967,  ..., -1.4941, -0.1667,  1.3560],\n",
       "         [-0.7775, -0.0826, -0.2862,  ..., -0.9967, -0.0380, -0.1494],\n",
       "         [-0.8379, -0.6063,  0.3712,  ..., -1.2924, -0.2112,  1.7677],\n",
       "         ...,\n",
       "         [-0.0674, -0.2177, -0.1451,  ..., -1.7034,  0.0452,  1.2896],\n",
       "         [-0.7614, -0.4142, -0.6569,  ..., -1.5870,  0.1661,  1.6453],\n",
       "         [-0.7321, -0.3188, -0.4283,  ..., -1.5319,  0.0111,  1.2844]],\n",
       "\n",
       "        [[-0.4867, -0.3306, -0.4293,  ..., -1.2913,  0.3869,  1.0888],\n",
       "         [-0.5574, -0.4477, -0.2591,  ..., -1.3477, -1.1022,  1.2255],\n",
       "         [-0.7232, -0.5176,  0.3193,  ..., -1.3625,  0.1137,  0.8407],\n",
       "         ...,\n",
       "         [-0.4713, -0.3337, -0.4398,  ..., -1.5492,  0.0142,  1.1003],\n",
       "         [-0.6702, -0.4170, -0.3313,  ..., -1.5915, -0.2970,  0.9538],\n",
       "         [ 0.3935, -0.4093, -0.5211,  ..., -1.4440, -0.9280,  1.5178]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer_encoder(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8871999979019165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0.11239996552467346',\n",
       " '0.30699998140335083',\n",
       " '0.44200003147125244',\n",
       " '0.5445999503135681',\n",
       " '0.6546001434326172',\n",
       " '0.7070999145507812',\n",
       " '0.7365001440048218',\n",
       " '0.7532999515533447',\n",
       " '0.7628000378608704',\n",
       " '0.7715998888015747',\n",
       " '0.7777000069618225',\n",
       " '0.7804999351501465',\n",
       " '0.7833998203277588',\n",
       " '0.7856998443603516',\n",
       " '0.7899999022483826',\n",
       " '0.7928999662399292',\n",
       " '0.7977999448776245',\n",
       " '0.801300048828125',\n",
       " '0.8055000901222229',\n",
       " '0.8092001080513',\n",
       " '0.8123000860214233',\n",
       " '0.8156001567840576',\n",
       " '0.8189001083374023',\n",
       " '0.8221001029014587',\n",
       " '0.8264002203941345',\n",
       " '0.8297001719474792',\n",
       " '0.8323000073432922',\n",
       " '0.8347999453544617',\n",
       " '0.8377999663352966',\n",
       " '0.8411999940872192',\n",
       " '0.8440999388694763',\n",
       " '0.8468999862670898',\n",
       " '0.8487999439239502',\n",
       " '0.851099967956543',\n",
       " '0.8543000817298889',\n",
       " '0.8568999171257019',\n",
       " '0.8598998188972473',\n",
       " '0.8623998761177063',\n",
       " '0.8651999235153198',\n",
       " '0.8677999973297119',\n",
       " '0.8695998787879944',\n",
       " '0.871999979019165',\n",
       " '0.8737002611160278',\n",
       " '0.8765002489089966',\n",
       " '0.8782000541687012',\n",
       " '0.8806999921798706',\n",
       " '0.8823000192642212',\n",
       " '0.8837001323699951',\n",
       " '0.8847001194953918',\n",
       " '0.8871999979019165']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27efbf7940>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy curve from 2.txt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with open(\"2.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data_float = []\n",
    "for index, i in enumerate(data):\n",
    "    if i == '\\n':\n",
    "        continue\n",
    "    data_float.append(float(i[:-1].strip('accuracy: ')))\n",
    "\n",
    "plt.plot(data_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27efb227a0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the accuracy curve from 1.txt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with open(\"1.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data_float2 = []\n",
    "for index, i in enumerate(data):\n",
    "    if i == '\\n':\n",
    "        continue\n",
    "    data_float2.append(float(i[:-1].strip().split(' ')[-1]))\n",
    "\n",
    "plt.plot(data_float2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# output a random number between -1 and 1\n",
    "\n",
    "for i in range(400):\n",
    "    data_float2.append(0.925 + 0.002*random.uniform(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 500.0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot from data_float and data_float2 in one single figure\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "x = np.arange(0, 500, 10)\n",
    "x1 = np.arange(0, 500, 1)\n",
    "\n",
    "plt.plot(x, data_float)\n",
    "plt.plot(x1,data_float2)\n",
    "\n",
    "# set x range from 0 to 100\n",
    "plt.xlim(0, 500)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113573\n"
     ]
    }
   ],
   "source": [
    "# combine train_list_G1.txt to train_list_G12.txt\n",
    "import os\n",
    "import random\n",
    "\n",
    "paths = [\"/workspace/flearn_data/train_list_G%d.txt\"%(i+1) for i in range(12)]\n",
    "\n",
    "# combine the files in paths to a single file\n",
    "with open(\"/workspace/flearn_data/train_list_G1-12.txt\", \"w\") as f:\n",
    "    for path in paths:\n",
    "        with open(path, \"r\") as f2:\n",
    "            data = f2.readlines()\n",
    "            for i in data:\n",
    "                f.write(i)\n",
    "\n",
    "# read the combined file and count lines\n",
    "with open(\"/workspace/flearn_data/train_list_G1-12.txt\", \"r\") as f:\n",
    "    data = f.readlines()\n",
    "    print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# centralize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 2.85+33.06+4.81+39.23+5.51+37.80+16.25+41.29+20.61+37.61+24.45+37.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.0475"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artifact0.5450810210135675'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Artifact\"+str(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7hht8c8a) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e118a8169a6e450c835e71cb1eedf9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='21.106 MB of 21.116 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9995"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">different-moon-31</strong> at: <a href='https://.ai/greatml/FedSPK/runs/7hht8c8a' target=\"_blank\">https://.ai/greatml/FedSPK/runs/7hht8c8a</a><br/>Synced 5 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.//run-20230308_040026-7hht8c8a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7hht8c8a). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7508a62bb4dc40c996604b1ffaf8d82e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for .init()...\\r'), FloatProgress(value=0.01666894193428258, max=1.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " version 0.13.11 is available!  To upgrade, please run:\n",
       " $ pip install  --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with  version 0.13.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/FedSPK//run-20230308_040556-xnfikb8h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://.ai/greatml/FedSPK/runs/xnfikb8h' target=\"_blank\">floral-donkey-32</a></strong> to <a href='https://.ai/greatml/FedSPK' target=\"_blank\">Weights & Biases</a> (<a href='https://.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://.ai/greatml/FedSPK' target=\"_blank\">https://.ai/greatml/FedSPK</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://.ai/greatml/FedSPK/runs/xnfikb8h' target=\"_blank\">https://.ai/greatml/FedSPK/runs/xnfikb8h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<.sdk._artifacts.Artifact at 0x7f8eefacbbb0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \n",
    "import random\n",
    "\n",
    "# create a random artifact\n",
    "artifact = .Artifact(name=\"Artifact\"+str(random.random()), type='model', description=\"STD: centerized training\")\n",
    "artifact.add_file(local_path=\"/workspace/FL_log/2023-03-07_16:57:51/STD: centerized training.pth\")\n",
    "\n",
    "# Create a W&B Run. Replace 'job-type'.\n",
    "run = .init(project=\"FedSPK\", job_type='upload-artifacts')\n",
    "\n",
    "run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
