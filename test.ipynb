{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torchaudio.info('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioMetaData(sample_rate=16000, num_frames=133761, num_channels=1, bits_per_sample=16, encoding=PCM_S)\n"
     ]
    }
   ],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = torchaudio.backend.sox_io_backend.load('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav', normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-147, -137,  -86,  ...,  581, 1629, 2023]], dtype=torch.int16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile as wavfile\n",
    "sample_rate, audio  = wavfile.read('/nvme/zhiyong/vox1/test/wav/id10270/5r0dWxy17C8/00001.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.SpeakerNet import SpeakerNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_vector.py, Embedding size is 192,  Spec_aug False.\n",
      "Initialised Softmax Loss\n"
     ]
    }
   ],
   "source": [
    "s = SpeakerNet(model='X_vector', trainfunc='softmax', nPerSpeaker=1, Syncbatch=False, n_mels=40, nOut=192, spec_aug=False, nClasses=5994)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'__L__' in '__L__.fc.weight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.fc.weight', '__L__.fc.bias'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('__S__.torchfb.0.flipped_filter',\n",
       "              tensor([[[-0.9700,  1.0000]]])),\n",
       "             ('__S__.torchfb.1.spectrogram.window',\n",
       "              tensor([0.0800, 0.0801, 0.0802, 0.0805, 0.0809, 0.0814, 0.0820, 0.0828, 0.0836,\n",
       "                      0.0846, 0.0857, 0.0868, 0.0881, 0.0896, 0.0911, 0.0927, 0.0945, 0.0963,\n",
       "                      0.0983, 0.1003, 0.1025, 0.1048, 0.1072, 0.1097, 0.1123, 0.1150, 0.1178,\n",
       "                      0.1208, 0.1238, 0.1269, 0.1301, 0.1335, 0.1369, 0.1404, 0.1441, 0.1478,\n",
       "                      0.1516, 0.1555, 0.1595, 0.1637, 0.1679, 0.1721, 0.1765, 0.1810, 0.1856,\n",
       "                      0.1902, 0.1949, 0.1998, 0.2047, 0.2097, 0.2147, 0.2199, 0.2251, 0.2304,\n",
       "                      0.2358, 0.2413, 0.2468, 0.2524, 0.2581, 0.2638, 0.2696, 0.2755, 0.2814,\n",
       "                      0.2874, 0.2935, 0.2997, 0.3058, 0.3121, 0.3184, 0.3248, 0.3312, 0.3376,\n",
       "                      0.3441, 0.3507, 0.3573, 0.3640, 0.3707, 0.3774, 0.3842, 0.3910, 0.3979,\n",
       "                      0.4047, 0.4117, 0.4186, 0.4256, 0.4326, 0.4397, 0.4467, 0.4538, 0.4609,\n",
       "                      0.4680, 0.4752, 0.4823, 0.4895, 0.4967, 0.5039, 0.5111, 0.5183, 0.5256,\n",
       "                      0.5328, 0.5400, 0.5472, 0.5544, 0.5617, 0.5689, 0.5761, 0.5833, 0.5905,\n",
       "                      0.5977, 0.6048, 0.6120, 0.6191, 0.6262, 0.6333, 0.6403, 0.6474, 0.6544,\n",
       "                      0.6614, 0.6683, 0.6753, 0.6821, 0.6890, 0.6958, 0.7026, 0.7093, 0.7160,\n",
       "                      0.7227, 0.7293, 0.7359, 0.7424, 0.7488, 0.7552, 0.7616, 0.7679, 0.7742,\n",
       "                      0.7803, 0.7865, 0.7926, 0.7986, 0.8045, 0.8104, 0.8162, 0.8219, 0.8276,\n",
       "                      0.8332, 0.8387, 0.8442, 0.8496, 0.8549, 0.8601, 0.8653, 0.8703, 0.8753,\n",
       "                      0.8802, 0.8851, 0.8898, 0.8944, 0.8990, 0.9035, 0.9079, 0.9121, 0.9163,\n",
       "                      0.9205, 0.9245, 0.9284, 0.9322, 0.9359, 0.9396, 0.9431, 0.9465, 0.9499,\n",
       "                      0.9531, 0.9562, 0.9592, 0.9622, 0.9650, 0.9677, 0.9703, 0.9728, 0.9752,\n",
       "                      0.9775, 0.9797, 0.9817, 0.9837, 0.9855, 0.9873, 0.9889, 0.9904, 0.9919,\n",
       "                      0.9932, 0.9943, 0.9954, 0.9964, 0.9972, 0.9980, 0.9986, 0.9991, 0.9995,\n",
       "                      0.9998, 0.9999, 1.0000, 0.9999, 0.9998, 0.9995, 0.9991, 0.9986, 0.9980,\n",
       "                      0.9972, 0.9964, 0.9954, 0.9943, 0.9932, 0.9919, 0.9904, 0.9889, 0.9873,\n",
       "                      0.9855, 0.9837, 0.9817, 0.9797, 0.9775, 0.9752, 0.9728, 0.9703, 0.9677,\n",
       "                      0.9650, 0.9622, 0.9592, 0.9562, 0.9531, 0.9499, 0.9465, 0.9431, 0.9396,\n",
       "                      0.9359, 0.9322, 0.9284, 0.9245, 0.9205, 0.9163, 0.9121, 0.9079, 0.9035,\n",
       "                      0.8990, 0.8944, 0.8898, 0.8851, 0.8802, 0.8753, 0.8703, 0.8653, 0.8601,\n",
       "                      0.8549, 0.8496, 0.8442, 0.8387, 0.8332, 0.8276, 0.8219, 0.8162, 0.8104,\n",
       "                      0.8045, 0.7986, 0.7926, 0.7865, 0.7803, 0.7742, 0.7679, 0.7616, 0.7552,\n",
       "                      0.7488, 0.7424, 0.7359, 0.7293, 0.7227, 0.7160, 0.7093, 0.7026, 0.6958,\n",
       "                      0.6890, 0.6821, 0.6753, 0.6683, 0.6614, 0.6544, 0.6474, 0.6403, 0.6333,\n",
       "                      0.6262, 0.6191, 0.6120, 0.6048, 0.5977, 0.5905, 0.5833, 0.5761, 0.5689,\n",
       "                      0.5617, 0.5544, 0.5472, 0.5400, 0.5328, 0.5256, 0.5183, 0.5111, 0.5039,\n",
       "                      0.4967, 0.4895, 0.4823, 0.4752, 0.4680, 0.4609, 0.4538, 0.4467, 0.4397,\n",
       "                      0.4326, 0.4256, 0.4186, 0.4117, 0.4047, 0.3979, 0.3910, 0.3842, 0.3774,\n",
       "                      0.3707, 0.3640, 0.3573, 0.3507, 0.3441, 0.3376, 0.3312, 0.3248, 0.3184,\n",
       "                      0.3121, 0.3058, 0.2997, 0.2935, 0.2874, 0.2814, 0.2755, 0.2696, 0.2638,\n",
       "                      0.2581, 0.2524, 0.2468, 0.2413, 0.2358, 0.2304, 0.2251, 0.2199, 0.2147,\n",
       "                      0.2097, 0.2047, 0.1998, 0.1949, 0.1902, 0.1856, 0.1810, 0.1765, 0.1721,\n",
       "                      0.1679, 0.1637, 0.1595, 0.1555, 0.1516, 0.1478, 0.1441, 0.1404, 0.1369,\n",
       "                      0.1335, 0.1301, 0.1269, 0.1238, 0.1208, 0.1178, 0.1150, 0.1123, 0.1097,\n",
       "                      0.1072, 0.1048, 0.1025, 0.1003, 0.0983, 0.0963, 0.0945, 0.0927, 0.0911,\n",
       "                      0.0896, 0.0881, 0.0868, 0.0857, 0.0846, 0.0836, 0.0828, 0.0820, 0.0814,\n",
       "                      0.0809, 0.0805, 0.0802, 0.0801])),\n",
       "             ('__S__.torchfb.1.mel_scale.fb',\n",
       "              tensor([[-0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.8756, 0.1244, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.7972, 0.2028,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      ...,\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1889],\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0945],\n",
       "                      [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])),\n",
       "             ('__S__.tdnn1.0.weight',\n",
       "              tensor([[[-1.2713e-02, -1.8299e-02,  4.9114e-02,  5.2640e-02,  2.6351e-02],\n",
       "                       [-3.2142e-02, -1.6426e-02, -2.1600e-02,  2.2035e-02,  2.4249e-02],\n",
       "                       [-4.3636e-02, -4.7509e-02,  1.9992e-02, -4.2740e-02, -3.8626e-02],\n",
       "                       ...,\n",
       "                       [ 1.1885e-02,  3.0398e-02,  4.6570e-02,  3.7177e-02,  4.5768e-02],\n",
       "                       [ 3.8047e-03, -5.2037e-02, -3.3013e-02,  3.4105e-02,  1.8720e-02],\n",
       "                       [-2.4096e-02,  4.7861e-02,  3.4828e-02, -4.5024e-02,  3.4111e-02]],\n",
       "              \n",
       "                      [[-7.3117e-03,  2.7849e-02,  8.7948e-03,  2.0099e-02, -3.5584e-04],\n",
       "                       [-2.1074e-02, -2.0154e-02, -4.2670e-02,  2.2109e-02,  1.1238e-02],\n",
       "                       [-2.1508e-02, -1.2506e-02, -2.9124e-02, -1.3669e-02, -3.1951e-02],\n",
       "                       ...,\n",
       "                       [ 1.9888e-03,  4.0819e-02, -5.2169e-02, -4.1193e-02,  3.6546e-02],\n",
       "                       [-1.9751e-02, -5.3781e-02,  3.1711e-03, -4.5323e-02, -6.8933e-03],\n",
       "                       [-3.5621e-02,  3.3085e-02,  2.2242e-02,  1.2598e-02,  4.8566e-02]],\n",
       "              \n",
       "                      [[ 3.9252e-02,  1.7649e-02, -5.3880e-02, -8.6610e-03, -3.1874e-02],\n",
       "                       [-1.6965e-02,  5.1327e-02, -4.0371e-02, -4.3542e-02, -1.7022e-02],\n",
       "                       [ 1.0157e-02,  2.4904e-02,  3.3899e-02,  4.7954e-02, -8.1891e-03],\n",
       "                       ...,\n",
       "                       [ 2.3529e-02, -2.9429e-02, -3.5445e-02, -1.1126e-04,  3.5911e-02],\n",
       "                       [-4.8669e-02, -3.0855e-02,  1.6818e-02,  2.3097e-02, -5.3822e-02],\n",
       "                       [ 4.8929e-02, -1.4289e-02, -2.4074e-02,  4.6487e-02, -1.3184e-02]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-5.8105e-03,  4.5871e-02, -1.3916e-02,  4.1882e-03, -5.1549e-02],\n",
       "                       [-4.9753e-04,  1.8424e-02,  4.9461e-02, -3.2300e-02, -8.3654e-04],\n",
       "                       [-5.2578e-02, -1.0689e-02, -4.5455e-03,  3.3247e-02, -5.0517e-02],\n",
       "                       ...,\n",
       "                       [-3.3230e-02, -1.5510e-02,  4.9918e-02,  8.2053e-04,  2.7274e-02],\n",
       "                       [ 2.6714e-02,  5.1033e-02, -3.4452e-02, -3.9167e-02,  1.1618e-02],\n",
       "                       [-2.9936e-02, -3.0279e-02, -1.2971e-02,  3.6829e-02, -4.7347e-02]],\n",
       "              \n",
       "                      [[-5.2432e-03,  2.0584e-02, -2.4683e-02,  1.8076e-02, -4.6413e-02],\n",
       "                       [-3.8681e-02,  5.8238e-03, -3.3817e-02,  1.0495e-02, -1.3731e-02],\n",
       "                       [ 4.7389e-02, -5.0768e-02,  2.8942e-02, -3.0262e-02,  1.3478e-02],\n",
       "                       ...,\n",
       "                       [ 4.2523e-02,  4.1866e-02, -3.9260e-02, -3.2368e-02, -6.3879e-04],\n",
       "                       [-9.8459e-03,  5.1897e-02, -7.5477e-03,  1.8934e-02, -9.0929e-03],\n",
       "                       [-4.9178e-02, -1.8614e-02,  4.0535e-02, -2.1405e-03,  8.0089e-03]],\n",
       "              \n",
       "                      [[-5.4289e-02,  2.3374e-02, -1.4197e-02, -8.1346e-03, -4.5811e-02],\n",
       "                       [-3.3268e-02,  1.7945e-02, -5.4105e-02,  1.1113e-02, -1.2995e-02],\n",
       "                       [ 2.4381e-02,  5.0347e-05, -2.0353e-02, -5.4582e-02, -4.2675e-02],\n",
       "                       ...,\n",
       "                       [-3.7074e-02,  2.8415e-02,  5.0810e-03, -3.9278e-02, -3.8614e-02],\n",
       "                       [-2.5877e-02, -2.9665e-02,  4.8716e-02, -4.6956e-02, -5.2224e-03],\n",
       "                       [ 4.7323e-02,  1.3843e-02,  1.2301e-02, -3.2644e-02,  1.4515e-02]]])),\n",
       "             ('__S__.tdnn1.0.bias',\n",
       "              tensor([ 2.1225e-02, -3.4663e-02, -3.0911e-02, -4.4578e-02,  3.9308e-02,\n",
       "                      -4.8730e-02, -4.4159e-02,  6.1011e-04, -3.8355e-02, -5.3412e-02,\n",
       "                       4.6391e-02, -9.2273e-03,  3.3401e-02,  2.5872e-02,  3.3986e-02,\n",
       "                      -2.5412e-02, -4.5164e-02, -3.7321e-02, -1.4405e-02,  3.4323e-02,\n",
       "                      -9.4329e-03, -2.8923e-02, -4.6448e-02,  1.6631e-02,  2.2533e-02,\n",
       "                       2.5740e-02,  5.3552e-02,  4.6541e-02,  3.7678e-02,  3.5410e-03,\n",
       "                       1.5976e-02, -2.7482e-03, -1.6613e-02,  5.4716e-02,  3.6388e-02,\n",
       "                       4.9836e-03,  4.4453e-02,  3.5055e-02,  3.2246e-02,  3.6123e-02,\n",
       "                       1.6936e-02, -3.1664e-03,  2.7083e-02,  1.1190e-02,  1.0725e-02,\n",
       "                      -3.2800e-02, -2.8942e-02,  1.2268e-03, -2.8194e-02,  9.5324e-03,\n",
       "                      -5.2609e-02,  2.7666e-02,  2.1066e-02, -1.9721e-02,  4.1050e-02,\n",
       "                       4.4041e-02, -3.7851e-02,  3.8728e-02,  2.1210e-02,  4.3475e-02,\n",
       "                      -5.5432e-02,  1.2468e-02, -4.9233e-02,  7.9523e-03,  2.9810e-03,\n",
       "                      -4.2981e-02,  4.2245e-02, -1.0139e-03,  1.9798e-02, -2.7027e-02,\n",
       "                       4.6851e-02, -2.2462e-02, -7.4380e-03, -5.5482e-02,  3.9247e-03,\n",
       "                      -3.3131e-02, -2.1083e-02,  3.9598e-02, -3.9156e-02,  5.0789e-02,\n",
       "                      -2.0754e-02, -4.5866e-02, -1.1342e-02,  1.3645e-02, -4.5697e-03,\n",
       "                       3.4663e-02,  5.1346e-02,  3.7283e-02,  3.8097e-02,  4.2713e-02,\n",
       "                      -4.7749e-02,  1.3728e-02, -1.9579e-02, -3.9805e-02, -1.6205e-02,\n",
       "                      -6.1746e-03, -4.0048e-02, -4.7881e-02,  3.6936e-03,  3.0681e-02,\n",
       "                       3.8717e-02,  4.4373e-02,  4.3153e-03,  2.9153e-02,  5.5591e-02,\n",
       "                      -3.5564e-02,  4.6579e-02, -2.5779e-02, -2.3843e-02,  2.3816e-02,\n",
       "                       5.5840e-02,  4.9082e-04, -5.3624e-02,  2.2875e-02,  4.6366e-02,\n",
       "                      -2.1595e-02,  3.5394e-03,  9.8031e-03, -5.3514e-02, -4.7845e-02,\n",
       "                       1.2374e-02, -3.4012e-02,  3.7188e-02,  1.0206e-02, -5.3159e-02,\n",
       "                       5.4067e-02, -4.8588e-02, -2.0124e-02,  4.5033e-02, -3.0863e-02,\n",
       "                      -3.5240e-03, -5.3638e-03, -4.6537e-02,  5.1911e-02, -3.7870e-02,\n",
       "                      -5.3864e-02, -1.9706e-02,  2.2665e-02, -2.2881e-02,  2.1116e-02,\n",
       "                      -1.8186e-05, -1.2089e-02,  4.3941e-02, -8.0688e-03, -2.7860e-02,\n",
       "                      -5.2700e-03, -4.1925e-02, -1.0441e-03, -6.7197e-03, -1.3656e-02,\n",
       "                       1.3803e-02, -2.6863e-02,  2.7806e-03,  2.9672e-02,  3.3279e-02,\n",
       "                      -1.7282e-02,  2.6512e-02, -2.1732e-02,  5.1686e-02, -4.2194e-02,\n",
       "                       1.9876e-02,  7.9002e-03,  4.4641e-03, -2.5952e-02, -1.0853e-03,\n",
       "                      -5.4857e-02,  3.0565e-02,  2.6505e-03, -3.8498e-02, -9.6770e-03,\n",
       "                      -3.4100e-02, -5.3490e-02, -2.1057e-02,  3.3397e-02, -9.2772e-03,\n",
       "                       6.8743e-03,  2.6723e-02,  4.3575e-02, -4.1231e-02, -6.4345e-03,\n",
       "                       1.9982e-02,  2.7320e-02,  8.1943e-03,  5.1254e-02, -4.8654e-02,\n",
       "                      -2.4833e-02, -3.1278e-02,  5.2356e-03, -4.8930e-02,  7.2022e-03,\n",
       "                       4.0372e-02,  6.4079e-03, -1.1613e-02, -3.6681e-02,  5.5342e-02,\n",
       "                       4.9236e-02, -2.1395e-02, -3.9998e-03,  1.4899e-04, -1.5888e-02,\n",
       "                       6.0450e-03, -4.8238e-03,  3.7750e-02,  3.4732e-03,  5.2840e-02,\n",
       "                       3.1822e-02,  2.9084e-02,  5.3660e-02, -3.4406e-02, -7.3505e-04,\n",
       "                      -1.8191e-02, -1.7812e-02, -1.8582e-02,  4.3449e-02, -4.8234e-02,\n",
       "                      -3.6482e-02,  3.3936e-02,  3.9694e-03,  1.6771e-04, -3.2234e-02,\n",
       "                      -1.3827e-02,  9.9384e-03, -1.5535e-02,  4.0458e-02,  1.4332e-02,\n",
       "                       4.6847e-02, -2.1521e-03,  3.8454e-02,  4.2858e-02,  2.2143e-02,\n",
       "                       5.3585e-02, -4.3914e-02,  5.4745e-02,  3.9681e-02, -6.6811e-03,\n",
       "                       2.8300e-02, -5.1964e-02, -2.3363e-02,  2.6782e-02,  4.7105e-02,\n",
       "                      -1.4355e-02,  4.2660e-03,  5.5263e-03,  3.6475e-02, -1.7283e-02,\n",
       "                       3.3341e-02,  4.9456e-02,  2.3787e-02, -3.0133e-02, -1.3515e-02,\n",
       "                      -4.5446e-02,  1.0198e-02, -2.5406e-02, -1.9571e-02,  3.7893e-02,\n",
       "                      -3.0942e-02, -3.1304e-02, -4.4918e-02,  2.9694e-02,  4.1192e-02,\n",
       "                      -5.5342e-02,  2.3412e-02,  2.4394e-02, -2.3254e-02,  9.6306e-03,\n",
       "                      -1.4006e-02, -3.3344e-03, -4.8415e-03,  1.4848e-02, -5.9308e-03,\n",
       "                       1.5163e-02,  2.1900e-02, -1.4321e-02, -5.2330e-02, -2.4230e-02,\n",
       "                       1.7207e-02, -3.8608e-02,  5.5684e-02, -4.6674e-02, -5.0327e-02,\n",
       "                      -1.4193e-02, -9.7704e-03,  5.4642e-02,  1.0305e-02,  3.5914e-02,\n",
       "                      -3.8995e-02,  1.5792e-02, -8.6831e-03, -4.7834e-02,  1.5045e-02,\n",
       "                      -4.2623e-02, -2.6146e-02,  2.3978e-02, -5.2158e-02, -1.6089e-02,\n",
       "                      -2.6944e-02, -5.1301e-02,  4.7776e-02, -4.2819e-02, -4.0032e-02,\n",
       "                       3.1316e-02, -4.9107e-03, -2.1047e-02, -4.2430e-02,  1.5704e-02,\n",
       "                      -3.3161e-02,  2.1621e-02,  4.0684e-02,  2.2307e-02,  1.6555e-02,\n",
       "                       1.9509e-02, -1.0036e-02, -1.9088e-02,  5.2763e-02,  5.1164e-02,\n",
       "                      -4.3807e-02,  5.3921e-02,  4.4027e-02,  4.3926e-02,  8.8357e-03,\n",
       "                       4.6649e-02,  4.2139e-02, -5.0424e-02,  5.9970e-03,  5.3166e-02,\n",
       "                      -5.0025e-04, -4.0940e-02, -3.3919e-02,  1.7805e-02, -2.6141e-02,\n",
       "                       3.2784e-04, -4.9358e-02, -1.8665e-02,  3.9359e-02,  5.0460e-02,\n",
       "                      -1.8713e-02, -5.5574e-02,  1.2764e-02,  6.4568e-03, -3.7575e-02,\n",
       "                       3.8396e-02, -4.9561e-02,  2.3706e-02, -1.0987e-02,  1.6868e-02,\n",
       "                       4.8727e-02,  5.2588e-02,  2.6377e-02,  1.4795e-02,  2.3238e-02,\n",
       "                      -1.4946e-02,  2.5691e-02, -4.3647e-02,  7.9372e-03,  4.7138e-02,\n",
       "                       4.6603e-02,  2.8739e-02, -7.6574e-03, -4.2673e-02, -4.3615e-02,\n",
       "                       2.8123e-02, -1.9241e-02,  5.2003e-02, -1.7523e-02,  5.1233e-02,\n",
       "                       9.6720e-03, -4.5080e-02,  2.9587e-02,  4.5288e-02,  2.1803e-02,\n",
       "                      -2.8970e-02,  3.6591e-02,  4.5905e-04,  5.8287e-04, -3.9192e-02,\n",
       "                      -4.4069e-02,  3.0832e-02, -4.6912e-02, -4.5945e-02,  2.0351e-02,\n",
       "                       4.3572e-02,  7.9333e-03, -4.9102e-02,  2.4471e-02, -3.0827e-02,\n",
       "                       4.4869e-02, -5.4619e-02, -1.4646e-03,  6.4370e-04, -3.0407e-02,\n",
       "                       1.2361e-02,  1.6616e-02,  1.3511e-02, -5.3985e-02, -1.3335e-02,\n",
       "                      -3.1039e-02, -6.5891e-03,  4.1464e-02, -5.4736e-02, -1.9209e-02,\n",
       "                       6.4644e-03, -2.7037e-02, -3.7604e-02,  2.2614e-02, -2.3873e-02,\n",
       "                       2.0286e-02,  2.3057e-02,  1.0024e-02,  4.0377e-04,  4.5650e-02,\n",
       "                       2.8350e-02, -4.4368e-02, -3.1973e-02,  3.8715e-02, -4.3743e-03,\n",
       "                      -2.4962e-02, -3.7935e-02,  4.5193e-02, -2.1064e-02, -5.0053e-02,\n",
       "                      -1.9664e-02, -3.5546e-02, -3.3585e-02,  1.1103e-02,  1.0295e-03,\n",
       "                       2.5813e-03,  5.4148e-02, -2.1120e-02, -2.0156e-02, -2.4537e-02,\n",
       "                       3.5011e-02, -2.3944e-03,  3.0298e-04, -1.5707e-02, -2.8259e-03,\n",
       "                       5.1449e-02, -2.7974e-03, -2.5520e-02,  9.6119e-03,  9.7931e-03,\n",
       "                       2.9714e-02,  2.4472e-02, -5.0737e-02,  2.6958e-02, -3.2635e-02,\n",
       "                       3.7877e-02,  1.2793e-02, -5.1739e-02,  2.4540e-02, -1.6677e-02,\n",
       "                       1.7770e-02,  4.4357e-02,  1.2874e-02, -4.2136e-02,  5.0765e-02,\n",
       "                      -7.2195e-03, -5.5428e-02, -3.7544e-03, -1.4103e-02,  8.7452e-03,\n",
       "                      -4.3352e-02, -1.5841e-02,  1.2422e-02, -3.4793e-02,  1.3941e-02,\n",
       "                      -2.1917e-03, -1.6442e-02, -2.6874e-02, -3.1153e-02,  5.4963e-02,\n",
       "                       4.4818e-02,  1.0342e-02, -2.9892e-02, -3.5117e-02, -1.8821e-02,\n",
       "                      -2.5612e-02,  3.0695e-02, -5.1180e-02,  3.7974e-02,  4.6682e-02,\n",
       "                       4.5310e-02,  3.3414e-02,  1.1838e-02,  2.3061e-02, -1.1660e-02,\n",
       "                      -3.8187e-02, -1.8608e-03, -5.1647e-02, -5.0353e-04,  4.6606e-02,\n",
       "                       4.5555e-02, -1.9873e-03,  3.2301e-02, -2.8507e-02,  4.0151e-02,\n",
       "                      -2.6527e-02, -1.0557e-02, -5.5398e-02, -2.2874e-02,  4.9305e-02,\n",
       "                      -3.6818e-02, -4.8607e-02,  8.8546e-04,  2.1474e-02, -4.6295e-02,\n",
       "                      -1.4643e-03, -5.4033e-02, -1.6165e-02,  4.1647e-04,  4.9470e-02,\n",
       "                      -3.4312e-02, -6.6533e-03])),\n",
       "             ('__S__.tdnn1.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn1.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn1.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn1.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn1.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn2.0.weight',\n",
       "              tensor([[[-0.0171, -0.0061, -0.0191],\n",
       "                       [-0.0145,  0.0147,  0.0028],\n",
       "                       [-0.0016,  0.0062, -0.0121],\n",
       "                       ...,\n",
       "                       [-0.0109, -0.0139, -0.0230],\n",
       "                       [-0.0003, -0.0050,  0.0013],\n",
       "                       [ 0.0146, -0.0176,  0.0095]],\n",
       "              \n",
       "                      [[ 0.0039,  0.0071, -0.0239],\n",
       "                       [ 0.0140,  0.0134,  0.0081],\n",
       "                       [ 0.0104,  0.0154,  0.0066],\n",
       "                       ...,\n",
       "                       [ 0.0225, -0.0043, -0.0117],\n",
       "                       [-0.0073, -0.0217,  0.0016],\n",
       "                       [ 0.0198, -0.0027, -0.0080]],\n",
       "              \n",
       "                      [[-0.0084, -0.0196,  0.0122],\n",
       "                       [ 0.0251,  0.0253,  0.0108],\n",
       "                       [ 0.0055, -0.0090,  0.0141],\n",
       "                       ...,\n",
       "                       [-0.0025,  0.0186,  0.0035],\n",
       "                       [ 0.0040, -0.0212, -0.0115],\n",
       "                       [-0.0015,  0.0223,  0.0028]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0234,  0.0159, -0.0034],\n",
       "                       [-0.0154, -0.0099,  0.0112],\n",
       "                       [ 0.0004, -0.0162, -0.0019],\n",
       "                       ...,\n",
       "                       [-0.0243, -0.0042, -0.0200],\n",
       "                       [ 0.0056,  0.0026, -0.0118],\n",
       "                       [-0.0251,  0.0203, -0.0164]],\n",
       "              \n",
       "                      [[-0.0094,  0.0029,  0.0240],\n",
       "                       [ 0.0092,  0.0122, -0.0175],\n",
       "                       [-0.0106, -0.0224,  0.0205],\n",
       "                       ...,\n",
       "                       [ 0.0094,  0.0147, -0.0183],\n",
       "                       [ 0.0178, -0.0087, -0.0082],\n",
       "                       [ 0.0144,  0.0130, -0.0236]],\n",
       "              \n",
       "                      [[-0.0054,  0.0078, -0.0164],\n",
       "                       [-0.0031,  0.0075, -0.0142],\n",
       "                       [ 0.0150,  0.0070,  0.0176],\n",
       "                       ...,\n",
       "                       [ 0.0239, -0.0060, -0.0129],\n",
       "                       [ 0.0054,  0.0193,  0.0009],\n",
       "                       [-0.0217, -0.0132, -0.0063]]])),\n",
       "             ('__S__.tdnn2.0.bias',\n",
       "              tensor([-1.4222e-02,  1.2266e-02, -9.2187e-03,  1.0356e-02, -6.8833e-03,\n",
       "                      -5.3937e-03,  2.3555e-02, -7.0714e-03, -2.4058e-02,  2.1791e-02,\n",
       "                       1.2158e-02, -7.8424e-04,  6.2325e-04, -2.3522e-02,  9.7166e-03,\n",
       "                      -1.2461e-02,  1.9153e-02,  1.7377e-02,  9.7963e-03,  2.2881e-02,\n",
       "                       7.3936e-03, -3.3218e-03,  9.0691e-03, -3.8945e-04,  3.7289e-03,\n",
       "                       1.9572e-02,  2.0036e-04, -1.6830e-02,  2.2875e-02,  2.1188e-02,\n",
       "                      -1.4945e-02,  8.4366e-03, -8.3212e-03, -6.4731e-03,  5.4817e-03,\n",
       "                      -1.1957e-02, -2.0802e-03,  2.0115e-02,  1.9645e-02, -1.9704e-03,\n",
       "                      -2.4272e-02, -1.8098e-03,  1.1165e-02, -3.1457e-03, -1.5682e-03,\n",
       "                       1.2992e-02, -1.9219e-02,  5.8960e-03,  1.6375e-02,  4.3268e-03,\n",
       "                      -2.1723e-02, -1.7311e-02,  2.2045e-02,  1.7993e-02,  1.8017e-02,\n",
       "                       1.0208e-02, -1.3824e-02, -2.6385e-04, -4.6527e-03, -8.2718e-03,\n",
       "                       2.1415e-02, -1.7219e-02,  2.5126e-03,  3.1609e-04, -2.3843e-02,\n",
       "                      -1.3092e-02, -2.3397e-02, -1.6504e-02,  7.3695e-03,  1.6649e-02,\n",
       "                      -1.9316e-02, -1.6868e-02,  1.2635e-02, -1.7271e-02, -2.1228e-02,\n",
       "                      -1.4394e-02,  7.8286e-03, -8.9021e-03,  1.3911e-02,  2.3634e-02,\n",
       "                      -3.7420e-03,  2.4027e-02,  1.2371e-03, -6.1385e-03,  5.6420e-03,\n",
       "                      -3.1108e-03,  3.6590e-03, -5.7734e-03,  1.2307e-02,  1.3401e-02,\n",
       "                      -1.6480e-02,  1.0562e-02, -1.9665e-03,  1.7607e-02,  6.3656e-03,\n",
       "                      -2.2083e-02, -8.0709e-03, -2.5397e-02, -1.0977e-03,  1.8088e-02,\n",
       "                      -1.3989e-02,  2.4155e-02, -1.4817e-02, -2.1272e-02, -9.4426e-03,\n",
       "                      -4.9423e-03, -1.5084e-02, -8.8722e-03,  2.2957e-02,  2.1598e-02,\n",
       "                      -2.0179e-02, -7.7462e-03,  2.1082e-02,  1.8155e-02, -1.7733e-02,\n",
       "                      -8.0361e-03, -2.1397e-02,  9.7367e-03, -5.6435e-03,  1.9180e-02,\n",
       "                      -2.5894e-03, -1.4960e-02,  2.5117e-02, -4.3130e-03, -3.2984e-03,\n",
       "                      -2.3926e-02,  9.4758e-03, -3.7726e-03,  1.0502e-02,  5.1651e-03,\n",
       "                       2.4409e-03,  3.3642e-03,  6.7007e-03, -2.1415e-02,  1.7654e-02,\n",
       "                      -1.0044e-02, -1.3423e-02,  1.0330e-02, -3.7896e-03, -1.7435e-02,\n",
       "                       2.5892e-03, -1.9737e-03, -2.1466e-02,  1.8932e-02, -2.0796e-03,\n",
       "                       2.1118e-02, -2.5258e-02,  7.6999e-03, -9.9569e-03, -1.8860e-02,\n",
       "                      -1.2738e-02,  9.6707e-03,  9.5509e-03, -5.5543e-03,  6.2219e-03,\n",
       "                      -9.2841e-03, -1.4191e-02,  2.0556e-02,  2.3415e-02, -7.4605e-03,\n",
       "                       5.0702e-03, -2.0327e-02,  1.2536e-02, -7.0013e-03,  1.7234e-02,\n",
       "                      -1.1163e-02, -1.4340e-02, -8.4265e-03,  2.4326e-02,  1.8776e-02,\n",
       "                      -1.1664e-02, -7.8462e-03, -2.3582e-02, -2.1370e-02,  2.4135e-02,\n",
       "                      -2.1151e-02, -2.4583e-02, -1.6544e-02, -1.8092e-02, -5.2859e-03,\n",
       "                       1.1107e-02,  2.2142e-02,  2.0234e-03, -1.3031e-02, -1.7249e-02,\n",
       "                       2.2023e-02,  7.8325e-03, -1.6514e-03,  2.4671e-02,  2.4186e-02,\n",
       "                      -1.6071e-02, -2.1630e-02,  4.3053e-03, -1.2321e-02,  2.0102e-02,\n",
       "                       1.5066e-02,  5.7595e-03,  1.5195e-02, -2.3413e-02, -7.9518e-03,\n",
       "                       1.5637e-02, -1.8819e-02, -3.5305e-03, -5.3056e-03, -2.3642e-02,\n",
       "                      -1.4505e-02,  2.4743e-02,  1.7717e-02,  1.1939e-02, -2.2104e-02,\n",
       "                      -1.6603e-02,  9.5191e-03,  4.9707e-05,  1.3473e-02, -1.8428e-02,\n",
       "                       1.5097e-02, -2.0648e-03, -9.6945e-03, -1.7744e-02,  1.3738e-02,\n",
       "                       5.9211e-03,  2.2390e-02, -2.3430e-02, -1.4382e-03,  1.7833e-02,\n",
       "                       6.5364e-03,  2.2926e-02, -2.4699e-02, -2.1118e-02,  3.0730e-04,\n",
       "                       1.3488e-02,  6.0480e-03,  2.1114e-03,  2.3120e-02, -4.5682e-03,\n",
       "                      -1.4121e-02,  9.5474e-03, -1.7839e-02,  9.8831e-03, -4.8561e-03,\n",
       "                       2.0196e-02, -7.4500e-03, -2.0294e-02, -8.5459e-03, -9.6827e-04,\n",
       "                       2.3735e-02,  2.1191e-03,  2.0475e-02, -2.4522e-02, -1.9885e-02,\n",
       "                      -2.3634e-02,  3.7965e-04,  1.7150e-02,  1.5719e-02,  2.1979e-03,\n",
       "                      -2.5126e-02, -5.1536e-03, -6.0249e-03,  6.0619e-03,  2.1001e-02,\n",
       "                      -1.3410e-02, -1.8632e-02, -1.7675e-04,  1.8982e-02, -2.4001e-02,\n",
       "                      -1.9236e-02, -1.5040e-02,  1.7307e-02, -1.6319e-02, -9.7832e-03,\n",
       "                       1.5657e-02,  2.4729e-02,  2.2883e-02,  1.1455e-03, -5.5433e-03,\n",
       "                       2.3802e-03,  1.3456e-02,  5.0085e-03, -1.5372e-02, -6.0970e-03,\n",
       "                       4.5651e-03,  2.3338e-02, -1.8547e-02, -5.2437e-03,  1.5525e-02,\n",
       "                      -1.3041e-02,  4.6142e-03,  1.3785e-03,  6.7429e-03, -5.6421e-03,\n",
       "                      -4.0686e-03, -1.1533e-02, -2.5283e-02, -5.7880e-03, -1.3124e-02,\n",
       "                       6.9868e-03, -2.1623e-02, -1.1526e-02, -1.7999e-02,  1.3508e-02,\n",
       "                       1.4487e-03,  7.4739e-03, -1.5438e-02, -1.6691e-02, -2.3553e-02,\n",
       "                      -2.1713e-03, -1.6825e-02, -1.3696e-02, -1.1457e-03,  1.5676e-02,\n",
       "                      -2.4640e-02,  1.8183e-02,  1.9784e-02, -1.5690e-02,  2.3676e-02,\n",
       "                      -6.5231e-03, -6.6435e-03, -2.5494e-02, -1.4004e-02,  1.3053e-02,\n",
       "                       1.7420e-02,  2.2794e-03, -6.4025e-03,  1.6053e-02,  2.5121e-02,\n",
       "                      -2.3840e-02,  1.4741e-03, -1.9594e-02, -7.0558e-03, -1.9358e-02,\n",
       "                       2.0071e-02, -2.0986e-02,  1.0067e-02, -3.3684e-03,  2.5370e-02,\n",
       "                       1.6489e-02,  3.1021e-03, -3.8855e-03,  7.0289e-03,  1.8303e-02,\n",
       "                       2.3633e-02, -7.3465e-03,  9.3258e-03, -2.5044e-02,  2.3166e-02,\n",
       "                       1.0766e-02,  1.1399e-02,  1.4462e-02, -1.6338e-02, -3.9989e-03,\n",
       "                      -6.2925e-03,  1.5868e-02,  2.3622e-02, -1.0488e-02, -2.5921e-03,\n",
       "                       2.3792e-02,  1.5430e-02,  4.3626e-03, -2.0024e-02, -1.3095e-02,\n",
       "                      -9.0591e-03, -1.3603e-02, -5.1387e-03,  1.4565e-02,  2.0691e-02,\n",
       "                      -2.1079e-02, -1.2463e-02,  2.2420e-02, -4.4231e-03, -1.3302e-02,\n",
       "                      -3.6154e-03, -2.1624e-02, -1.0776e-02, -3.2818e-04, -2.5342e-03,\n",
       "                       1.4891e-02, -1.6952e-02, -1.5457e-03, -1.7076e-02,  1.6353e-02,\n",
       "                       1.0669e-03, -2.9554e-03,  1.1908e-02, -9.2411e-03, -2.2205e-02,\n",
       "                       2.4879e-02, -1.7554e-02,  1.9303e-02,  1.7735e-02, -1.8927e-02,\n",
       "                       7.7002e-03, -1.3819e-02,  1.6119e-02,  1.2976e-02,  2.0005e-02,\n",
       "                       4.9640e-03, -2.0413e-02,  1.1255e-02,  2.9413e-03,  2.2818e-02,\n",
       "                       1.1405e-02, -1.8204e-02,  5.0312e-03,  7.2009e-03,  2.4142e-02,\n",
       "                       8.9092e-03, -1.0756e-04,  2.4993e-02,  1.2250e-02, -1.9575e-02,\n",
       "                       9.0941e-03, -2.2128e-02,  1.0677e-02,  6.5316e-03,  1.4514e-02,\n",
       "                      -2.3672e-02, -1.0513e-02, -1.0216e-02, -1.1484e-02,  2.6113e-03,\n",
       "                       2.4558e-02,  6.5544e-03,  2.3963e-02, -1.5001e-02, -6.1973e-03,\n",
       "                       2.3334e-02, -1.9570e-02,  1.7806e-02, -8.8015e-03, -9.8613e-03,\n",
       "                       2.4263e-02,  8.0180e-04,  1.2237e-02, -1.1740e-02,  2.6031e-03,\n",
       "                      -3.7717e-03, -2.4540e-02, -1.5924e-02,  1.3982e-02,  1.2489e-02,\n",
       "                      -1.1507e-03,  2.3493e-02, -2.3561e-02, -1.0206e-02,  1.6744e-02,\n",
       "                      -1.7922e-02,  2.3257e-02, -1.7006e-02,  1.9299e-02, -1.2102e-02,\n",
       "                      -1.4461e-02,  1.4814e-02, -2.3477e-02, -4.8671e-03, -1.6340e-03,\n",
       "                       1.7526e-02,  2.2135e-02, -2.3618e-02, -2.2416e-02, -1.2816e-02,\n",
       "                      -2.0135e-02,  7.7553e-04, -1.1973e-02, -6.7282e-03, -1.6196e-02,\n",
       "                       1.9982e-02, -1.0032e-02, -6.2954e-03, -1.5926e-02,  1.3992e-03,\n",
       "                      -5.7690e-03, -1.9201e-02, -5.6930e-03,  2.8703e-03, -8.9832e-03,\n",
       "                      -1.9717e-02,  1.9249e-02, -3.5901e-03, -5.7033e-03, -8.0994e-03,\n",
       "                      -9.9780e-03, -6.9180e-03,  1.1724e-03,  1.6251e-02, -7.7720e-03,\n",
       "                       1.7628e-02, -1.5657e-02,  2.0949e-03,  2.3423e-02, -4.3998e-03,\n",
       "                       2.5305e-02,  1.0836e-02,  1.3011e-02,  4.9767e-03, -1.6489e-02,\n",
       "                       2.1197e-02,  1.1996e-02,  1.3164e-02, -1.1514e-02, -9.8646e-03,\n",
       "                      -2.0917e-02,  7.0743e-03,  1.4061e-02, -1.3463e-02, -2.0865e-02,\n",
       "                      -9.4157e-03,  2.3009e-02, -1.4475e-02,  3.7430e-04, -2.1384e-02,\n",
       "                       2.2898e-02, -3.7045e-03])),\n",
       "             ('__S__.tdnn2.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn2.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn2.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn2.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn2.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn3.0.weight',\n",
       "              tensor([[[-0.0229,  0.0078,  0.0016],\n",
       "                       [-0.0170, -0.0083,  0.0254],\n",
       "                       [-0.0109, -0.0134, -0.0115],\n",
       "                       ...,\n",
       "                       [-0.0171,  0.0069,  0.0189],\n",
       "                       [ 0.0030,  0.0009,  0.0166],\n",
       "                       [-0.0165, -0.0213,  0.0079]],\n",
       "              \n",
       "                      [[-0.0118,  0.0041,  0.0039],\n",
       "                       [-0.0221, -0.0115,  0.0176],\n",
       "                       [-0.0228,  0.0242,  0.0203],\n",
       "                       ...,\n",
       "                       [-0.0012,  0.0109, -0.0225],\n",
       "                       [-0.0059,  0.0179, -0.0192],\n",
       "                       [ 0.0008,  0.0177,  0.0151]],\n",
       "              \n",
       "                      [[-0.0103,  0.0094,  0.0022],\n",
       "                       [-0.0184,  0.0108, -0.0233],\n",
       "                       [-0.0066, -0.0225,  0.0185],\n",
       "                       ...,\n",
       "                       [ 0.0203,  0.0189, -0.0081],\n",
       "                       [-0.0129,  0.0244, -0.0251],\n",
       "                       [ 0.0080, -0.0050,  0.0245]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0178, -0.0209,  0.0037],\n",
       "                       [ 0.0198, -0.0153, -0.0163],\n",
       "                       [ 0.0010, -0.0030,  0.0017],\n",
       "                       ...,\n",
       "                       [-0.0008,  0.0046, -0.0047],\n",
       "                       [-0.0140, -0.0230, -0.0075],\n",
       "                       [ 0.0131, -0.0158, -0.0205]],\n",
       "              \n",
       "                      [[ 0.0091, -0.0021,  0.0240],\n",
       "                       [-0.0194,  0.0024, -0.0162],\n",
       "                       [-0.0191,  0.0019, -0.0200],\n",
       "                       ...,\n",
       "                       [-0.0169, -0.0233, -0.0070],\n",
       "                       [ 0.0179, -0.0085,  0.0125],\n",
       "                       [ 0.0192,  0.0039,  0.0015]],\n",
       "              \n",
       "                      [[-0.0039,  0.0050, -0.0069],\n",
       "                       [-0.0191,  0.0021, -0.0016],\n",
       "                       [ 0.0061,  0.0224,  0.0034],\n",
       "                       ...,\n",
       "                       [-0.0121,  0.0103,  0.0191],\n",
       "                       [-0.0128, -0.0168,  0.0133],\n",
       "                       [-0.0098, -0.0139,  0.0092]]])),\n",
       "             ('__S__.tdnn3.0.bias',\n",
       "              tensor([-2.2601e-02, -3.8762e-03,  3.3697e-03,  4.4517e-03,  4.8219e-03,\n",
       "                       2.0293e-03, -7.4470e-03, -1.0319e-02, -1.2063e-02,  2.1350e-03,\n",
       "                       2.3954e-02, -1.9183e-02,  9.8305e-03,  8.1325e-04, -1.6426e-02,\n",
       "                      -1.5857e-02,  1.7180e-02, -1.4932e-02, -5.9951e-03,  1.3610e-02,\n",
       "                      -3.5420e-03,  3.5968e-03, -1.6474e-02,  1.6798e-02, -2.1174e-02,\n",
       "                      -1.0885e-02, -1.5937e-02, -1.7538e-02,  1.1635e-03, -1.9036e-03,\n",
       "                       3.0145e-03,  6.9190e-03, -1.0986e-02,  2.5208e-02,  1.6609e-02,\n",
       "                      -8.9742e-03, -9.4197e-03,  1.4880e-02,  1.9096e-02, -3.9555e-03,\n",
       "                       2.1063e-02, -2.5447e-02,  1.6194e-02,  9.1560e-03, -1.2586e-02,\n",
       "                       1.1750e-02,  1.0976e-02, -2.3503e-02,  2.0845e-02,  9.4207e-03,\n",
       "                       1.2033e-02,  2.1159e-02,  1.3190e-02, -8.8513e-03, -1.6639e-02,\n",
       "                      -6.3803e-03, -1.0963e-02, -1.4464e-02, -1.4928e-02,  1.2063e-02,\n",
       "                       8.8372e-03,  1.4489e-02, -2.0762e-02, -1.3215e-02,  1.9491e-02,\n",
       "                       2.1174e-02,  2.0455e-02,  7.8522e-03,  1.1947e-02, -9.6868e-03,\n",
       "                       1.2003e-02, -4.5976e-03,  2.1395e-02, -5.4812e-03, -1.0613e-03,\n",
       "                      -1.2537e-02, -3.9876e-03,  1.4596e-02,  2.2940e-02, -1.7378e-02,\n",
       "                      -2.8606e-03,  1.7135e-04,  7.8554e-03, -1.5792e-02, -3.8008e-03,\n",
       "                      -1.5091e-02,  6.0938e-03, -2.1174e-02, -2.2564e-02, -1.7931e-02,\n",
       "                       2.2138e-02, -1.0661e-02,  2.3635e-02,  1.9605e-02, -2.2306e-02,\n",
       "                      -2.2874e-02,  8.1617e-03, -5.1707e-04, -1.0355e-02,  1.2237e-02,\n",
       "                       6.8230e-03, -5.7056e-03, -2.2204e-02,  1.9300e-02,  1.2902e-02,\n",
       "                      -1.4612e-02,  4.2615e-03,  9.9983e-03,  1.4371e-02, -2.9826e-03,\n",
       "                      -1.1550e-02,  7.1524e-03, -4.8312e-03, -1.3498e-02, -2.4978e-02,\n",
       "                      -9.5320e-03, -2.5419e-02, -1.4105e-02, -3.2404e-03, -1.0801e-02,\n",
       "                      -1.0546e-02,  1.7413e-02,  1.4872e-02,  3.8445e-03,  2.1733e-02,\n",
       "                      -1.8104e-02,  1.1102e-02,  1.4539e-02, -3.9540e-03,  3.2909e-03,\n",
       "                       2.1679e-02,  1.2448e-02,  4.0128e-04,  4.9261e-03, -1.0304e-02,\n",
       "                      -1.0842e-02,  1.9794e-02,  2.4776e-02,  2.3794e-02, -3.0890e-03,\n",
       "                       2.5026e-02, -2.1832e-02, -2.1268e-04,  1.0448e-02, -8.5664e-03,\n",
       "                       6.7025e-03,  2.0029e-02, -2.5088e-02, -9.2922e-03, -2.2903e-02,\n",
       "                       1.5497e-02,  1.1287e-02, -2.0997e-02,  6.4860e-03, -5.3903e-03,\n",
       "                       1.2409e-02, -2.9595e-03,  1.2223e-02, -1.8576e-04, -7.3416e-03,\n",
       "                      -8.0846e-03, -3.1198e-03,  2.9917e-03, -9.2033e-04, -2.3751e-02,\n",
       "                       1.6790e-02,  1.6125e-03, -1.8061e-02,  6.7311e-03, -1.4120e-03,\n",
       "                       1.0349e-02, -2.4983e-02,  1.7725e-02,  1.7637e-02, -7.4579e-04,\n",
       "                      -2.0063e-02,  6.7935e-03, -1.4256e-02,  1.3856e-02, -2.1316e-02,\n",
       "                      -5.9798e-03,  1.7938e-02, -2.4791e-02, -2.1314e-02,  2.5461e-02,\n",
       "                       1.6386e-02,  8.7120e-03, -1.2340e-02,  1.0240e-02,  2.1145e-02,\n",
       "                       1.9590e-02,  1.7399e-02, -1.3619e-04, -5.0606e-03,  5.7608e-04,\n",
       "                      -8.1125e-03, -1.3552e-02,  8.1082e-04,  2.1526e-02,  7.0061e-03,\n",
       "                      -2.3285e-02, -9.1774e-03, -1.4762e-02,  1.5736e-02,  1.9833e-02,\n",
       "                      -2.2074e-02, -1.8856e-02,  3.6536e-03,  1.4594e-02,  1.5593e-02,\n",
       "                       2.0486e-02, -1.4410e-02, -3.1757e-03,  1.9905e-03, -3.4839e-03,\n",
       "                       9.5239e-03,  1.0045e-02, -1.9861e-02, -1.0834e-02, -5.4680e-05,\n",
       "                      -2.5002e-02,  3.6168e-03, -2.1132e-02, -8.4794e-03,  7.8348e-03,\n",
       "                       2.3225e-02,  1.5407e-02, -4.8016e-03, -1.3011e-02,  7.8205e-03,\n",
       "                      -2.4247e-02, -3.6600e-03,  2.2119e-02, -2.3281e-02, -1.1587e-02,\n",
       "                      -5.7926e-03, -1.2657e-02,  1.0073e-02, -2.0285e-02,  1.2949e-02,\n",
       "                      -1.0213e-02,  1.2539e-02, -7.7986e-03, -1.6004e-02, -6.3676e-03,\n",
       "                       1.5746e-02,  5.5768e-03, -1.8041e-02,  1.4096e-02,  5.9269e-04,\n",
       "                      -6.1763e-03,  1.5410e-02,  6.5497e-03, -1.6260e-02, -1.6813e-02,\n",
       "                       2.0994e-03,  7.9001e-03, -1.7722e-02, -9.6670e-03, -2.3238e-02,\n",
       "                      -2.5497e-02, -4.7793e-03,  1.8747e-02,  2.2392e-02,  1.5180e-02,\n",
       "                       2.3847e-02, -1.7832e-02,  1.1738e-02,  2.3423e-02, -1.9616e-02,\n",
       "                       2.2189e-02,  7.8885e-03, -2.3102e-02, -4.5879e-03, -1.5300e-02,\n",
       "                      -5.7948e-03, -8.3203e-03, -1.8798e-02,  2.4812e-02,  1.6801e-02,\n",
       "                      -1.5480e-03, -1.0918e-02, -1.5810e-02, -2.0950e-02, -2.5385e-02,\n",
       "                       3.8341e-03, -2.2267e-02, -1.3967e-03,  6.8777e-03,  7.4658e-04,\n",
       "                       1.3178e-02,  7.8954e-03,  8.3044e-03,  4.7887e-03,  1.2558e-02,\n",
       "                       2.4760e-02,  2.4834e-03,  4.0910e-03, -2.1307e-02,  2.0086e-02,\n",
       "                       1.2443e-03,  5.6497e-04,  1.9583e-02,  1.1659e-02, -1.3871e-02,\n",
       "                       2.3285e-02, -8.9017e-03, -1.0995e-02, -1.0121e-02,  5.3366e-03,\n",
       "                      -7.4986e-03, -2.1392e-02, -2.1119e-02, -2.4709e-02,  1.1931e-02,\n",
       "                       2.1518e-02,  8.8515e-03, -1.8802e-02, -9.4775e-03,  9.5812e-03,\n",
       "                       1.2697e-02,  8.9736e-03,  1.4154e-02, -1.9564e-02,  2.0681e-02,\n",
       "                       1.4188e-02,  2.3692e-02, -8.1231e-03, -1.1903e-02, -2.0180e-02,\n",
       "                      -2.2698e-02,  1.8216e-02,  1.7578e-05,  7.1059e-03,  1.9199e-02,\n",
       "                      -2.0264e-02, -9.0161e-03,  1.8790e-02, -1.6193e-02, -1.1524e-03,\n",
       "                      -3.6202e-05, -2.3931e-02,  1.0962e-02,  2.1133e-03,  1.7792e-02,\n",
       "                       1.4340e-02, -1.4286e-02,  1.3403e-02, -1.2444e-02, -7.8574e-03,\n",
       "                       7.6194e-03,  3.3333e-03,  1.8063e-02, -1.7247e-02,  1.1642e-02,\n",
       "                       1.4148e-02,  2.0241e-02,  1.4131e-02,  1.1988e-02, -1.8255e-02,\n",
       "                       5.1446e-03, -2.0562e-03, -8.1819e-04, -4.7332e-03,  1.4576e-02,\n",
       "                      -2.3944e-02,  1.8521e-02,  2.0032e-02,  9.9497e-03, -1.3807e-02,\n",
       "                      -1.0317e-03,  9.8103e-03, -9.4638e-03, -5.4793e-03,  2.0663e-02,\n",
       "                      -1.6271e-02, -2.2825e-02, -4.9688e-03, -1.7008e-02, -2.0832e-02,\n",
       "                       2.0663e-02, -1.3890e-02, -2.4789e-02, -2.5443e-02,  2.3578e-02,\n",
       "                      -1.9585e-02, -4.3555e-04, -2.3285e-02,  1.3480e-02, -2.3654e-02,\n",
       "                       2.1416e-02, -7.3319e-03, -2.3788e-02, -7.3927e-03, -3.9029e-03,\n",
       "                       2.0051e-02, -1.6857e-02,  2.5074e-02, -1.8191e-02,  7.6259e-03,\n",
       "                       5.1879e-03, -1.6905e-02, -1.7273e-03,  1.8219e-03,  9.9717e-03,\n",
       "                       3.8754e-03,  1.6902e-02, -5.6131e-03,  4.7569e-03, -1.5454e-02,\n",
       "                       2.2951e-02,  1.7261e-02,  6.1743e-03, -2.4627e-04,  6.3318e-03,\n",
       "                       2.1959e-02,  1.1858e-02, -1.2683e-03,  1.3460e-02,  2.4521e-02,\n",
       "                       2.5640e-03,  2.4161e-02, -1.4085e-03,  1.3474e-02,  1.0281e-02,\n",
       "                       2.0366e-02, -2.0133e-02,  1.8657e-02, -2.2846e-02, -2.3879e-02,\n",
       "                       1.4762e-02, -2.7277e-03,  1.7620e-02,  1.6483e-02, -1.8457e-02,\n",
       "                      -2.1519e-02,  1.1146e-02, -1.6067e-02, -2.9458e-03, -3.2326e-03,\n",
       "                       1.7140e-03, -3.6957e-03,  3.3231e-03, -9.1342e-03, -3.7684e-03,\n",
       "                       1.1891e-02,  2.0576e-02,  2.1636e-02,  1.1915e-02, -6.3280e-03,\n",
       "                       1.8136e-02, -1.3064e-02,  5.5319e-03, -2.2187e-02,  1.8720e-04,\n",
       "                       1.9529e-02,  3.6148e-03,  2.4075e-02, -9.6008e-03,  1.7036e-04,\n",
       "                      -1.0401e-02, -1.8021e-02, -3.7382e-03,  2.4679e-02, -7.2719e-03,\n",
       "                       9.1436e-03,  3.8174e-03, -4.7193e-03, -1.4345e-02, -2.5430e-02,\n",
       "                      -2.0612e-02,  2.2033e-02, -1.8103e-02,  1.0685e-02,  2.1724e-03,\n",
       "                      -1.5186e-02, -1.4375e-02,  2.3949e-03, -9.1202e-03, -2.9944e-03,\n",
       "                       7.0771e-05,  2.2133e-02,  1.5544e-02, -3.9801e-04, -9.3464e-03,\n",
       "                       8.8630e-03,  2.3889e-02, -1.0486e-02, -1.6026e-02, -1.3433e-02,\n",
       "                       1.8756e-02, -1.5501e-02,  2.3155e-02,  6.2286e-03,  8.7450e-03,\n",
       "                       6.8904e-03,  1.4150e-02,  1.6630e-02,  1.0005e-02, -5.7465e-03,\n",
       "                      -3.7619e-03, -7.1171e-03, -1.6442e-02, -1.9171e-02, -1.3702e-02,\n",
       "                      -3.1802e-03, -1.6405e-02,  1.5797e-03,  1.4794e-02, -4.5666e-03,\n",
       "                      -6.2521e-03, -1.6091e-02])),\n",
       "             ('__S__.tdnn3.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn3.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn3.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn3.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn3.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn4.0.weight',\n",
       "              tensor([[[ 0.0202],\n",
       "                       [-0.0173],\n",
       "                       [-0.0175],\n",
       "                       ...,\n",
       "                       [-0.0245],\n",
       "                       [-0.0192],\n",
       "                       [-0.0410]],\n",
       "              \n",
       "                      [[-0.0222],\n",
       "                       [ 0.0230],\n",
       "                       [-0.0051],\n",
       "                       ...,\n",
       "                       [ 0.0427],\n",
       "                       [ 0.0275],\n",
       "                       [ 0.0279]],\n",
       "              \n",
       "                      [[-0.0213],\n",
       "                       [-0.0354],\n",
       "                       [ 0.0077],\n",
       "                       ...,\n",
       "                       [ 0.0275],\n",
       "                       [ 0.0349],\n",
       "                       [-0.0359]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0220],\n",
       "                       [-0.0006],\n",
       "                       [-0.0326],\n",
       "                       ...,\n",
       "                       [ 0.0115],\n",
       "                       [ 0.0118],\n",
       "                       [ 0.0028]],\n",
       "              \n",
       "                      [[-0.0278],\n",
       "                       [ 0.0164],\n",
       "                       [-0.0116],\n",
       "                       ...,\n",
       "                       [-0.0349],\n",
       "                       [ 0.0266],\n",
       "                       [ 0.0378]],\n",
       "              \n",
       "                      [[-0.0033],\n",
       "                       [ 0.0311],\n",
       "                       [-0.0131],\n",
       "                       ...,\n",
       "                       [ 0.0417],\n",
       "                       [-0.0433],\n",
       "                       [-0.0063]]])),\n",
       "             ('__S__.tdnn4.0.bias',\n",
       "              tensor([-3.9521e-02, -1.3964e-02, -5.8618e-03, -1.1828e-02,  1.7036e-02,\n",
       "                      -3.2960e-02,  1.7691e-03,  1.1719e-02, -7.2136e-03,  3.8725e-04,\n",
       "                      -2.4402e-02,  1.6353e-02,  8.3455e-03, -2.2517e-02, -2.1743e-02,\n",
       "                       3.9909e-02,  1.1072e-02, -1.4706e-02, -4.4071e-02,  1.7243e-02,\n",
       "                      -2.2479e-02,  3.8230e-02,  2.5368e-02,  2.2699e-02,  1.6840e-02,\n",
       "                      -6.1671e-03,  2.3430e-02,  3.2418e-03, -4.2470e-02, -2.4065e-02,\n",
       "                      -3.4568e-02, -2.4667e-02, -3.6610e-02,  3.4013e-02,  6.2310e-03,\n",
       "                       5.0414e-03, -1.2908e-02,  8.0380e-03, -2.8141e-02,  1.5530e-02,\n",
       "                      -5.5195e-03,  3.0129e-03,  9.3967e-03,  2.0002e-02,  4.1527e-02,\n",
       "                       1.7917e-02,  4.4139e-02, -4.6196e-03,  3.1983e-02,  9.9266e-03,\n",
       "                      -1.9886e-02, -1.1085e-02, -2.6320e-02,  2.8755e-02, -3.9933e-02,\n",
       "                       2.7551e-02,  2.2824e-02, -2.9851e-02, -2.7588e-02, -2.5049e-03,\n",
       "                       2.1449e-02, -2.3188e-02, -2.2580e-02, -1.9647e-03, -3.2997e-02,\n",
       "                      -4.0659e-03, -2.4484e-02, -6.4936e-04,  2.5815e-02,  2.1973e-02,\n",
       "                      -8.2288e-03, -3.9827e-02, -1.6853e-02,  4.3692e-02,  3.5592e-02,\n",
       "                       2.2377e-02,  4.1195e-02, -5.2968e-03, -3.5317e-02,  2.6829e-02,\n",
       "                       3.0681e-02,  4.1176e-02,  3.0817e-02,  7.4884e-03, -9.8538e-03,\n",
       "                       2.2392e-02,  7.0795e-04,  7.7075e-03,  4.0728e-03, -3.5539e-02,\n",
       "                       2.2607e-02, -3.0291e-02,  4.3890e-02,  3.0481e-02, -2.4451e-02,\n",
       "                       2.6951e-02, -1.7527e-02, -3.0061e-02,  3.4751e-02,  3.7448e-04,\n",
       "                      -3.6784e-02, -3.1944e-02,  2.0617e-02,  1.9557e-02, -3.8455e-03,\n",
       "                      -4.1093e-02,  1.5691e-02, -1.3667e-02,  2.0819e-02,  3.4596e-02,\n",
       "                       1.0457e-03, -6.5855e-03, -7.4990e-03,  1.2416e-02, -7.4223e-03,\n",
       "                       1.9316e-03,  3.3916e-02, -2.2333e-02, -4.0313e-02,  2.2585e-02,\n",
       "                      -3.6825e-02, -1.9322e-02,  3.9437e-02, -7.6470e-03,  7.2620e-03,\n",
       "                       4.0330e-02, -3.6669e-02, -3.5452e-03, -1.0397e-02,  9.1176e-03,\n",
       "                       1.4272e-02,  4.8757e-03,  2.5169e-02,  4.2788e-02, -5.2970e-03,\n",
       "                      -3.7749e-02, -2.7060e-02,  2.1552e-03,  1.4486e-02, -2.9869e-02,\n",
       "                       2.7639e-02, -2.4674e-02,  3.0899e-02, -3.5810e-02,  9.2086e-03,\n",
       "                       4.0748e-02,  3.5959e-02, -3.7505e-02, -3.7186e-02,  1.1982e-02,\n",
       "                       1.9935e-02,  3.9047e-02, -4.3048e-02, -3.5767e-02,  2.5894e-02,\n",
       "                      -2.8207e-02,  3.5305e-02,  7.0999e-04, -1.9609e-02, -1.2114e-02,\n",
       "                       1.4795e-03, -5.7700e-03, -4.1595e-02, -4.3823e-02,  2.5801e-02,\n",
       "                      -8.9345e-03,  2.4052e-02,  2.2221e-03,  4.2612e-02, -2.4605e-02,\n",
       "                       8.9763e-03, -3.2922e-02, -2.3218e-02, -3.8887e-02,  2.8612e-02,\n",
       "                      -2.0098e-02, -1.2955e-02, -1.6202e-02, -9.0409e-03,  5.3171e-03,\n",
       "                      -8.9959e-03, -2.5277e-02,  3.1513e-02, -1.9969e-02, -3.8689e-02,\n",
       "                      -4.3038e-02, -3.2809e-02,  4.0176e-02,  2.8451e-02, -1.2894e-02,\n",
       "                      -2.6763e-02,  2.8733e-03,  2.5885e-02,  2.6327e-02,  2.5144e-02,\n",
       "                       1.1239e-02,  6.5606e-03, -2.1276e-03,  2.2919e-02, -3.7771e-02,\n",
       "                       3.9726e-02, -4.3352e-02, -4.1698e-02,  1.3385e-02, -1.5596e-02,\n",
       "                       1.0952e-02, -2.6959e-02, -3.0486e-02,  7.7101e-03, -2.9675e-02,\n",
       "                      -1.7148e-02,  3.1716e-02,  2.9144e-03,  2.9590e-02, -4.1186e-02,\n",
       "                      -8.1675e-03, -2.2636e-02,  2.4151e-02, -6.6595e-03,  1.4392e-02,\n",
       "                       4.2879e-02, -3.9360e-02, -1.0424e-02, -6.2076e-03,  6.3926e-04,\n",
       "                       2.6553e-06,  1.2715e-02,  1.6164e-02,  6.5457e-04,  3.7942e-02,\n",
       "                       4.2867e-02,  2.2610e-02, -1.6393e-02,  2.1763e-02, -1.6172e-02,\n",
       "                      -2.0853e-02, -3.1756e-02, -3.6017e-03, -6.7043e-03,  7.9934e-04,\n",
       "                      -2.6433e-02,  1.5433e-02, -3.5738e-02, -4.1740e-02,  3.7924e-02,\n",
       "                      -2.3842e-02,  3.9347e-02,  1.1469e-02, -3.5631e-02, -3.6123e-02,\n",
       "                      -8.5721e-03,  1.2621e-02,  1.6850e-02, -1.3785e-02,  3.8712e-02,\n",
       "                       4.5542e-03, -2.0739e-03,  1.5983e-03,  1.6469e-02, -2.0746e-03,\n",
       "                      -8.9429e-03,  1.7788e-02,  1.3988e-02, -3.5315e-02,  2.1591e-03,\n",
       "                       6.5030e-04,  5.2022e-03, -1.8971e-02,  8.6891e-03, -4.2265e-02,\n",
       "                      -2.8781e-02, -2.1885e-02, -1.9439e-02, -1.5539e-02, -3.8935e-02,\n",
       "                      -2.7044e-02, -2.7033e-02, -1.7785e-02, -2.5535e-02,  2.1723e-03,\n",
       "                       4.3042e-02,  3.9042e-02,  1.4768e-02, -4.0979e-02, -1.0971e-02,\n",
       "                      -4.3522e-02,  3.7301e-02,  2.5817e-02, -3.8092e-02,  2.3361e-02,\n",
       "                      -2.2811e-02, -1.8811e-02,  9.5936e-03, -2.9924e-02,  7.4870e-03,\n",
       "                      -4.3482e-02, -5.4137e-03,  2.9212e-02,  1.8176e-02,  4.2388e-02,\n",
       "                       2.2601e-03, -2.6682e-02,  2.5432e-03,  1.5482e-02,  3.2234e-02,\n",
       "                      -2.1457e-02, -4.0758e-02,  5.7415e-04,  8.6478e-03,  7.4995e-03,\n",
       "                      -2.9695e-02, -2.5171e-03, -3.4790e-02, -2.6186e-02,  5.0249e-03,\n",
       "                      -3.8415e-02,  2.4952e-02,  1.6696e-03,  2.0034e-02, -3.4579e-04,\n",
       "                       2.0316e-02, -3.9186e-02,  2.0465e-02,  3.2908e-02,  4.3616e-02,\n",
       "                       1.0071e-03, -3.9423e-02, -2.4873e-02, -3.6809e-02,  3.6965e-02,\n",
       "                      -2.9297e-02,  2.8074e-02, -1.6178e-02, -2.3990e-02,  2.0379e-02,\n",
       "                       2.3435e-02, -6.7641e-03, -4.3818e-02, -3.2831e-02,  3.5420e-02,\n",
       "                       3.5989e-02,  2.8603e-02, -3.2104e-02, -2.0151e-02,  1.7828e-02,\n",
       "                      -1.7554e-02, -3.0170e-02, -5.9291e-03, -4.1329e-02,  4.1625e-02,\n",
       "                      -1.4843e-02,  1.3538e-02, -2.5894e-03, -2.1016e-02, -1.5050e-02,\n",
       "                      -2.9481e-02,  1.0258e-02, -2.7488e-02, -2.2468e-03,  1.9959e-02,\n",
       "                      -3.3678e-02, -3.9367e-02,  2.5470e-02, -5.6959e-03,  1.9395e-02,\n",
       "                      -4.2826e-02,  4.4108e-02, -3.6174e-02,  2.5144e-03, -2.0158e-02,\n",
       "                       2.0522e-02,  2.8464e-02,  2.9977e-02, -1.6377e-02, -5.7612e-03,\n",
       "                      -3.6401e-03,  1.7553e-02,  1.0839e-02, -2.0058e-02,  7.3047e-03,\n",
       "                      -3.0235e-02,  2.1001e-02, -3.8725e-02, -3.5970e-02, -1.5564e-02,\n",
       "                      -2.0424e-02, -1.4629e-02,  5.2306e-04, -2.3617e-02, -1.0120e-04,\n",
       "                      -3.4833e-02, -3.7002e-02,  3.6201e-02, -1.7146e-02,  3.2178e-02,\n",
       "                      -3.9860e-03, -3.8684e-02, -1.2871e-02, -4.2824e-02,  3.3360e-02,\n",
       "                      -5.0488e-03,  6.2711e-03, -2.8112e-02, -3.9143e-02,  1.7675e-03,\n",
       "                      -4.1675e-02,  2.2835e-02, -3.7505e-02,  4.1249e-02,  4.3742e-02,\n",
       "                      -2.4258e-02,  3.4525e-02, -2.9333e-02,  2.7352e-02, -2.6444e-02,\n",
       "                       3.9394e-02,  2.2775e-02, -2.3315e-02, -4.2466e-02, -2.4536e-02,\n",
       "                      -3.3627e-02,  3.6052e-02,  3.2263e-02,  2.9398e-02, -1.9969e-02,\n",
       "                       3.2223e-02,  2.0694e-02, -3.0176e-02, -2.3416e-02,  2.3037e-02,\n",
       "                      -1.6820e-02,  2.7209e-02,  4.2328e-02,  3.4410e-02,  2.4142e-02,\n",
       "                      -1.5842e-02, -9.5929e-03, -2.7161e-02,  4.2949e-02, -1.1869e-02,\n",
       "                       8.3619e-03,  2.6464e-02,  2.6247e-02, -2.5737e-02,  1.9616e-02,\n",
       "                      -3.6112e-02,  3.4172e-02, -1.3108e-02,  3.9197e-02, -6.2959e-03,\n",
       "                       5.4154e-03,  2.9941e-03, -1.0623e-02, -2.4471e-02, -5.5058e-03,\n",
       "                      -4.5500e-03,  3.7988e-02, -3.3964e-02, -2.2443e-02,  1.6194e-02,\n",
       "                       3.4872e-02,  2.6405e-02,  8.7336e-03, -4.2351e-03,  3.2777e-02,\n",
       "                       1.6281e-02,  2.1749e-02,  5.4855e-03, -2.5098e-02,  9.2174e-04,\n",
       "                       2.1761e-03,  3.2563e-02, -2.2796e-02,  3.9475e-02, -1.8014e-02,\n",
       "                      -6.0217e-03, -2.6841e-02,  1.9047e-03, -1.1580e-03,  1.0494e-02,\n",
       "                       3.1037e-03,  2.0600e-02,  1.5304e-02, -2.2692e-02,  4.0857e-02,\n",
       "                      -2.9509e-02,  1.9164e-02, -3.3144e-02, -3.1607e-03,  2.9906e-03,\n",
       "                      -3.2901e-02,  3.8913e-02,  3.0443e-02, -9.7022e-04,  2.9788e-02,\n",
       "                       1.0222e-02,  4.3473e-02,  3.7400e-02,  3.3907e-03, -3.8639e-02,\n",
       "                       2.6508e-02, -3.5372e-02, -2.3559e-02,  4.2005e-02,  2.0017e-02,\n",
       "                       2.0691e-03,  2.0162e-02,  4.3980e-02, -2.1227e-03,  3.2621e-02,\n",
       "                       3.5281e-02, -2.6309e-02])),\n",
       "             ('__S__.tdnn4.2.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn4.2.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn4.2.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.tdnn4.2.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.tdnn4.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.tdnn5.0.weight',\n",
       "              tensor([[[-0.0229],\n",
       "                       [-0.0125],\n",
       "                       [-0.0374],\n",
       "                       ...,\n",
       "                       [ 0.0240],\n",
       "                       [-0.0126],\n",
       "                       [-0.0370]],\n",
       "              \n",
       "                      [[ 0.0381],\n",
       "                       [ 0.0340],\n",
       "                       [-0.0165],\n",
       "                       ...,\n",
       "                       [ 0.0389],\n",
       "                       [ 0.0102],\n",
       "                       [-0.0348]],\n",
       "              \n",
       "                      [[ 0.0428],\n",
       "                       [-0.0103],\n",
       "                       [ 0.0364],\n",
       "                       ...,\n",
       "                       [-0.0332],\n",
       "                       [ 0.0371],\n",
       "                       [ 0.0032]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0034],\n",
       "                       [-0.0260],\n",
       "                       [ 0.0192],\n",
       "                       ...,\n",
       "                       [ 0.0229],\n",
       "                       [ 0.0100],\n",
       "                       [-0.0009]],\n",
       "              \n",
       "                      [[-0.0025],\n",
       "                       [-0.0180],\n",
       "                       [ 0.0239],\n",
       "                       ...,\n",
       "                       [-0.0236],\n",
       "                       [ 0.0348],\n",
       "                       [ 0.0224]],\n",
       "              \n",
       "                      [[ 0.0194],\n",
       "                       [-0.0252],\n",
       "                       [-0.0432],\n",
       "                       ...,\n",
       "                       [-0.0340],\n",
       "                       [-0.0135],\n",
       "                       [-0.0011]]])),\n",
       "             ('__S__.tdnn5.0.bias',\n",
       "              tensor([-0.0334,  0.0098,  0.0440,  ..., -0.0017, -0.0268,  0.0320])),\n",
       "             ('__S__.tdnn5.2.weight', tensor([1., 1., 1.,  ..., 1., 1., 1.])),\n",
       "             ('__S__.tdnn5.2.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('__S__.tdnn5.2.running_mean',\n",
       "              tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('__S__.tdnn5.2.running_var',\n",
       "              tensor([1., 1., 1.,  ..., 1., 1., 1.])),\n",
       "             ('__S__.tdnn5.2.num_batches_tracked', tensor(0)),\n",
       "             ('__S__.pooling.linear1.weight',\n",
       "              tensor([[[-0.0004],\n",
       "                       [-0.0048],\n",
       "                       [-0.0021],\n",
       "                       ...,\n",
       "                       [-0.0001],\n",
       "                       [ 0.0091],\n",
       "                       [ 0.0068]],\n",
       "              \n",
       "                      [[-0.0111],\n",
       "                       [ 0.0021],\n",
       "                       [ 0.0036],\n",
       "                       ...,\n",
       "                       [ 0.0016],\n",
       "                       [-0.0147],\n",
       "                       [-0.0021]],\n",
       "              \n",
       "                      [[-0.0031],\n",
       "                       [-0.0145],\n",
       "                       [ 0.0233],\n",
       "                       ...,\n",
       "                       [ 0.0047],\n",
       "                       [-0.0184],\n",
       "                       [-0.0029]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[ 0.0231],\n",
       "                       [ 0.0105],\n",
       "                       [ 0.0034],\n",
       "                       ...,\n",
       "                       [-0.0244],\n",
       "                       [ 0.0113],\n",
       "                       [-0.0126]],\n",
       "              \n",
       "                      [[ 0.0147],\n",
       "                       [ 0.0161],\n",
       "                       [-0.0087],\n",
       "                       ...,\n",
       "                       [ 0.0245],\n",
       "                       [-0.0126],\n",
       "                       [-0.0209]],\n",
       "              \n",
       "                      [[ 0.0050],\n",
       "                       [ 0.0223],\n",
       "                       [ 0.0014],\n",
       "                       ...,\n",
       "                       [ 0.0157],\n",
       "                       [ 0.0196],\n",
       "                       [-0.0016]]])),\n",
       "             ('__S__.pooling.linear1.bias',\n",
       "              tensor([ 1.1690e-03, -2.9569e-03, -2.4084e-02,  2.1898e-02, -1.5069e-02,\n",
       "                       1.2164e-02,  1.1746e-02,  1.7477e-03,  1.9293e-02, -2.2257e-02,\n",
       "                       9.4038e-04, -3.8836e-03,  1.3968e-03,  1.9127e-02, -7.7005e-03,\n",
       "                      -1.2250e-02, -1.1025e-03, -1.3980e-02, -2.2869e-02, -2.5340e-02,\n",
       "                      -2.7671e-03, -2.6237e-03,  2.2916e-02,  7.2109e-03, -2.5177e-02,\n",
       "                      -7.5660e-03,  1.0588e-02, -2.4560e-02, -1.0035e-02,  9.0492e-03,\n",
       "                      -1.3856e-02, -2.5473e-03,  1.7109e-02,  8.5650e-03, -9.1047e-03,\n",
       "                      -5.9214e-03,  4.9649e-03,  1.9471e-02,  4.5044e-04,  7.8715e-03,\n",
       "                      -1.9609e-02, -2.4754e-02,  2.5264e-02,  8.2206e-03, -1.2271e-03,\n",
       "                      -2.5456e-03, -6.2811e-03, -2.1334e-02, -4.6197e-03, -3.2599e-03,\n",
       "                      -2.5386e-02, -9.9041e-03,  1.8512e-02,  8.2638e-03,  4.0762e-03,\n",
       "                      -1.9350e-02, -2.5522e-02,  1.2760e-02,  1.5920e-03, -2.0741e-02,\n",
       "                       1.5455e-02, -2.1972e-02,  1.6640e-02,  2.6467e-03,  1.8629e-02,\n",
       "                       2.1856e-02, -1.2141e-02,  2.0111e-02,  4.6604e-03, -1.3793e-03,\n",
       "                       1.0662e-02,  1.9564e-02, -7.1969e-03,  1.1944e-02, -1.8457e-02,\n",
       "                      -2.1197e-02, -1.3911e-02, -1.4849e-02,  2.0356e-02,  2.1073e-02,\n",
       "                       5.8554e-03,  1.7099e-02,  9.9753e-03,  1.0322e-02, -1.5015e-02,\n",
       "                       1.3678e-03, -5.8369e-03,  1.4446e-02, -2.4480e-02,  1.2548e-02,\n",
       "                       1.6893e-02,  1.1416e-02, -7.2285e-04,  2.0359e-02,  2.0938e-02,\n",
       "                       2.6932e-03,  2.4562e-02,  1.0536e-02, -1.8561e-02, -2.5184e-02,\n",
       "                       6.9061e-03,  1.2162e-02,  1.1877e-02, -6.9634e-03, -5.2372e-03,\n",
       "                      -1.7865e-02, -2.4682e-03,  1.9801e-05,  4.6449e-04, -1.3092e-02,\n",
       "                      -6.5373e-03,  9.0358e-03,  6.3959e-03,  1.9784e-02,  1.9872e-02,\n",
       "                      -1.1820e-02,  5.7718e-03,  1.4543e-03, -9.7804e-03, -2.0106e-02,\n",
       "                      -1.8136e-02,  5.6104e-03, -5.2767e-03, -1.1757e-02,  2.7971e-03,\n",
       "                       2.7896e-03,  8.6078e-03,  4.4473e-03])),\n",
       "             ('__S__.pooling.linear2.weight',\n",
       "              tensor([[[-0.0046],\n",
       "                       [ 0.0671],\n",
       "                       [-0.0155],\n",
       "                       ...,\n",
       "                       [ 0.0283],\n",
       "                       [ 0.0428],\n",
       "                       [ 0.0751]],\n",
       "              \n",
       "                      [[-0.0151],\n",
       "                       [-0.0331],\n",
       "                       [-0.0451],\n",
       "                       ...,\n",
       "                       [ 0.0285],\n",
       "                       [-0.0702],\n",
       "                       [-0.0036]],\n",
       "              \n",
       "                      [[-0.0171],\n",
       "                       [-0.0342],\n",
       "                       [ 0.0608],\n",
       "                       ...,\n",
       "                       [-0.0393],\n",
       "                       [ 0.0500],\n",
       "                       [-0.0492]],\n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "                      [[-0.0598],\n",
       "                       [ 0.0151],\n",
       "                       [-0.0041],\n",
       "                       ...,\n",
       "                       [ 0.0804],\n",
       "                       [-0.0602],\n",
       "                       [ 0.0477]],\n",
       "              \n",
       "                      [[-0.0001],\n",
       "                       [-0.0472],\n",
       "                       [-0.0582],\n",
       "                       ...,\n",
       "                       [-0.0184],\n",
       "                       [ 0.0716],\n",
       "                       [-0.0464]],\n",
       "              \n",
       "                      [[ 0.0560],\n",
       "                       [-0.0700],\n",
       "                       [-0.0505],\n",
       "                       ...,\n",
       "                       [ 0.0848],\n",
       "                       [ 0.0723],\n",
       "                       [-0.0073]]])),\n",
       "             ('__S__.pooling.linear2.bias',\n",
       "              tensor([ 0.0500,  0.0571,  0.0409,  ..., -0.0336, -0.0320, -0.0404])),\n",
       "             ('__S__.embedding_layer1.linear.weight',\n",
       "              tensor([[ 0.0070,  0.0109, -0.0029,  ...,  0.0151, -0.0126,  0.0124],\n",
       "                      [-0.0042, -0.0144,  0.0118,  ...,  0.0046, -0.0158, -0.0024],\n",
       "                      [-0.0155, -0.0104, -0.0088,  ..., -0.0048, -0.0061,  0.0089],\n",
       "                      ...,\n",
       "                      [ 0.0176,  0.0093, -0.0147,  ..., -0.0015,  0.0028, -0.0012],\n",
       "                      [ 0.0031,  0.0011,  0.0057,  ..., -0.0132,  0.0086,  0.0012],\n",
       "                      [-0.0078, -0.0066, -0.0112,  ...,  0.0169, -0.0008,  0.0141]])),\n",
       "             ('__S__.embedding_layer1.linear.bias',\n",
       "              tensor([-1.0349e-02, -1.7972e-02,  1.7249e-02,  1.4870e-02,  9.9584e-03,\n",
       "                      -1.5486e-02,  3.8871e-03,  1.2742e-02, -1.4397e-02, -1.7714e-02,\n",
       "                      -1.1004e-02, -1.7119e-02, -3.5033e-03, -2.9436e-03,  9.4609e-04,\n",
       "                      -9.6580e-03,  1.3120e-02,  1.3958e-02, -5.2743e-03, -1.3442e-02,\n",
       "                      -5.3794e-04,  2.5785e-03, -5.5474e-03, -1.0862e-02,  3.3420e-03,\n",
       "                       8.4271e-03, -4.3764e-03,  6.4858e-03, -6.8555e-03,  5.7438e-03,\n",
       "                      -1.3499e-02,  5.0019e-03,  1.3434e-02,  2.4432e-03,  1.7515e-02,\n",
       "                       1.3908e-02,  5.0184e-03, -6.7034e-04, -1.7539e-02,  4.8698e-03,\n",
       "                      -1.4642e-02, -8.4949e-03,  7.2557e-03,  1.8161e-02,  1.3053e-02,\n",
       "                       6.4032e-03, -5.5115e-03,  1.0247e-02, -1.6862e-03, -1.5463e-02,\n",
       "                      -1.3256e-02, -6.7334e-03,  1.7349e-02, -1.7340e-02,  4.0732e-05,\n",
       "                      -1.7362e-02,  1.1759e-02,  1.2885e-02,  5.8442e-03,  8.6430e-03,\n",
       "                      -7.0206e-04,  9.2753e-03,  1.1053e-02,  6.7893e-03,  1.4063e-02,\n",
       "                      -2.4761e-03, -1.6334e-02,  1.2895e-02, -5.6168e-03,  1.3502e-02,\n",
       "                       1.5774e-02, -2.9390e-03,  1.5313e-02,  1.1735e-02, -1.1822e-02,\n",
       "                      -8.2481e-03, -1.6153e-02,  7.7252e-03, -5.1074e-03,  2.2907e-03,\n",
       "                       1.0183e-02,  7.9087e-03, -1.1379e-02, -6.0890e-03,  1.5366e-02,\n",
       "                      -1.0474e-02,  6.6609e-03,  1.2746e-02,  1.3932e-02, -1.3021e-03,\n",
       "                       2.5392e-03,  2.9697e-03, -7.2156e-03,  1.2879e-02,  1.4856e-02,\n",
       "                      -9.8424e-03,  2.2375e-03, -6.2086e-03,  1.4080e-02, -2.4572e-03,\n",
       "                       1.1103e-02, -9.7863e-04, -1.4057e-02, -4.1303e-03,  8.5761e-03,\n",
       "                      -1.7040e-02,  1.8810e-03,  1.6777e-02, -1.5836e-02, -1.7882e-02,\n",
       "                       1.7345e-02,  1.5125e-02, -4.1963e-03, -7.5611e-03,  1.6779e-02,\n",
       "                      -1.5003e-02, -1.6691e-02, -3.1231e-03,  3.0470e-03, -1.4490e-02,\n",
       "                       2.9487e-03, -2.7787e-03,  1.2794e-02, -5.0551e-03,  9.1710e-03,\n",
       "                       8.5885e-03,  1.0121e-02,  1.4734e-02,  1.1210e-02,  2.6850e-03,\n",
       "                      -5.0584e-03,  1.3950e-02,  2.5412e-04, -8.8646e-03,  8.0690e-03,\n",
       "                      -2.4214e-03,  1.5722e-02, -6.5616e-03,  3.9569e-03, -1.0896e-02,\n",
       "                      -9.1125e-03,  1.7793e-02,  9.6051e-03,  6.3442e-03,  8.0714e-03,\n",
       "                       4.0336e-03, -1.7603e-02,  8.3497e-04,  1.5526e-04,  3.5042e-04,\n",
       "                      -1.2190e-02,  1.3428e-03, -1.7037e-02,  5.2623e-03, -1.2302e-02,\n",
       "                      -6.1150e-03, -1.7345e-02, -1.2093e-02,  3.1441e-03,  9.2207e-03,\n",
       "                       1.0255e-02,  1.2777e-02, -2.9669e-03,  1.2361e-02,  1.2395e-02,\n",
       "                       5.6799e-03, -9.3067e-03,  1.5533e-02, -5.6200e-03, -3.9354e-03,\n",
       "                      -1.6030e-02,  1.1848e-03,  1.5296e-02, -1.0602e-02,  6.2509e-03,\n",
       "                      -2.4574e-03, -1.5326e-02, -1.1856e-02, -1.5397e-02, -4.1111e-03,\n",
       "                       1.0579e-02, -8.2224e-03, -1.5633e-02,  1.2613e-02,  1.6264e-02,\n",
       "                       3.5068e-03,  3.7387e-03, -2.7682e-03, -1.4333e-02, -5.4606e-03,\n",
       "                       1.1248e-02, -1.5572e-02])),\n",
       "             ('__S__.embedding_layer1.batchnorm.weight',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.bias',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.running_mean',\n",
       "              tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "                      0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.running_var',\n",
       "              tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])),\n",
       "             ('__S__.embedding_layer1.batchnorm.num_batches_tracked',\n",
       "              tensor(0)),\n",
       "             ('__L__.fc.weight',\n",
       "              tensor([[-0.0535,  0.0347,  0.0201,  ..., -0.0365, -0.0007,  0.0472],\n",
       "                      [ 0.0567,  0.0202, -0.0330,  ..., -0.0009,  0.0713, -0.0576],\n",
       "                      [-0.0142, -0.0654,  0.0437,  ...,  0.0399,  0.0240,  0.0215],\n",
       "                      ...,\n",
       "                      [ 0.0469, -0.0623, -0.0647,  ..., -0.0373,  0.0557,  0.0547],\n",
       "                      [ 0.0189,  0.0004,  0.0574,  ..., -0.0483, -0.0125,  0.0266],\n",
       "                      [-0.0006,  0.0400,  0.0575,  ...,  0.0444,  0.0639,  0.0099]])),\n",
       "             ('__L__.fc.bias',\n",
       "              tensor([-0.0186, -0.0333, -0.0554,  ...,  0.0284,  0.0671,  0.0522]))])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DatasetLoader import get_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = get_data_loader(dataset_file_name='/nvme/zhiyong/sdsv21/vox2_trainlist.txt', batch_size=128, augment=False, musan_path='/nvme/zhiyong/musan_split', rir_path='/nvme/zhiyong/RIRS_NOISES/simulated_rirs', max_frames=300, max_seg_per_spk=10, nDataLoaderThread=4, nPerSpeaker=1, train_path='/nvme/zhiyong/sdsv21', sox_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468.28125"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5994*10/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = glob.glob('/nvme/zhiyong/CN-Celeb/data/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for i in a:\n",
    "    b = glob.glob(i+'/*')\n",
    "    if b[0].split('/')[-1].split('-')[0] == 'interview':\n",
    "        c.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/nvme1/zhiyong/ASV_LOGS_202102/train_logs_201120/xvector(vox2)/model/model000000134.model'\n",
    "# loaded_state = torch.load(path, map_location=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.fc.weight', '__L__.fc.bias'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['__S__.torchfb.0.flipped_filter', '__S__.torchfb.1.spectrogram.window', '__S__.torchfb.1.mel_scale.fb', '__S__.tdnn1.0.weight', '__S__.tdnn1.0.bias', '__S__.tdnn1.2.weight', '__S__.tdnn1.2.bias', '__S__.tdnn1.2.running_mean', '__S__.tdnn1.2.running_var', '__S__.tdnn1.2.num_batches_tracked', '__S__.tdnn2.0.weight', '__S__.tdnn2.0.bias', '__S__.tdnn2.2.weight', '__S__.tdnn2.2.bias', '__S__.tdnn2.2.running_mean', '__S__.tdnn2.2.running_var', '__S__.tdnn2.2.num_batches_tracked', '__S__.tdnn3.0.weight', '__S__.tdnn3.0.bias', '__S__.tdnn3.2.weight', '__S__.tdnn3.2.bias', '__S__.tdnn3.2.running_mean', '__S__.tdnn3.2.running_var', '__S__.tdnn3.2.num_batches_tracked', '__S__.tdnn4.0.weight', '__S__.tdnn4.0.bias', '__S__.tdnn4.2.weight', '__S__.tdnn4.2.bias', '__S__.tdnn4.2.running_mean', '__S__.tdnn4.2.running_var', '__S__.tdnn4.2.num_batches_tracked', '__S__.tdnn5.0.weight', '__S__.tdnn5.0.bias', '__S__.tdnn5.2.weight', '__S__.tdnn5.2.bias', '__S__.tdnn5.2.running_mean', '__S__.tdnn5.2.running_var', '__S__.tdnn5.2.num_batches_tracked', '__S__.pooling.linear1.weight', '__S__.pooling.linear1.bias', '__S__.pooling.linear2.weight', '__S__.pooling.linear2.bias', '__S__.embedding_layer1.linear.weight', '__S__.embedding_layer1.linear.bias', '__S__.embedding_layer1.batchnorm.weight', '__S__.embedding_layer1.batchnorm.bias', '__S__.embedding_layer1.batchnorm.running_mean', '__S__.embedding_layer1.batchnorm.running_var', '__S__.embedding_layer1.batchnorm.num_batches_tracked', '__L__.W'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_state['model'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadParameters(model, path, map_location=\"cuda:0\"):\n",
    "\n",
    "    self_state = model.state_dict()\n",
    "    loaded_state = torch.load(path, map_location=map_location)\n",
    "\n",
    "    for name, param in loaded_state['model'].items():\n",
    "        if name == '__L__.W':\n",
    "            continue\n",
    "        \n",
    "        origname = name\n",
    "        if name not in self_state:\n",
    "            name = name.replace(\"module.\", \"\")\n",
    "            if name not in self_state:\n",
    "                name = \"__S__.\"+name\n",
    "                if name not in self_state:\n",
    "                    print(\"#%s is not in the model.\"%origname)\n",
    "                    continue\n",
    "\n",
    "        if self_state[name].size() != loaded_state['model'][origname].size():\n",
    "            print(\"#Wrong parameter length: %s, model: %s, loaded: %s\"%(origname, self_state[name].size(), loaded_state['model'][origname].size()))\n",
    "            continue\n",
    "\n",
    "        self_state[name].copy_(param)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadParameters(s, path, 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy, math, pdb, sys, random\n",
    "import time, os, itertools, shutil, importlib\n",
    "\n",
    "from src.DatasetLoader import loadWAV\n",
    "from src.tuneThreshold import tuneThresholdfromScore_std\n",
    "\n",
    "def evaluateFromList(model, listfilename, distance_m='cosine', print_interval=100, test_path='', num_eval=10, eval_frames=0, verbose=True):\n",
    "    assert distance_m in ['L2', 'cosine']\n",
    "    if verbose:\n",
    "        print('Distance metric: %s'%(distance_m))\n",
    "        print('Evaluating from trial file: %s'%(listfilename))\n",
    "    \n",
    "    model = model.cuda()\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    lines       = []\n",
    "    files       = []\n",
    "    feats       = {}\n",
    "    tstart      = time.time()\n",
    "\n",
    "    ## Read all lines\n",
    "    with open(listfilename) as listfile:\n",
    "        while True:\n",
    "            line = listfile.readline()\n",
    "            if (not line):\n",
    "                break\n",
    "\n",
    "            data = line.split()\n",
    "\n",
    "            ## Append random label if missing\n",
    "            if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "            files.append(data[1])\n",
    "            files.append(data[2])\n",
    "            lines.append(line)\n",
    "\n",
    "    setfiles = list(set(files))\n",
    "    setfiles.sort()\n",
    "\n",
    "    ## Save all features to file\n",
    "    for idx, file in enumerate(setfiles):\n",
    "\n",
    "        inp1 = torch.FloatTensor(loadWAV(os.path.join(test_path,file), eval_frames, evalmode=True, num_eval=num_eval)).cuda()\n",
    "\n",
    "        ref_feat = model.forward(inp1).detach().cpu()\n",
    "\n",
    "        filename = '%06d.wav'%idx\n",
    "\n",
    "        feats[file] = ref_feat\n",
    "\n",
    "        telapsed = time.time() - tstart\n",
    "\n",
    "        if (idx % print_interval == 0) and verbose:\n",
    "            sys.stdout.write(\"\\rReading %d of %d: %.2f Hz, embedding size %d\"%(idx, len(setfiles), idx/telapsed, ref_feat.size()[1]))\n",
    "\n",
    "    all_scores = []\n",
    "    all_labels = []\n",
    "    all_trials = []\n",
    "    tstart = time.time()\n",
    "\n",
    "    ## Read files and compute all scores\n",
    "    for idx, line in enumerate(lines):\n",
    "\n",
    "        data = line.split()\n",
    "\n",
    "        ## Append random label if missing\n",
    "        if len(data) == 2: data = [random.randint(0,1)] + data\n",
    "\n",
    "\n",
    "        ref_feat = feats[data[1]]\n",
    "        com_feat = feats[data[2]]\n",
    "        # ref_feat = (feats[data[1]] - mean_vector).cuda() \n",
    "        # com_feat = (feats[data[2]] - mean_vector).cuda()\n",
    "\n",
    "        # if self.__model__.module.__L__.test_normalize:\n",
    "        ref_feat = F.normalize(ref_feat, p=2, dim=1)\n",
    "        com_feat = F.normalize(com_feat, p=2, dim=1)\n",
    "\n",
    "        if distance_m == 'L2':\n",
    "            dist = F.pairwise_distance(ref_feat.unsqueeze(-1), com_feat.unsqueeze(-1).transpose(0,2)).numpy()\n",
    "            score = -1 * numpy.mean(dist)\n",
    "        elif distance_m == 'cosine':\n",
    "            ## [1, emb_size]\n",
    "            dist = F.cosine_similarity(ref_feat.unsqueeze(-1), com_feat.unsqueeze(-1).transpose(0,2)).numpy()\n",
    "            score = numpy.mean(dist)\n",
    "        else:\n",
    "            raise ValueError('Unknown distance metric: %s'%(distance_m))\n",
    "\n",
    "        all_scores.append(score)\n",
    "        all_labels.append(int(data[0]))\n",
    "        all_trials.append(data[1]+\" \"+data[2])\n",
    "\n",
    "        if (idx % (print_interval*100) == 0) and verbose:\n",
    "            telapsed = time.time() - tstart\n",
    "            sys.stdout.write(\"\\rComputing %d of %d: %.2f Hz\"%(idx,len(lines),idx/telapsed))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "    result = tuneThresholdfromScore_std(all_scores, all_labels)\n",
    "    print('')\n",
    "    print('EER %2.4f MINC@0.01 %.5f MINC@0.001 %.5f'%(result[1], result[-2], result[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance metric: cosine\n",
      "Evaluating from trial file: /nvme/zhiyong/sdsv21/vox_o_triallist.txt\n",
      "Computing 30000 of 37611: 6605.29 Hzedding size 192\n",
      "EER 2.0469 MINC@0.01 0.23119 MINC@0.001 0.32961\n"
     ]
    }
   ],
   "source": [
    "evaluateFromList(s, '/nvme/zhiyong/sdsv21/vox_o_triallist.txt', distance_m='cosine', print_interval=100, test_path='/nvme/zhiyong/sdsv21', num_eval=10, eval_frames=0, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "with open('/workspace/Federated-Averaging-PyTorch1/config.yaml') as c:\n",
    "    configs = list(yaml.load_all(c, Loader=yaml.FullLoader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'global_config': {'seed': 5959,\n",
       "   'device': 'cuda',\n",
       "   'is_mp': False,\n",
       "   'evaluate': True}},\n",
       " {'data_config': {'data_path': './data/',\n",
       "   'dataset_name': 'MNIST',\n",
       "   'num_shards': 200,\n",
       "   'iid': False,\n",
       "   'fl_dataset_path': '/workspace/flearn_data'}},\n",
       " {'fed_config': {'C': 0.6,\n",
       "   'K': 12,\n",
       "   'R': 500,\n",
       "   'E': 1,\n",
       "   'B': 10,\n",
       "   'criterion': 'torch.nn.CrossEntropyLoss',\n",
       "   'optimizer': 'torch.optim.SGD'}},\n",
       " {'optim_config': {'lr': 0.01, 'momentum': 0.9}},\n",
       " {'init_config': {'init_type': 'xavier',\n",
       "   'init_gain': 1.0,\n",
       "   'gpu_ids': [0, 1, 2]}},\n",
       " {'model_config': {'name': 'CNN',\n",
       "   'in_channels': 1,\n",
       "   'hidden_channels': 32,\n",
       "   'num_hiddens': 512,\n",
       "   'num_classes': 10}},\n",
       " {'log_config': {'log_path': './log/',\n",
       "   'log_name': 'FL.log',\n",
       "   'tb_port': 5252,\n",
       "   'tb_host': '0.0.0.0'}},\n",
       " {'eval_config': {'eval_task': 'ver',\n",
       "   'testfile_path': '/workspace/flearn_data',\n",
       "   'model_path': '/nvme1/zhiyong/ASV_LOGS_202102/train_logs_201120/xvector(vox2)/model/model000000134.model',\n",
       "   'listfilename': '/workspace/flearn_data/ver_list_G12_VER.txt'}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config = configs[0][\"global_config\"]\n",
    "data_config = configs[1][\"data_config\"]\n",
    "fed_config = configs[2][\"fed_config\"]\n",
    "optim_config = configs[3][\"optim_config\"]\n",
    "init_config = configs[4][\"init_config\"]\n",
    "model_config = configs[5][\"model_config\"]\n",
    "log_config = configs[6][\"log_config\"]\n",
    "eval_config = configs[7][\"eval_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/flearn_data/train_list_G1.txt',\n",
       " '/workspace/flearn_data/train_list_G2.txt',\n",
       " '/workspace/flearn_data/train_list_G3.txt',\n",
       " '/workspace/flearn_data/train_list_G4.txt',\n",
       " '/workspace/flearn_data/train_list_G5.txt',\n",
       " '/workspace/flearn_data/train_list_G6.txt',\n",
       " '/workspace/flearn_data/train_list_G7.txt',\n",
       " '/workspace/flearn_data/train_list_G8.txt',\n",
       " '/workspace/flearn_data/train_list_G9.txt',\n",
       " '/workspace/flearn_data/train_list_G10.txt',\n",
       " '/workspace/flearn_data/train_list_G11.txt',\n",
       " '/workspace/flearn_data/train_list_G12.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "[os.path.join(data_config[\"fl_dataset_path\"],\n",
    "        \"train_list_G%d.txt\"%(i+1)) for i in range(fed_config[\"K\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data',\n",
       " '/workspace/flearn_data']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[data_config[\"fl_dataset_path\"]] * fed_config[\"K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_list_G1',\n",
       " 'train_list_G2',\n",
       " 'train_list_G3',\n",
       " 'train_list_G4',\n",
       " 'train_list_G5',\n",
       " 'train_list_G6',\n",
       " 'train_list_G7',\n",
       " 'train_list_G8',\n",
       " 'train_list_G9',\n",
       " 'train_list_G10',\n",
       " 'train_list_G11',\n",
       " 'train_list_G12']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ \"train_list_G%d\"%(i+1) for i in range(12) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.DatasetLoader import get_data_loader_speaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = get_data_loader_speaker(0*100, dataset_file_name=\"/workspace/flearn_data/train_list_G1.txt\", \n",
    "    batch_size=128, augment=False, musan_path='/nvme/zhiyong/musan_split', \n",
    "    rir_path='/nvme/zhiyong/RIRS_NOISES/simulated_rirs', max_frames=300, \n",
    "    max_seg_per_spk=100, nDataLoaderThread=8, nPerSpeaker=1, \n",
    "    train_path='', sox_aug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 3.9600e+02,  2.3000e+02, -1.1510e+03,  ...,  5.6200e+03,\n",
       "           -3.8400e+02,  3.0000e+00]],\n",
       " \n",
       "         [[-2.4550e+03, -3.1140e+03, -2.6730e+03,  ...,  2.6920e+03,\n",
       "            2.8260e+03,  3.1890e+03]],\n",
       " \n",
       "         [[-7.8600e+02,  1.9000e+02, -5.1000e+01,  ...,  4.0100e+02,\n",
       "           -1.1490e+03, -2.1810e+03]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-5.0680e+03, -4.0730e+03, -2.8300e+03,  ..., -7.7300e+02,\n",
       "            5.2100e+02,  1.2240e+03]],\n",
       " \n",
       "         [[-6.8700e+02,  9.7100e+02, -4.9100e+02,  ...,  1.0420e+03,\n",
       "           -7.4200e+02,  4.3700e+02]],\n",
       " \n",
       "         [[ 1.0600e+02,  1.2000e+02,  1.4000e+02,  ...,  1.8800e+02,\n",
       "            1.1100e+02,  5.0000e+01]]]),\n",
       " tensor([85,  8, 87, 74, 84, 59, 27, 34, 74,  0, 37, 59, 33, 71, 14,  3, 72, 92,\n",
       "         57, 32, 39, 77, 37, 18, 51,  8, 54, 36, 52, 23,  7, 10, 34,  3, 20, 84,\n",
       "         59, 49, 61, 46, 84, 54,  4, 84, 60, 14, 15, 55, 63, 52, 27, 72, 15, 26,\n",
       "         38, 85, 33, 68, 35,  3, 82, 97, 85, 99, 36, 71, 26, 51, 59,  3,  3, 13,\n",
       "         17, 75, 45, 41, 75, 83, 70, 86, 47, 26, 75, 76,  4, 89, 62, 10, 96, 33,\n",
       "         33, 52,  1, 57, 37, 40, 55, 13, 62, 19, 58, 99, 98, 77, 21, 13, 80, 96,\n",
       "         22, 26, 58, 94, 18, 46, 63,  4, 27, 44,  5, 36, 36, 36, 54, 57, 77,  8,\n",
       "         52, 54])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
